<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>jar包执行时访问资源文件造成的FileSystemNotFoundException问题</title>
    <link href="/2021/01/07/jar%E5%8C%85%E6%89%A7%E8%A1%8C%E6%97%B6%E8%AE%BF%E9%97%AE%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6%E9%80%A0%E6%88%90%E7%9A%84FileSystemNotFoundException%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    <url>/2021/01/07/jar%E5%8C%85%E6%89%A7%E8%A1%8C%E6%97%B6%E8%AE%BF%E9%97%AE%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6%E9%80%A0%E6%88%90%E7%9A%84FileSystemNotFoundException%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>在Java项目中，若需要访问资源文件，通常使用<code>getClass().getResource(&quot;/xxx&quot;)</code>和<code>getClass().getResourceAsStream(&quot;/&quot;)</code>来获取资源文件，后一种方式获取到的是InputStream，一般不会出现什么问题，但是通过第一种获取资源URL的方式，在IDEA中执行时没有问题，但是在服务器环境执行时，会出现<code>java.nio.file.FileSystemNotFoundException</code>，之前遇到这个问题我没有在意，只是换成<code>getResourceAsStream</code>后就解决了，但是后来遇到一个需要递归访问资源文件目录，我使用的<code>Files.walkFileTree</code>方法，直接获取输入流的方案不适合我，随后发现其实只要是打成jar包执行的时候，通过<code>Files</code>和<code>Path</code>去访问资源文件，<code>getResource</code>就会抛出<code>FileSystemNotFoundException</code>，并非服务器环境的问题，因为jar包执行时，文件系统与IDE中直接执行时不一样，所以会抛出这个异常。<br>原始的代码如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">Path configDir &#x3D; Paths.get(                    LocalConfigDataFlowManager.class.getResource(                            &quot;&#x2F;&quot;                    ).toURI().getPath(), &quot;flow-config&quot;            );List&lt;Map&lt;String, Object&gt;&gt; config &#x3D; new ArrayList&lt;&gt;();Files.walkFileTree(        configDir,        new HashSet&lt;&gt;(),        1,        new FileVisitor&lt;Path&gt;() &#123;        ......</code></pre><p>报错信息如下：</p><pre class="line-numbers language-log" data-language="log"><code class="language-log">java.nio.file.FileSystemNotFoundException        at jdk.zipfs&#x2F;jdk.nio.zipfs.ZipFileSystemProvider.getFileSystem(ZipFileSystemProvider.java:169)        at jdk.zipfs&#x2F;jdk.nio.zipfs.ZipFileSystemProvider.getPath(ZipFileSystemProvider.java:155)        at java.base&#x2F;java.nio.file.Path.of(Path.java:208)        at java.base&#x2F;java.nio.file.Paths.get(Paths.java:97)        at ink.andromeda.dataflow.core.flow.ConfigurableDataFlowManager.&lt;init&gt;(ConfigurableDataFlowManager.java:305)        at ink.andromeda.dataflow.demo.LocalConfigDataFlowManager.&lt;init&gt;(LocalConfigDataFlowManager.java:25)        at ink.andromeda.dataflow.demo.DataFlowDemoApplication.dataFlowManager(DataFlowDemoApplication.java:51)        at ink.andromeda.dataflow.demo.DataFlowDemoApplication$$EnhancerBySpringCGLIB$$73b01d37.CGLIB$dataFlowManager$0(&lt;generated&gt;)        ............2021-01-07.22:34:39.649 ERROR TraceId[] [main] i.a.d.d.LocalConfigDataFlowManager.visitFileFailed:60 null&#x2F;flow-configjava.nio.file.NoSuchFileException: null&#x2F;flow-config        at java.base&#x2F;sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)        at java.base&#x2F;sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)        at java.base&#x2F;sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)        at java.base&#x2F;sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)        at java.base&#x2F;sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:149)        at java.base&#x2F;java.nio.file.Files.readAttributes(Files.java:1763)        at java.base&#x2F;java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219)        at java.base&#x2F;java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276)        at java.base&#x2F;java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322)        at java.base&#x2F;java.nio.file.Files.walkFileTree(Files.java:2716)        at ink.andromeda.dataflow.demo.LocalConfigDataFlowManager.getFlowConfig(LocalConfigDataFlowManager.java:39)        at ink.andromeda.dataflow.core.flow.ConfigurableDataFlowManager.reload(ConfigurableDataFlowManager.java:92)        at ink.andromeda.dataflow.core.flow.ConfigurableDataFlowManager.init(ConfigurableDataFlowManager.java:56)        at java.base&#x2F;jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at java.base&#x2F;jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at java.base&#x2F;jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.base&#x2F;java.lang.reflect.Method.invoke(Method.java:566)        ......</code></pre><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>刚开始试了如下方案：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">Path configDir &#x3D; FileSystems.getDefault().getPath(new UrlResource(this.getClass().getResource(&quot;&#x2F;flow-config&quot;).toURI()).toString());</code></pre><p>但是仍然有问题：</p><pre class="line-numbers language-log" data-language="log"><code class="language-log">2021-01-07.23:06:42.037 ERROR TraceId[] [main] i.a.d.d.LocalConfigDataFlowManager.visitFileFailed:63 URL [jar:file:&#x2F;Users&#x2F;windlively&#x2F;IdeaProjects&#x2F;data-flow&#x2F;data-flow-demo&#x2F;target&#x2F;data-flow-demo-1.0-SNAPSHOT.jar!&#x2F;BOOT-INF&#x2F;classes!&#x2F;flow-config]java.nio.file.NoSuchFileException: URL [jar:file:&#x2F;Users&#x2F;windlively&#x2F;IdeaProjects&#x2F;data-flow&#x2F;data-flow-demo&#x2F;target&#x2F;data-flow-demo-1.0-SNAPSHOT.jar!&#x2F;BOOT-INF&#x2F;classes!&#x2F;flow-config]        at java.base&#x2F;sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)        at java.base&#x2F;sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)        at java.base&#x2F;sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)        at java.base&#x2F;sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)        at java.base&#x2F;sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:149)        at java.base&#x2F;java.nio.file.Files.readAttributes(Files.java:1763)        at java.base&#x2F;java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219)        at java.base&#x2F;java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276)        at java.base&#x2F;java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322)        at java.base&#x2F;java.nio.file.Files.walkFileTree(Files.java:2716)        at ink.andromeda.dataflow.demo.LocalConfigDataFlowManager.getFlowConfig(LocalConfigDataFlowManager.java:42)        at ink.andromeda.dataflow.core.flow.ConfigurableDataFlowManager.reload(ConfigurableDataFlowManager.java:92)        at ink.andromeda.dataflow.core.flow.ConfigurableDataFlowManager.init(ConfigurableDataFlowManager.java:56)</code></pre><p>于是继续查询资料，在stackoverflow上看到了一个利用Spring的<code>@Value()</code>注解和Spring Resource来访问资源文件的替代方案，而且提供了遍历资源文件夹的方法。<br>首先在Bean中加入一个字段并用Value注解注入资源文件的位置：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Value(&quot;classpath:&#x2F;flow-config&#x2F;**&quot;)private Resource[] flowConfigResources;</code></pre><p>Spring会自动将classes根目录<code>flow-config</code>文件夹下的资源文件全部注入到<code>flowConfigResources</code>字段中去。<br>然后修改原先的代码如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">protected List&lt;Map&lt;String, Object&gt;&gt; getFlowConfig() &#123;    return Stream.of(flowConfigResources)            .filter(s -&gt; Objects.nonNull(s.getFilename()))            .filter(s -&gt; s.getFilename().matches(&quot;^sync-config-[\\w-]+?.json$&quot;))            .map(flowConfigResource -&gt; &#123;                try (InputStream is &#x3D; flowConfigResource.getInputStream()) &#123;                    ByteArrayOutputStream os &#x3D; new ByteArrayOutputStream();                    int data;                    while ((data &#x3D; is.read()) !&#x3D; -1) os.write(data);                    &#x2F;&#x2F;noinspection unchecked                    return (Map&lt;String, Object&gt;) GSON().fromJson(os.toString(StandardCharsets.UTF_8.name()),                            new TypeToken&lt;Map&lt;String, Object&gt;&gt;() &#123;                            &#125;.getType());                &#125; catch (IOException ex) &#123;                    throw new IllegalStateException(ex);                &#125;            &#125;)            .filter(Objects::nonNull)            .collect(Collectors.toList());&#125;</code></pre><p>过滤和遍历Spring注入的Resource列表，即可读取到此文件夹下所有需要的资源文件，打成jar包之后也可正常运行。</p>]]></content>
    
    
    
    <tags>
      
      <tag>后端开发</tag>
      
      <tag>Java</tag>
      
      <tag>踩坑记录</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>前端发展简史</title>
    <link href="/2020/12/23/%E5%89%8D%E7%AB%AF%E5%8F%91%E5%B1%95%E7%AE%80%E5%8F%B2/"/>
    <url>/2020/12/23/%E5%89%8D%E7%AB%AF%E5%8F%91%E5%B1%95%E7%AE%80%E5%8F%B2/</url>
    
    <content type="html"><![CDATA[<h2 id="前端技术发展历程"><a href="#前端技术发展历程" class="headerlink" title="前端技术发展历程"></a>前端技术发展历程</h2><h3 id="远古时代："><a href="#远古时代：" class="headerlink" title="远古时代："></a>远古时代：</h3><p>还没有前端这个概念，网页是纯静态页面，HTML伴随着HTTP协议诞生，做一些纯文字信息的展示。</p><h3 id="CSS和JavaScript加入"><a href="#CSS和JavaScript加入" class="headerlink" title="CSS和JavaScript加入"></a>CSS和JavaScript加入</h3><p>早期的页面样式是由<code>&lt;font&gt;&lt;b&gt;&lt;sub&gt;&lt;center&gt;</code>等一系列标签去控制的，但是不利于维护和扩展，所以出现了CSS，将样式控制独立了出来，利于样式的复用。那时候网速也很慢，为了优化交互体验，诞生了JavaScript，此时的JavaScript就是做一些简单的页面逻辑交互，而且原名叫LiveScript，为了蹭Java热度改为了JavaScript……</p><h3 id="JavaScript和ECMAScript？"><a href="#JavaScript和ECMAScript？" class="headerlink" title="JavaScript和ECMAScript？"></a>JavaScript和ECMAScript？</h3><p>JavaScript的开发公司是Netscape，Netscape为了抵抗微软的JScript，将JavaScript提交给ECMA国际标准化组织，希望JavaScript成为国际标准，后来ECMA组织颁布了浏览器脚本语言标准，称之为ECMAScript，因此ECMAScript是一套规范标准，而JavaScript、微软的JScript则是这套标准的实现，大多数场合下ECMAScript和JavaScript的称呼可以通用。</p><h3 id="Dreamweaver、Firework、Flash、FrontPage等拖拽式设计网页的软件"><a href="#Dreamweaver、Firework、Flash、FrontPage等拖拽式设计网页的软件" class="headerlink" title="Dreamweaver、Firework、Flash、FrontPage等拖拽式设计网页的软件"></a>Dreamweaver、Firework、Flash、FrontPage等拖拽式设计网页的软件</h3><ul><li><p>Dreamweaver</p><p>大名鼎鼎的设计软件公司Adobe出品的产品，将网页开发变成了所见即所得，可以使得不懂代码的人经过简单的拖拽操作即可快速生成一套静态网页。Dreamweaver至今仍然在更新，支持的功能也越来越高级了。</p></li></ul><ul><li><p>FrontPage</p><p>微软的网页制作软件，属于Office组件中的一个产品，功能也十分强大，还支持数据库相关操作，于2006年停止更新，后由SharePoint Designer和Expression Web代替</p></li></ul><h3 id="动态网页技术CGI、PHP、JSP等的产生"><a href="#动态网页技术CGI、PHP、JSP等的产生" class="headerlink" title="动态网页技术CGI、PHP、JSP等的产生"></a>动态网页技术CGI、PHP、JSP等的产生</h3><ul><li><p>CGI</p><p>CGI(通用网关接口)是最老的一种技术，其实就是一组接口规范，可以用许多语言( C 、C++ 、VB和Perl等)编写，只要实现其接口即可，当浏览器发起请求，经Web服务器路由后会启动一个进程，调用对应的的CGI程序，程序执行完毕后返回HTML文本至浏览器，展示给用户。由于CGI性能低下，后来衍生出FastCGI，至今仍是一种广泛应用的技术，主流web服务器(Apache、Nginx、Microsoft IIS等)均支持该技术。</p></li><li><p>PHP</p><p>是一种在HTML文本中嵌入服务端代码的脚本语言，可以跨平台运行。由于其简单易上手，功能强大，又是开源技术，曾在Web开发领域风靡一时，和MySQL是好基友。（PHP是世界上最好的语言 yeah~）</p></li><li><p>JSP</p><p>基于Java的动态网页技术，与PHP有些许类似，也是在HTML代码中嵌入Java代码，由服务端编译执行。Java是Web开发领域最主流的技术之一，诞生过许多优秀的Web框架技术，从SSH(Struct、Spring、Hibernate)到SSM(Spring、Spring MVC、MyBatis)，都深受开发者喜爱。如今已经是Spring一家独大，几乎囊括了后端开发的方方面面。相比于PHP技术要求更高一点。</p></li></ul><ul><li><p>ASP</p><p>微软家的动态网页技术，同时支持VBScript和JScript，一般结合.NET框架使用，技术以及功能上来说都挺好，就是收费，财大气粗的公司多数可能会选择它。。。</p></li></ul><ul><li><p>FreeMarker、Thymeleaf等后端模板引擎</p><p>相对于JSP进行优化的页面渲染框架，这两种模板引擎Spring Boot框架都给予了良好的支持。</p></li></ul><h3 id="Ajax技术兴起以及JQuery时代降临"><a href="#Ajax技术兴起以及JQuery时代降临" class="headerlink" title="Ajax技术兴起以及JQuery时代降临"></a>Ajax技术兴起以及JQuery时代降临</h3><ul><li><p>Ajax</p><p>异步的JavaScript和XML(Asynchronous JavaScript and XML)技术，在之前的架构中，客户端向服务器发起请求，服务器处理结束后返回一个新的HTML文本，这样每一次请求都会交互大量数据，而且还要占用服务端资源渲染HTML文档，因此产生了Ajax技术：通过JavaScript代码主动请求服务器，而服务器只返回客户端需要的数据，不再将数据渲染为HTML返回，客户端拿到数据之后，通过DOM操作异步的更新界面，Ajax的优点非常明显：</p><ul><li>极大的减少了网络通信的数据量，比如有时候页面仅需变更一个数字，原先的服务端渲染方式就需要将整个页面全部重新返回，而ajax方式只需要返回这个更新后的数字。</li><li>减轻服务器压力，在大量请求时，仅渲染HTML文档所占用的资源就已经很大了，而客户端JavaScript代码更新页面则不会存在此问题。</li><li>页面是局部刷新的，而不是跟以前一样全部刷新，用户体验更好。</li></ul><p>但是也有一部分缺点：</p><ul><li>用户使用浏览器前进后退时的体验不好，异步刷新的局部更新方式浏览器无法获取历史页面，即丢失了页面的变更历史，但是这一点之后也有开发者想出办法解决。<br>搜索引擎无法SEO。搜索引擎公司的爬虫脚本获取不到网站数据，只能得到一段发送HTTP请求的JS代码，对网站的SEO是一个负面影响，不过Google对此已经有了解决方案，google的搜索引擎已经可以通过执行网页中的JS代码来爬取数据了（黑科技啊！~）</li><li>早期兼容性不好，但是现在已经不是问题了。</li></ul><p>Ajax在JavaScript中是通过XmlHttpRequest对象来支持的，原生的XHR API用起来是比较复杂的，于是便有人对其进行了封装，顺便处理了兼容性，用起来十分方便，比如JQuery。<br>随着Ajax的兴起，JSON这种数据格式也随之慢慢被大家所采用的，凭借比XML的简洁与方便，现在已成为主流的数据交互格式之一。</p></li><li><p>JQuery</p><p>JQuery是之前非常流行的一款前端JS框架，简洁且功能强大，还帮助开发者处理了很多兼容性问题，优化了DOM操作，封装了许多非常好用的API，是当时前端必备的利器，我当时对其也爱不释手，至今仍然还有不少人在用。在此段时期，前后端开发也渐渐出现了分离的迹象。</p></li></ul><h3 id="架在Chrome-V8上的Node"><a href="#架在Chrome-V8上的Node" class="headerlink" title="架在Chrome V8上的Node"></a>架在Chrome V8上的Node</h3><ul><li><p>V8 JavaScript引擎</p><p>V8是由Google研发的一款JavaScript执行引擎，并且谷歌将其开源，V8的特点，就是：快！，非常快，各种优化的奇淫技巧，诞生了这个杰作。所以当年产生了不少调侃Chrome和IE的段子，而由于V8的出现，在服务器上运行JavaScript代码成为了可能。</p></li><li><p>Node.js</p><p>Node凭借着V8引擎的基础，将JavaScript搬到了后台，V8作为Node的运行时，并添加了一些与操作系统交互的API，使其可以脱离浏览器运行，试图将JavaScript应用于后端开发，分一杯服务器开发的羹，并且确实火了一把，虽然最终未能撼动Java的地位，但是他的包管理工具NPM以及依赖管理后续被大家广泛使用，为后来前端项目的工程化奠定了基础，使得前端开发者们有了媲美后端的一系列项目工具（依赖管理、编译、测试、打包、部署、运行）。</p></li></ul><h3 id="JavaScript编译器以及TypeScript等许多新技术"><a href="#JavaScript编译器以及TypeScript等许多新技术" class="headerlink" title="JavaScript编译器以及TypeScript等许多新技术"></a>JavaScript编译器以及TypeScript等许多新技术</h3><ul><li><p>Babel.js</p><p>babel是一个开源的JavaScript编译(转译)器，用于将其他的编程风格转换为JavaScript代码。Babel的出现主要是因为在ES 5、ES 6标准问世之后，各浏览器厂商却未能及时支持，所以出现了此类转译工具，可以将ES 5 + 的语法编译成向后兼容的JavaScript语法，也可自定义语法，提升开发效率，React框架的语法翻译就依赖此库。</p></li><li><p>TypeScript</p><p>TypeScript是JavaScript的超集，由微软推出并开源，它在JavaScript基础之上增添了许多强大的功能支持，最重要的一个特点就是加入了静态类型系统的支持，使其更适合于大型工程项目，并且对于类型的支持比Java之类的语言更加优雅。TypeScript代码通过TypeScript编译期或Babel编译为JavaScript代码执行。</p></li><li><p>服务端推送技术</p><ul><li><p>SSE</p><p>SSE(Server-Sent Events)是服务端向客户端推送数据的一种技术，原先的web模型只能是客户端向服务端发起请求，服务端被动响应，而服务器无法主动向客户端发送数据，所以出现了SSE方案，其实SSE仍然是基于HTTP长连接的一种技术，本质仍然是HTTP协议，其Content-Type为text/event-stream类型，JavaScript代码使用EventSource对象进行处理，发送的文本有固定格式，使用较为简单方便，但是只能服务端向客户端单向发送数据。Spring MVC框架对SSE有不错的支持。</p></li><li><p>WebSocket</p><p>建立在TCP之上的另外一种网络通信协议，支持全双工通信，且效率更高，使用起来比SSE复杂一些，适合需要与服务端进行频繁交互的场景。</p></li></ul></li></ul><ul><li><p>HTML5新特性</p><p>HTML5标准其实诞生时间比较早，由W3C于2014年10月完成标准制定，但是各个浏览器支持进度不一，直至Chrome 67、IE8等现代浏览器问世之后，HTML5标准才被较好的支持。</p><ul><li><p>canvas画布</p><p>支持使用JavaScript代码在页面上绘制复杂图形以及动画。</p></li><li><p>多媒体标签</p><p><code>&lt;audio&gt;&lt;video&gt;</code>等标签的加入，使得开发人员可以更容易的在网页中处理多媒体内容，此前这类复杂内容主要通过Flash、ActiveX等控件处理，而现在HTML原生支持多媒体处理，Flash等技术由于安全性相关问题已经慢慢被遗弃，Chrome浏览器早已默认禁用flash。</p></li><li><p>其他新特性</p><p>本地存储、WEB SQL、<code>&lt;article&gt;&lt;footer&gt;&lt;header&gt;&lt;nav&gt;&lt;section&gt;</code>等新标签，etc…</p></li></ul></li><li><p>CSS新特性</p><p>CSS陆续加入了许多强大和有趣的功能，使得UI可以越来越漂亮，这也得益于客户端浏览器性能越来越强悍：</p><ul><li>适合移动设备的flex布局</li><li>MediaQuery加入，支持响应式布局</li><li>Grid布局</li><li>CSS滤镜</li><li>CSS背景虚化</li><li>CSS动画</li><li>……</li></ul></li></ul><h3 id="React-js、Angular、Vue-js等框架陆续登场"><a href="#React-js、Angular、Vue-js等框架陆续登场" class="headerlink" title="React.js、Angular、Vue.js等框架陆续登场"></a>React.js、Angular、Vue.js等框架陆续登场</h3><p>随着前后端分离的web开发方案以及SPA(单页面应用)的概念越来越流行，前端框架也开始层出不穷，将原先属于后端的MVC模型利用JS搬到了前端，又形成了MVVM、MVP等模型概念，其中以React、Angular、Vue最为出名和流行，彻底将前端开发从后端开发中剥离出来，使得前端开发更为纯粹，专注于页面视图开发，曾风光无限的JQuery一类的js库开始慢慢淡出历史舞台，得益于框架提供的强大功能，我们不再需要手动操纵DOM文档。框架技术在此时的发展十分迅速，甚至开始向原生APP开发领域挺进，而基于这些框架技术开发的网站，又可被称之为Web App，网站已经从原先的信息展示变成了一些功能性应用。Android、Windows都有将JS开发的应用转换为对应平台APP的技术，至此，JavaScript已经做到了”Any application that can be written in JavaScript, will eventually be written in JavaScript”！</p><h3 id="大前端时代，百花齐放的WebApp框架"><a href="#大前端时代，百花齐放的WebApp框架" class="headerlink" title="大前端时代，百花齐放的WebApp框架"></a>大前端时代，百花齐放的WebApp框架</h3><p>此时的前端又被许多人称之为”大前端”，JavaScript早已不再局限于传统网站的开发，Electron、React Native、微信小程序、支付宝小程序等等，都在尝试基于浏览器的跨平台APP技术，也都取得了不错的效果，JavaScript从早期一个无数人吐槽的脚本语言进化到现在成为了前端开发的核心。<br>到今天，人们还不满足于此，前端技术仍在高速发展，以Google为代表的众多行业领头羊继续在探索未来的前端方向，例如浏览器已经开始支持的WebAssembly技术和Google的Flutter跨平台原生APP开发框架。</p>]]></content>
    
    
    
    <tags>
      
      <tag>前端开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker安装mongo</title>
    <link href="/2020/12/15/docker%E5%AE%89%E8%A3%85mongo/"/>
    <url>/2020/12/15/docker%E5%AE%89%E8%A3%85mongo/</url>
    
    <content type="html"><![CDATA[<ul><li><p>拉取镜像<br><code>docker pull mongo</code></p></li><li><p>选择一个合适的文件夹, 创建mongo目录并进入<br><code>mkdir mongo &amp;&amp; cd mongo</code></p></li><li><p>创建配置文件目录<br><code>mkdir conf</code></p></li><li><p>创建并编辑配置文件<br><code>vim conf/mongod.conf</code><br>mongod.config为mongo配置文件, 示例:</p><pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">storage:journal:  enabled: trueengine: wiredTiger#如下配置仅对 wiredTiger 引擎生效（3.0 以上版本） wiredTiger:  engineConfig:  # wiredTiger缓存工作集（working set）数据的内存大小，单位：GB   # 此值决定了wiredTiger与mmapv1的内存模型不同，它可以限制mongod对内存的使用量，而mmapv1则不能（依赖于系统级的mmap）。默认情况下，cacheSizeGB 的值为假定当前节点只部署一个mongod实例，此值的大小为物理内存的一半；如果当前节点部署了多个mongod进程，那么需要合理配置此值。如果mongod部署在虚拟容器中（比如，lxc，cgroups，Docker）等，它将不能使用整个系统的物理内存，则需要适当调整此值。默认值为物理内存的一半。     cacheSizeGB: 1.5systemLog:  logAppend: truenet:  bindIp: 0.0.0.0# 是否开启授权security:  authorization: enabled</code></pre></li><li><p>创建并运行mongo docker容器，路径映射需要根据机器更改  </p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker run --name mongo \   --privileged \   -p 27017:27017 \   -v ~&#x2F;docker-app&#x2F;mongo&#x2F;data:&#x2F;data&#x2F;db \   -v ~&#x2F;docker-app&#x2F;mongo&#x2F;conf:&#x2F;data&#x2F;configdb \   -v ~&#x2F;docker-app&#x2F;mongo&#x2F;logs:&#x2F;data&#x2F;log&#x2F; \   -d  \   mongo  \   -f &#x2F;data&#x2F;configdb&#x2F;mongod.conf</code></pre><p>解释:</p><blockquote><p>–name mongo  #容器名<br>–privileged  #给予权限<br>-p 27017:27017   #端口映射<br>-v ~/docker-app/mongo/data:/data/db   #数据文件夹映射（主机:容器）<br>-v ~/docker-app/mongo/conf:/data/configdb   #配置文件路径映射<br>-v ~/docker-app/mongo/logs:/data/log/    #日志文件夹路径映射<br>-d   #后台运行<br>mongo   # 所使用的镜像<br>-f /data/configdb/mongod.conf  #使用配置文件启动(路径对应的容器路径，非主机路径)  </p></blockquote></li><li><p>附一个bash脚本(在mongo文件夹下执行)</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"># 创建一个mongo docker容器mkdir conftouch conf&#x2F;mongod.confconf_file&#x3D;&#39;conf&#x2F;mongod.conf&#39;cat&gt;$conf_file&lt;&lt;EOFstorage:  journal:    enabled: true  engine: wiredTiger  wiredTiger:  engineConfig:    cacheSizeGB: 1.5systemLog:  logAppend: truenet:  bindIp: 0.0.0.0security:  authorization: enabledEOFdocker pull mongobase_dir&#x3D;$PWDdocker run --name mongo \  --privileged \  -p 27017:27017 \  -v $base_dir&#x2F;data:&#x2F;data&#x2F;db \  -v $base_dir&#x2F;conf:&#x2F;data&#x2F;configdb \  -v $base_dir&#x2F;logs:&#x2F;data&#x2F;log&#x2F; \  -d  \  mongo  \  -f &#x2F;data&#x2F;configdb&#x2F;mongod.conf</code></pre></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>docker</tag>
      
      <tag>后端开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于一次Kafka重复消费问题排查记录的闲谈</title>
    <link href="/2020/12/15/%E5%85%B3%E4%BA%8E%E4%B8%80%E6%AC%A1Kafka%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%AE%B0%E5%BD%95%E7%9A%84%E9%97%B2%E8%B0%88/"/>
    <url>/2020/12/15/%E5%85%B3%E4%BA%8E%E4%B8%80%E6%AC%A1Kafka%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%AE%B0%E5%BD%95%E7%9A%84%E9%97%B2%E8%B0%88/</url>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;前段时间上线一个新服务，我们的运营在测试的时候，导入了一批数据，结果目标表里的数据是预期数量的2倍，有大量的重复数据，一开始我认为可能是我没有过滤数据类型导致的，我所消费的数据是通过监听数据库的binlog解析后推送到Kafka的数据，我收到kafka消息经过反序列化得到多条数据库表的变动记录，每一条记录都有一个类型：<code>INSERT</code>，<code>UPDATE</code>，<code>DELETE</code>，其实也就是对应SQL的类型，我一开始并没有判断这个类型，而是收到的所有数据都进行后续的处理，运营也说可能是有<code>UPDATE</code>操作的，于是我加了过滤，只处理<code>INSERT</code>类型数据，改好之后想着肯定没问题了，于是让运营再删掉原有数据重新导入一遍，第二天再看结果。   </p><p>&emsp;&emsp;然而第二天，问题依旧……这下可难到我了，想了一会猜测会不会是前面的环节推送的数据就是重复的呢？但是也不能瞎猜，于是我在处理一条数据之前打印上offset，发版后开始观察日志，不一会儿库里出现了重复数据了，我拿到重复的订单号之后去日志中搜索，结果，两条数据的offset是一样的？</p><p><img src="https://oscimg.oschina.net/oscnet/up-a4d97566c877c3ad14dc1ae79d947b9c48e.png" alt="img"></p><p>&emsp;&emsp;看来这真是我消费的问题了，但是之前类似的项目也是同样的消费方式，从来没出现过重复消费呀，这就让我非常纳闷，于是找了几条重复数据，观察了一下插入时间，发现时间间隔还挺有规律，基本都是五分钟左右重复插入一次，在日志上发现重复消费是两台机器交替进行的，我所消费的Topic是只有一个分区的，所以只会有一台机器消费，从日志上看出来两台机器在交替消费，因而产生了重复消费，但是为什么呢，于是再搜了下<em>Exception</em>关键词，发现了一个<code>CommitFailedException</code>：</p><p><img src="https://oscimg.oschina.net/oscnet/up-4a5809d58553eb75c4d899315e717ef0e9c.png" alt="img"></p><p>&emsp;&emsp;可以看出来，是当前消费端被踢出了消费组，随后offset提交失败，然后换了一台机器重新消费这个offset，导致了重复消费，但是为什么被被剔除出消费组我仍然无法解释，因为日志上再也没其他错误信息了，好在后来又让我发现了点蛛丝马迹，那会刚好使用了<code>tail -f</code>命令，不经意间发现过了好久，接收到的数据offset都是一样的，一条kafka消息解压后有这么多？(后来在本地试了下，果然一条Kafka消息，反序列化后都有3000到9000条不等，这也太多了吧。。)经过一番Google之后注意到了Kafka的两个配置项：<code>max.poll.interval.ms</code>和<code>max.poll.records</code>分别代表拉取消息的间隔时间和拉取的最大条数，我的配置是：</p><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties">max.poll.interval.ms &#x3D; 600000 # 默认5分钟max.poll.records &#x3D; 20         # 这个是我最开始写的20条</code></pre><p>&emsp;&emsp;也就是说，最快要5分钟内处理完20个offset，否则将认为客户端不在消费了，也就产生了上面的异常，被踢出消费组，而后又commit失败。从打印的日志来看，这个时间明显不够，处理一个offset的消息都要很久，更别说最大20个了。知道原因后，我改了参数:</p><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties">max.poll.interval.ms &#x3D; 1200000max.poll.records &#x3D; 1</code></pre><p>&emsp;&emsp;也就是一条十分钟的一个的下限速度，但是后来证明，这个时间依旧远远不够(最后这个时间已经改为了1个小时…)，经过一段时间的观察，一条Kafka消息反序列化最多会有10000条数据，处理时间最长大约40多分钟，我最开始确实没有想到这个Topic中的一条消息包含的数据会这么多，导致了这一系列的问题，时间改为1小时后连续两天再没出现过重复消费offset的问题。</p><p>&emsp;&emsp;但是但是，这个程序的处理速度慢，也是导致此问题的一个原因，当然后来发现代码中，处理一条数据，平均查询与插入数据库的次数有五六十次！这当然快不起来啊，于是我在大部分的SQL查询部分使用<code>WeakHashMap</code>进行了数据缓存，因为这部分查询的数据基本是不会有变动的，极大的减少了数据库查询次数，处理速度提升了将近10倍！再后来，由于这个Topic只有一个partition，完全没办法用到多台机器的性能，而且据运维反馈，这个TiDB binlog监听的中间件只支持一个分区发送， 于是我自己在程序中增加了一道转发，即消费到Kafka消息反序列化之后，将反序列化之后的数据先不做处理，直接一条一条转发至RocketMQ，这个过程是非常快的，rocketMQ再发送至各个机器上(也可新建一个多partition的Kafka Topic用于转发)，这样就能充分利用集群的优势，进一步极大地提高处理速度，这一块说这么多其实偏题了，属于后续的一个优化。</p><p>&emsp;&emsp;后来发现，其实每一次在消费端即将离开之前，都会有一条日志：</p><p><img src="https://oscimg.oschina.net/oscnet/up-9bd6fbd5b2048752b177b7de8a7211c6c6d.png" alt="img"></p><p>&emsp;&emsp;提示向服务端发送了离开消费组的请求，因为客户端poll操作已超时，并建议增大最大拉取间隔时间或者减小最大拉取数量(这个不行，我都改到1了 T_T )。  </p><p>&emsp;&emsp;然后在处理完一个offset提交的时候会提示请求失败，当前消费者不再是此消费组的一部分。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ded106931e5c1de8ecefc6f11fca2dbf796.png" alt="img"></p><p>&emsp;&emsp;但是日志级别是INFO，确实不太容易发现，至此问题已完全解决，原因也完全清楚了。</p><p>&emsp;&emsp;总的来说此次遇到的Kafka重复消费的原因，第一是Kafka的消息太大（后来解析到最大有包含25万条数据的一条消息。。。这都是使用protobuf序列化的消息），但是这部分我们无法变动，第二是一开始处理速度也比较慢，默认间隔时间完全不够，综合导致频繁重新消费。</p><p>&emsp;&emsp;经过此次问题对Kafka参数有了更深的一些认识，除上面两个用到的同时也是比较重要参数之外，还有请求的超时时间、会话超时时间、心跳检测事件、拉取消息的超时时间等，在本地Debug期间还遇到过一个总是拉取不到消息然后报空指针异常的问题，然后查到原因是拉取Kafka消息超时了，一条消息可能有十几兆，那会刚好我电脑的网速非常慢，就超时了，后来加大了<code>fetch.max.wait.ms</code>和<code>request.timeout.ms</code>就没问题了。很有意义的一次Kafka问题排查经历</p><h3 id="附一个：Kafka-Consumer配置官方文档"><a href="#附一个：Kafka-Consumer配置官方文档" class="headerlink" title="附一个：Kafka Consumer配置官方文档"></a>附一个：<a href="http://kafka.apache.org/090/documentation.html#consumerconfigs">Kafka Consumer配置官方文档</a></h3>]]></content>
    
    
    
    <tags>
      
      <tag>kafka</tag>
      
      <tag>后端开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动态创建与修改定时任务</title>
    <link href="/2020/12/15/%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BA%E4%B8%8E%E4%BF%AE%E6%94%B9%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"/>
    <url>/2020/12/15/%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BA%E4%B8%8E%E4%BF%AE%E6%94%B9%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h3 id="emsp-emsp-最近遇到一个需求，需要能够按照特定的配置执行定时任务，而且定时任务需要在应用不重启的情况下动态增删改，Spring提供的-Scheduled注解是硬编码形式，只能实现固定的定时任务，随后经过一番探究，依托注明的quartz框架终于实现了该功能，下面来分享一下我的方案。"><a href="#emsp-emsp-最近遇到一个需求，需要能够按照特定的配置执行定时任务，而且定时任务需要在应用不重启的情况下动态增删改，Spring提供的-Scheduled注解是硬编码形式，只能实现固定的定时任务，随后经过一番探究，依托注明的quartz框架终于实现了该功能，下面来分享一下我的方案。" class="headerlink" title="&emsp;&emsp;最近遇到一个需求，需要能够按照特定的配置执行定时任务，而且定时任务需要在应用不重启的情况下动态增删改，Spring提供的@Scheduled注解是硬编码形式，只能实现固定的定时任务，随后经过一番探究，依托注明的quartz框架终于实现了该功能，下面来分享一下我的方案。"></a>&emsp;&emsp;最近遇到一个需求，需要能够按照特定的配置执行定时任务，而且定时任务需要在应用不重启的情况下动态增删改，Spring提供的<code>@Scheduled</code>注解是硬编码形式，只能实现固定的定时任务，随后经过一番探究，依托注明的quartz框架终于实现了该功能，下面来分享一下我的方案。</h3><ul><li><p>首先引入quartz maven依赖：</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml">&lt;dependency&gt;    &lt;groupId&gt;org.quartz-scheduler&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;quartz&lt;&#x2F;artifactId&gt;    &lt;!-- 由于我的项目继承了spring-boot-starter-parent，因此这里可以不用写版本号，会直接使用父pom文档中dependencyManagement的quartz版本号 --&gt;    &lt;!-- &lt;version&gt;2.3.2&lt;&#x2F;version&gt; --&gt;&lt;&#x2F;dependency&gt;</code></pre></li><li><p>我的定时任务配置是存储在MySQL数据库当中的，当程序启动时，初始化过程会的<code>init()</code>方法会读取一遍所有有效的定时任务配置，然后将其实例化为一个个对象，一个对象便代表了一个定时任务，我定义的类为 <code>public class ScheduledClauseTriggerEngine implements ClauseTriggerEngine&lt;Void&gt;, Job, AutoCloseable</code>，其中<code>ClauseTriggerEngine</code>为我自定义的接口，因为在项目中除定时触发外还有其他的任务触发方式，不再过多赘述，<code>Job</code>(<code>org.quartz.Job</code>)是quartz框架的一个接口，代表一个任务，在任务调度时，<code>Job</code>的<code>execute(JobExecutionContext context)</code>方法会被调用，用以执行任务内容。所有实例化后的<code>ScheduledClauseTriggerEngine</code>对象会被存在一个<code>Map&lt;Integer, ScheduledClauseTriggerEngine&gt;</code>容器中去，Key为定时任务的id，后续在定时任务增删改的时候，也会同步修改这个Map的内容。</p></li><li><p>创建<code>SchedulerFactoryBean</code>(<code>org.springframework.scheduling.quartz.SchedulerFactoryBean</code>)，并设置JobFactory，由于我这里只使用到SchedulerFactoryBean一次，因此这一小段代码写在构造方法中的，若是全局使用，需要在Spring的Configuration类中专门定义一个SchedulerFactoryBean类型的Bean(比较规范的用法)。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">SchedulerFactoryBean schedulerFactoryBean &#x3D; new SchedulerFactoryBean();        schedulerFactoryBean.setJobFactory((bundle, scheduler) -&gt;                triggers.get(Integer.parseInt(bundle.getJobDetail().getKey().getName())));        schedulerFactoryBean.afterPropertiesSet();        this.scheduler &#x3D; schedulerFactoryBean.getScheduler();        this.scheduler.start();</code></pre><p><code>setJobFactory</code>这一步比较重要，默认的调度方案是通过反射实现的，即传入一个Job类型的class，然后反射实例化一个此类的对象，再去调用execute方法，通过<code>JobExecutionContext</code>传参，而我的方案是所有任务类都已实例化完成，我希望在触发时直接返回对应的对象实例去执行即可，因此需要去修改JobFactory，<code>triggers</code>是上一步中所说的存储定时任务的Map，而<code>bundle.getJobDetail().getKey().getName()</code>其实就是获取到了任务的key，在我这里其实也就是定时任务id，这个与后面步骤的代码相对应，也就是此时定时任务触发时，会拿到我提前准备好的Map中的对应任务实例去执行，覆盖默认行为。</p></li><li><p>实例化ScheduledClauseTriggerEngine并创建定时任务，下面为比较重要的几行代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 此部分代码为实例化并创建一个定时任务的代码，我将其封装为了一个方法，方便调用，在初始化方法中查询所有定时任务循环调用即可&#x2F;&#x2F; ... 忽略数据库查询及参数校验的过程&#x2F;&#x2F; 创建JobDetailJobDetail jobDetail &#x3D; new JobDetailImpl()              .getJobBuilder()              &#x2F;&#x2F; 任务的id以及group，id为数据库中的id，在上一步设置的JobFactory，当改任务被调度时，会根据此id去获取到要执行的任务              .withIdentity(clauseTriggerId.toString(), SCHEDULE_JOB_GROUP_NAME)              &#x2F;&#x2F; 任务描述，可选              .withDescription(clauseTrigger.getName())              &#x2F;&#x2F; 这里直接传入ScheduledClauseTriggerEngine.class即可              .ofType(ScheduledClauseTriggerEngine.class)              .build();&#x2F;&#x2F; 添加触发器并开始调度任务scheduler.scheduleJob(jobDetail, TriggerBuilder.newTrigger()        &#x2F;&#x2F; 要调度的任务的key        .withIdentity(clauseTriggerId.toString())        &#x2F;&#x2F; 触发周期，triggerConfigToCronExpression是将数据库中的时间配置转换为corn表达式的方法        .withSchedule(CronScheduleBuilder.cronSchedule(triggerConfigToCronExpression(clauseTrigger.getTriggerConfig())))        .build());&#x2F;&#x2F; 此时其实定时任务已经开始生效&#x2F;&#x2F; 后续操作...triggerEngine.setTemplateList(scheduledTemplates);log.info(&quot;add one scheduled clause trigger: &#123;&#125;&quot;, clauseTrigger.getName());return triggerEngine;</code></pre></li><li><p>定时任务的增删改：</p><ul><li><p>根据id新增一个任务：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void addTrigger(int triggerId) &#123;  &#x2F;&#x2F; 根据triggerId实例化和启动一个定时任务，并添加到定时任务的Map中去，instanceOneScheduledClauseTriggerEngine就是上一步所封装的方法  ScheduledClauseTriggerEngine triggerEngine &#x3D; triggers.computeIfAbsent(triggerId, k -&gt; instanceOneScheduledClauseTriggerEngine(triggerId));&#125;</code></pre></li><li><p>根据id删除一个任务：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void removeTrigger(int clauseTriggerId) &#123;      try &#123;          &#x2F;&#x2F; 生成要删除的jobKey，注意此处必须传入刚才所使用的的group name，否则会使用默认的组名，便无法查询到我们想要删除的任务          JobKey jobKey &#x3D; JobKey.jobKey(String.valueOf(clauseTriggerId), SCHEDULE_JOB_GROUP_NAME);          &#x2F;&#x2F; 移除定时任务          scheduler.deleteJob(jobKey);          &#x2F;&#x2F; 从Map中移除对应的对象          triggers.remove(clauseTriggerId);          log.info(&quot;remove schedule trigger: &#123;&#125;&quot;, jobKey);      &#125; catch (SchedulerException e) &#123;          log.error(e.getMessage(), e);      &#125;&#125;</code></pre></li><li><p>根据id更新一个任务：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void updateTrigger(int triggerId) &#123;    &#x2F;&#x2F; 由于我项目中的定时任务可能任务执行内容会变，因此我是将定时任务删除再重新添加，若定时任务只会有触发时间的变化，也可使用rescheduleJob方法只更新触发时间    removeTrigger(triggerId);    addTrigger(triggerId);&#125;</code></pre></li></ul></li><li><p>集群环境下需要注意的地方</p><ul><li><p>多台机器时，我需要只有一台机器执行任务，而其他机器不执行，在此处我使用了Redis作为锁，追求简便，当然也可使用zookeeper。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Overridepublic void execute(JobExecutionContext context) &#123;    String jobKey &#x3D; context.getJobDetail().getKey().toString();    String redisKey &#x3D; JOB_REDIS_PREFIX + jobKey;    &#x2F;&#x2F; 判断是否获取到锁    &#x2F;&#x2F;noinspection ConstantConditions    if(redisTemplate.opsForValue().increment(redisKey) !&#x3D; 1L)&#123;        log.info(&quot;job &#123;&#125; has in running&quot;, jobKey);        return;    &#125;    &#x2F;&#x2F; 注意上面的判断必须放在try-finally块之外，否则会导致一个隐秘的BUG(无论当前机器是否获取到锁，都会执行finally中的方法，释放掉锁，产生错误)    &#x2F;&#x2F; 为锁加上默认过期时间    redisTemplate.expire(redisKey, 3600, TimeUnit.SECONDS);    try &#123;        MDC.put(&quot;traceId&quot;, randomId());        log.info(&quot;execute schedule job: &#123;&#125;&quot;, jobKey);        long l &#x3D; System.currentTimeMillis();        trigger();        log.info(&quot;finish job: &#123;&#125;, used time: &#123;&#125;ms&quot;, jobKey, System.currentTimeMillis()-l);    &#125; catch (Exception ex)&#123;        log.error(ex.getMessage(), ex);    &#125;finally &#123;        MDC.clear();        &#x2F;&#x2F; 释放锁        redisTemplate.delete(redisKey);    &#125;&#125;</code></pre><p>其实在之前，我写了一个注解：<code>@RedisLock</code>，可以通过注解方式直接为某个方法加分布式锁，但是注解不能传入变量，只能传入常量，在这个项目，锁的key是动态的，无法直接使用，便先采用直接写代码的形式，后期可以添加上此功能，通过注解传入SpringEL表达式解析方法入参，就可以实现动态key值了。</p></li><li><p>多台机器定时任务更新问题，当定时任务配置更改时，我需要响应的修改定时任务，但是多台机器，我不能一台一台机器的手动去调用对应的方法，因此我想到了使用redis的发布订阅去完成，因为Redis的默认消息模式是群发模式，刚好符合我的需求，若项目中有MQ，也可配置一个群发的MQ Topic去实现，略微复杂一些。<br>附我所使用的代码，供参考，基于spring-redis：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Bean  RedisMessageListenerContainer redisMessageListenerContainer(RedisConnectionFactory connectionFactory,                                                              ScheduledTriggerService scheduledTriggerService,                                                              DwdDataTriggerService dwdDataTriggerService,                                                              ClauseExecuteService clauseExecuteService) &#123;      RedisMessageListenerContainer container &#x3D; new RedisMessageListenerContainer();      container.setConnectionFactory(connectionFactory);      &#x2F;&#x2F;trigger发布订阅      container.addMessageListener((message, bytes) -&gt; &#123;          String body &#x3D; new String(message.getBody(), StandardCharsets.UTF_8);          if (body.startsWith(&quot;scheduled-trigger-change&quot;)) &#123;            Assert.isTrue(body.matches(&quot;^scheduled-trigger-change:((add)|(remove)|(update)):\\d+$&quot;),&quot;invalid scheduled-trigger-change message: &quot; + body);              String[] split &#x3D; body.split(&quot;:&quot;);              String type &#x3D; split[1];              int triggerId &#x3D; Integer.parseInt(split[2]);              switch (type) &#123;                  case &quot;add&quot;:                      scheduledTriggerService.addTrigger(triggerId);                      break;                  case &quot;remove&quot;:                      scheduledTriggerService.removeTrigger(triggerId);                      break;                  case &quot;update&quot;:                      scheduledTriggerService.updateTrigger(triggerId);                      break;                  default:                      scheduledTriggerService.refreshAllTriggerEngine();                      break;              &#125;          &#125; else &#123;              log.info(&quot;receive redis message, topic: &#123;&#125;, body, &#123;&#125;&quot;, new String(message.getChannel()), body);              dwdDataTriggerService.refreshClauseTrigger();          &#125;      &#125;, new ChannelTopic(&quot;trigger-config-change&quot;));      return container;  &#125;</code></pre><p>发送消息：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">redisTemplate.convertAndSend(&quot;trigger-config-change&quot;, &quot;scheduled-trigger-change:update:0&quot;);</code></pre><p>当定时配置变更时，发送redis消息即可。</p><h3 id="总结-本篇文章基于我的实际项目，讲解了借助于quartz框架的定时任务动态增删改的方案，但是因项目而异，我也做了许多定制化的操作，我的思路就是一项定时任务配置对应一个对象实例，任务触发时直接拿到对应的对象实例进行调用，但是quartz框架的默认调度方案不是这样的，所以做了一下调整，此外还增加了集群环境的支持。本篇文章提供一种方案或者说思路，实际使用时还需要大家结合自己的需求进行合理更改或优化，例如当定时任务比较轻量的时候，我认为可不借助于框架，使用轮询也未尝不是一种简单有效的方案。"><a href="#总结-本篇文章基于我的实际项目，讲解了借助于quartz框架的定时任务动态增删改的方案，但是因项目而异，我也做了许多定制化的操作，我的思路就是一项定时任务配置对应一个对象实例，任务触发时直接拿到对应的对象实例进行调用，但是quartz框架的默认调度方案不是这样的，所以做了一下调整，此外还增加了集群环境的支持。本篇文章提供一种方案或者说思路，实际使用时还需要大家结合自己的需求进行合理更改或优化，例如当定时任务比较轻量的时候，我认为可不借助于框架，使用轮询也未尝不是一种简单有效的方案。" class="headerlink" title="总结: 本篇文章基于我的实际项目，讲解了借助于quartz框架的定时任务动态增删改的方案，但是因项目而异，我也做了许多定制化的操作，我的思路就是一项定时任务配置对应一个对象实例，任务触发时直接拿到对应的对象实例进行调用，但是quartz框架的默认调度方案不是这样的，所以做了一下调整，此外还增加了集群环境的支持。本篇文章提供一种方案或者说思路，实际使用时还需要大家结合自己的需求进行合理更改或优化，例如当定时任务比较轻量的时候，我认为可不借助于框架，使用轮询也未尝不是一种简单有效的方案。"></a><strong>总结:</strong> 本篇文章基于我的实际项目，讲解了借助于quartz框架的定时任务动态增删改的方案，但是因项目而异，我也做了许多定制化的操作，我的思路就是一项定时任务配置对应一个对象实例，任务触发时直接拿到对应的对象实例进行调用，但是quartz框架的默认调度方案不是这样的，所以做了一下调整，此外还增加了集群环境的支持。本篇文章提供一种方案或者说思路，实际使用时还需要大家结合自己的需求进行合理更改或优化，例如当定时任务比较轻量的时候，我认为可不借助于框架，使用轮询也未尝不是一种简单有效的方案。</h3></li></ul></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>后端开发</tag>
      
      <tag>Java</tag>
      
      <tag>quartz</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Angular使用Http拦截器</title>
    <link href="/2020/12/15/Angular%E4%BD%BF%E7%94%A8Http%E6%8B%A6%E6%88%AA%E5%99%A8/"/>
    <url>/2020/12/15/Angular%E4%BD%BF%E7%94%A8Http%E6%8B%A6%E6%88%AA%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在前端开发的过程中，一般通过HTTP接口与后端进行数据交互，而后端一般会固定一个返回格式，例如：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json">&#123;    &quot;code&quot;: 0,    &quot;success&quot;: true,    &quot;message&quot;: &quot;&quot;,    &quot;result&quot;:&#123;        &quot;id&quot;:9,        &quot;title&quot;:&quot;&quot;,        &quot;content&quot;:&quot;&quot;,        &quot;createTime&quot;:&quot;2020-11-25 19:22:31&quot;,        &quot;updateTime&quot;:&quot;2020-11-25 19:47:22&quot;,        &quot;available&quot;:true    &#125;&#125;</code></pre><p>&emsp;&emsp;前端在拿到数据后，首先判断是否成功，然后取出数据体显示到页面上，但是每一次都这么去做，几乎都是重复的操作，在后端开发的过程中，有诸如过滤器、Spring提供的拦截器等工具实现对HTTP请求的统一处理，在前端其实也有类似的东西，Angular框架就提供了拦截器接口:</p><pre class="line-numbers language-typescript" data-language="typescript"><code class="language-typescript">interface HttpInterceptor &#123;  intercept(req: HttpRequest&lt;any&gt;, next: HttpHandler): Observable&lt;HttpEvent&lt;any&gt;&gt;&#125;</code></pre><p>&emsp;&emsp;可以实现统一的HTTP请求处理，帮助我们简化代码，并且方便代码的维护，直接放上一个我实际使用过的示例代码：</p><pre class="line-numbers language-typescript" data-language="typescript"><code class="language-typescript">import &#123;  HttpErrorResponse,  HttpEvent,  HttpHandler,  HttpInterceptor,  HttpRequest,  HttpResponse,  HttpResponseBase&#125; from &#39;@angular&#x2F;common&#x2F;http&#39;;import &#123;Observable, of, throwError&#125; from &#39;rxjs&#39;;import &#123;Injectable&#125; from &#39;@angular&#x2F;core&#39;;import &#123;catchError, debounceTime, finalize, mergeMap, retry&#125; from &#39;rxjs&#x2F;operators&#39;;import &#123;AppService&#125; from &#39;..&#x2F;service&#x2F;app.service&#39;;&#x2F;** * 全局HTTP请求拦截器 *&#x2F;@Injectable()export class AppHttpInterceptor implements HttpInterceptor &#123;  &#x2F;&#x2F; 当前正在通信中的HTTP请求数量，此值是为了在http请求的过程中添加加载动画  public processingHttpCount &#x3D; 0;  &#x2F;&#x2F; 依赖注入  constructor(public appService: AppService) &#123;  &#125;  intercept(req: HttpRequest&lt;any&gt;, next: HttpHandler): Observable&lt;HttpEvent&lt;any&gt;&gt; &#123;    &#x2F;&#x2F; &#x2F;monitor前缀的不做处理    if (req.url.includes(&#39;&#x2F;monitor&#39;)) &#123;      return next.handle(req);    &#125;    &#x2F;&#x2F;; setTimeout(() &#x3D;&gt; this.appService.showLoadingBar &#x3D; true);    &#x2F;&#x2F;     this.processingHttpCount ++;    return next.handle(req.clone(&#123;      &#x2F;&#x2F; 为所有拦截的请求添加一个&#39;&#x2F;starry&#39;前缀      url: &#39;&#x2F;starry&#39; + (req.url.startsWith(&#39;&#x2F;&#39;) ? req.url : &#39;&#x2F;&#39; + req.url)    &#125;))      .pipe(        debounceTime(1000),        &#x2F;&#x2F; 失败时重试2次        retry(2),        mergeMap((event: any) &#x3D;&gt; &#123;          &#x2F;&#x2F; 处理后端HTTP接口返回结果          if (event instanceof HttpResponseBase) &#123;            &#x2F;&#x2F; HTTP返回代码正常            if (event.status &gt;&#x3D; 200 &amp;&amp; event.status &lt; 400) &#123;              &#x2F;&#x2F; 处理HTTP Response              if (event instanceof HttpResponse) &#123;                const body &#x3D; event.body;                &#x2F;&#x2F; 判断后端的成功标志字段是否为true                if (body &amp;&amp; body.success) &#123;                  &#x2F;&#x2F; 取出响应体数据的data部分并继续后续操作(将原有的body替换为了body[&#39;result&#39;])                  return of(new HttpResponse(Object.assign(event, &#123;body: body.result&#125;)));                &#125; else &#123;                  &#x2F;&#x2F; 抛出异常                  throw Error(body.message);                &#125;              &#125;            &#125;          &#125;          &#x2F;&#x2F; 其余事件类型不作拦截处理          return of(event);        &#125;), catchError((err: HttpErrorResponse) &#x3D;&gt; &#123;          &#x2F;&#x2F; 如果发生5xx异常，显示一个错误信息提示          this.appService.showSnackBar(err.message, 4000);          console.error(err.message)          return throwError(err);        &#125;), finalize(() &#x3D;&gt; &#123;          &#x2F;&#x2F; 最终processingHttpCount减一，并且在减至0的时候移除掉加载动画          setTimeout(() &#x3D;&gt; --this.processingHttpCount &#x3D;&#x3D;&#x3D; 0 ?            this.appService.showLoadingBar &#x3D; false : this.appService.showLoadingBar &#x3D; true, 500);        &#125;));  &#125;&#125;</code></pre><p>&emsp;&emsp;并将此拦截器注册在Angular模块的provider中去，在providers中添加：</p><pre class="line-numbers language-typescript" data-language="typescript"><code class="language-typescript">&#123;    provide: HTTP_INTERCEPTORS, useClass: AppHttpInterceptor, multi: true&#125;</code></pre><p>&emsp;&emsp;这样在调用后端接口的时候我们不用每次再处理后端的返回数据，可直接在返回值中拿到数据体部分去做页面展示，其余的事情就交给拦截器去处理，例如：</p><pre class="line-numbers language-typescript" data-language="typescript"><code class="language-typescript">this.httpClient.get(&#39;&#x2F;config&#x2F;template&#x2F;&#39; + template).subscribe(data &#x3D;&gt; this.configTemplates.push(&#123;template, data&#125;));</code></pre><p>&emsp;&emsp;至此，就配置好了一个HTTP拦截器，还可以统一处理请求的URL以及异常处理等等，十分方便。官方文档地址：<a href="https://angular.io/api/common/http/HttpInterceptor">https://angular.io/api/common/http/HttpInterceptor</a> (中文文档将 <strong>.io</strong> 改为 <strong>.cn</strong> 即可)<br>&emsp;&emsp;除此之外，对于页面路由，Angular其实也提供了类似的工具，可以对路由以及页面组件进行拦截控制，有机会再作介绍。</p>]]></content>
    
    
    
    <tags>
      
      <tag>前端开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker安装zookeeper集群(附bash脚本)</title>
    <link href="/2020/12/14/docker%E5%AE%89%E8%A3%85zookeeper%E9%9B%86%E7%BE%A4-%E9%99%84bash%E8%84%9A%E6%9C%AC/"/>
    <url>/2020/12/14/docker%E5%AE%89%E8%A3%85zookeeper%E9%9B%86%E7%BE%A4-%E9%99%84bash%E8%84%9A%E6%9C%AC/</url>
    
    <content type="html"><![CDATA[<ul><li><p>准备一个文件夹并进入此文件夹， 例如</p><p><code>mkdir -p ~/docker-app/zookeeper &amp;&amp; cd ~/docker-app/zookeeper</code></p></li><li><p>准备三个文件夹并写入zookeeper的myid</p><p><code>mkdir -p zoo1/data &amp;&amp; echo 1 &gt; zoo1/data/myid</code><br><code>mkdir -p zoo2/data &amp;&amp; echo 2 &gt; zoo2/data/myid</code><br><code>mkdir -p zoo3/data &amp;&amp; echo 3 &gt; zoo3/data/myid</code>  </p></li><li><p>创建一个docker-compose.yml文件并编辑  </p><p><code>vim docker-compose.yml</code></p><p>文件内容如下:  </p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">version: &#39;3.7&#39;networks:  zk_cluster:    name: zk_cluster #为集群创建一个网络    driver: bridge#集群中的服务(3个节点)services:  zoo1:    image: zookeeper #所使用的镜像    restart: always #容器异常时是否重启    container_name: zoo1 #容器名称    ports: #与宿主机的端口映射      - 2181:2181      - 8001:8080    # zookeeper的配置    environment:      ZOO_MY_ID: 1      ZOO_SERVERS: server.1&#x3D;0.0.0.0:2888:3888;2181 server.2&#x3D;zoo2:2888:3888;2181 server.3&#x3D;zoo3:2888:3888;2181    #容器目录映射，此处使用了相对路径    volumes:      - .&#x2F;zoo1&#x2F;data:&#x2F;data      - .&#x2F;zoo1&#x2F;datalog:&#x2F;datalog    #所使用的网络    networks:      - zk_cluster  zoo2:    image: zookeeper    restart: always    container_name: zoo2    ports:      - 2182:2181      - 8002:8080    environment:      ZOO_MY_ID: 2      ZOO_SERVERS: server.1&#x3D;zoo1:2888:3888;2181 server.2&#x3D;0.0.0.0:2888:3888;2181 server.3&#x3D;zoo3:2888:3888;2181    volumes:      - .&#x2F;zoo2&#x2F;data:&#x2F;data      - .&#x2F;zoo2&#x2F;datalog:&#x2F;datalog    networks:      - zk_cluster  zoo3:    image: zookeeper    restart: always    container_name: zoo3    ports:      - 2183:2181      - 8003:8080    environment:      ZOO_MY_ID: 3      ZOO_SERVERS: server.1&#x3D;zoo1:2888:3888;2181 server.2&#x3D;zoo2:2888:3888;2181 server.3&#x3D;0.0.0.0:2888:3888;2181    volumes:      - .&#x2F;zoo3&#x2F;data:&#x2F;data      - .&#x2F;zoo3&#x2F;datalog:&#x2F;datalog    networks:      - zk_cluster</code></pre></li><li><p>使用docker-compose命令运行  </p><p><code>docker-compose --project-directory $PWD up -d</code></p></li><li><p>附：一键创建docker zookeeper集群并执行的脚本（该方案仅供参考和学习，生产环境需仔细斟酌，合理修改配置参数）</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#! &#x2F;bin&#x2F;bashmkdir -p zookeeper &amp;&amp; cd zookeeperDIR&#x3D;$PWDecho &quot;cd $DIR&quot;echo &quot;create docker compose config file&quot;CONF_YML&#x3D;&#39;docker-compose.yml&#39;touch $CONF_YMLecho &quot;version: &#39;3.7&#39;&quot; &gt; $CONF_YMLNET&#x3D;&#39;zk_cluster&#39;echo &#39;networks:&#39; &gt;&gt; $CONF_YMLecho &quot;  $NET:&quot; &gt;&gt; $CONF_YMLecho &quot;    name: $NET&quot; &gt;&gt; $CONF_YMLecho &quot;    driver: bridge&quot; &gt;&gt; $CONF_YML#节点个数，可以修改此值创建任意数量的容器节点let CLUSTER_COUNT&#x3D;3 IMAGE&#x3D;zookeeperecho &quot;services:&quot; &gt;&gt; $CONF_YMLfor i in &#96;seq 1 $CLUSTER_COUNT&#96;do    echo &quot;  zoo$i:&quot; &gt;&gt; $CONF_YML    echo &quot;    image: $IMAGE&quot; &gt;&gt; $CONF_YML    echo &quot;    restart: always&quot; &gt;&gt; $CONF_YML    echo &quot;    container_name: zoo$i&quot; &gt;&gt; $CONF_YML    echo &quot;    ports:&quot; &gt;&gt; $CONF_YML    echo &quot;      - $[2180 + $i]:2181&quot; &gt;&gt; $CONF_YML    echo &quot;      - $[8000 + $i]:8080&quot; &gt;&gt; $CONF_YML    echo &quot;    environment:&quot; &gt;&gt; $CONF_YML    echo &quot;      ZOO_MY_ID: $i&quot; &gt;&gt; $CONF_YML    zk_srv_conf&#x3D;&#39;&#39;    for j in &#96;seq 1 $CLUSTER_COUNT&#96;    do        if test $i !&#x3D; $j;        then            zk_srv_conf+&#x3D;&quot;server.$j&#x3D;zoo$j:2888:3888;2181&quot;        else            zk_srv_conf+&#x3D;&quot;server.$j&#x3D;0.0.0.0:2888:3888;2181&quot;        fi        if test $j !&#x3D; $CLUSTER_COUNT;        then            zk_srv_conf+&#x3D;&#39; &#39;;        fi    done    echo &quot;      ZOO_SERVERS: $zk_srv_conf&quot; &gt;&gt; $CONF_YML    echo &quot;    volumes:&quot; &gt;&gt; $CONF_YML    echo &quot;      - .&#x2F;zoo$i&#x2F;data:&#x2F;data&quot; &gt;&gt; $CONF_YML    echo &quot;      - .&#x2F;zoo$i&#x2F;datalog:&#x2F;datalog&quot; &gt;&gt; $CONF_YML    echo &quot;    networks:&quot; &gt;&gt; $CONF_YML    echo &quot;      - $NET&quot; &gt;&gt; $CONF_YML    mkdir -p zoo$i&#x2F;data    echo $i &gt; zoo$i&#x2F;data&#x2F;myiddone# docker pull zookeeperdocker-compose --project-directory $DIR up -d</code></pre></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>docker</tag>
      
      <tag>后端开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
