<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>数据结构与算法的实际应用（图）——有依赖的任务并行处理框架</title>
    <link href="/2021/12/05/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%EF%BC%88%E5%9B%BE%EF%BC%89%E2%80%94%E2%80%94%E6%9C%89%E4%BE%9D%E8%B5%96%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6/"/>
    <url>/2021/12/05/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%EF%BC%88%E5%9B%BE%EF%BC%89%E2%80%94%E2%80%94%E6%9C%89%E4%BE%9D%E8%B5%96%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>一开始接到一个技改需求，需要将我们系统的一些首页查询接口进行优化，合并为一个聚合接口提供给前端；最初与前端同学进行交流，认为这些首页查询接口没有依赖关系，因此对于我来说解决方案比较简单，直接将需要查询的接口进行并行处理即可：</p><p><img src="https://oscimg.oschina.net/oscnet/up-94bcd2805685f7f54111ef056462846b866.png"></p><p>其中每一个查询抽象成了一个Function，在子线程中调用apply方法执行。</p><p>但是在与前端同学联调时，发现其中一个接口的入参依赖另一个接口的结果，本想让前端给我传过来，但是这样的话又有一个接口会分离出去，影响首页加载速度，于是决定还是我后端想办法处理；如此一来，就需要解决查询时的前后依赖关系，一开始想了几种方案：</p><ul><li> 使用CountDownLatch进行等待</li><li>拿到前一个依赖任务的Future，调用get方法等待</li><li>有依赖的任务串行执行</li></ul><p>前两种方案大同小异，其实都是利用线程间的等待机制，待前置查询执行完成后，唤醒当前线程继续执行查询；第三种方案则简单粗暴，由于时间较紧，经过短暂思考后权利利弊还是决定用第三种方案，毕竟我现在只有两个子查询是有依赖的，这样做也是效率最高的办法；于是在生成查询的supplier中做了下手脚，将有依赖关系的Function通过andThen方法聚合为一个Function，便完成了需求，这样子查询顺序变成了（假设B依赖A）：</p><p><img src="https://oscimg.oschina.net/oscnet/up-7ec52bb218f4ac8773cb5726ac34e47e4d2.png"></p><p>至此，在需求上来说已经实现完成了，但是从技术角度来说不能算完整：假如新来了一个接口G，G也依赖于A，那么按照这种方案，ABG将会串行执行，然而BG之间没有依赖关系，它俩理应并行；又或者B依赖于A和C，则ABC会串行执行，然而AC应该并行才合理；再极端的例子，B依赖了ACEF，则整个聚合查询都退化为了单线程，显然更不合理。</p><p>所以，虽然现阶段这种方案没什么问题，但对于复杂的依赖关系处理是远不够完善的，因此我又思考了有没有更好的方式去处理，并且能够有一定的通用性。</p><h2 id="重构的并行任务处理方案"><a href="#重构的并行任务处理方案" class="headerlink" title="重构的并行任务处理方案"></a>重构的并行任务处理方案</h2><p>在此类需求中，其实比较重要的一点就是如何处理这些任务的依赖关系，而且尽可能的让他们并行处理，由此引入了一些图的应用。<br>在我的方案中，有以下几个概念：</p><ul><li>ExecutionContext：执行的上下文环境，所有子任务共用，用于处理数据交换和输入输出的问题，其实本质上是一个线程安全的Map。</li><li>ExecutionNode：任务节点，即一个子任务的抽象，内部包含：名称、依赖节点名称、可执行的Function</li><li>ExecutionGraph：整个任务流的执行图，包含所有的执行节点以及排序后的节点，任务流启动时将按照此类的描述执行。</li><li>ExecutionFlow：任务流的抽象，本质上也是一个Function，调用apply方法开始执行。</li><li>FlowConfiguration：任务执行的一些配置，包含前置Action、后置Action、线程执行器、超时时间等。<h3 id="图的生成"><a href="#图的生成" class="headerlink" title="图的生成"></a>图的生成</h3>ExecutionGraph是将任务的执行过程抽象成了一个有向无环图，在使用时，传入每个节点的定义及提前定义好的执行过程(Function)即可生成一个图。</li></ul><p>其中节点的定义规则为：<code>&#123;节点名称&#125;[&#123;依赖节点A&#125;,&#123;依赖节点B&#125;,...]</code></p><p>若无依赖，则没有方括号中的内容。<br>具体在构建执行图时，则相当于是对这个有向图做了一个简单的排序（拓扑排序）：</p><ol><li>首先将所有节点加入到remainMap，preMap为空</li><li>找到没有依赖的节点，作为第一层，并将这些节点从remainMap移除，加入到preMap中</li><li>遍历remainMap，找到所有依赖节点均已经在preMap中出现的节点，加入到preMap，并在remainMap移除，这些元素作为下一层</li><li>循环第3步，直至remainMap为空</li></ol><p>需要注意的是，第3步中，如果remainMap在筛选前后大小不变，则认为是出现了循环依赖，或者依赖了一个不存在的节点，即有向图中出现了环，应抛出异常，否则将陷入死循环。<br>核心代码如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;** * 构建执行图，实质上是对节点做排序 * * @param preNodes   已处理的节点 * @param remainNode 剩余节点 * @param levels     有序节点（结果集） *&#x2F;private static void buildGraph(Map&lt;String, ExecutionNode&gt; preNodes, Map&lt;String, ExecutionNode&gt; remainNode, List&lt;List&lt;ExecutionNode&gt;&gt; levels) &#123;    &#x2F;&#x2F; 若剩余节点为空，结束    if (remainNode.isEmpty()) &#123;        return;    &#125;    List&lt;String&gt; currentLevel;    &#x2F;&#x2F; 记录剩余节点个数    int remainSize &#x3D; remainNode.size();    if (preNodes.isEmpty()) &#123;        &#x2F;&#x2F; 若preNodes为空，则为第一层，找出无依赖的节点，即入度为0的节点        currentLevel &#x3D; remainNode.values()                .stream()                .filter(e -&gt; e.getDepend().length &#x3D;&#x3D; 0)                .map(ExecutionNode::getName)                .collect(Collectors.toList());        &#x2F;&#x2F; 若没有无依赖的节点，抛出异常        if (currentLevel.isEmpty()) &#123;            throw new IllegalStateException(&quot;could not found init node&quot;);        &#125;    &#125; else &#123;        &#x2F;&#x2F; 继续寻找前置节点已处理的节点，相当于继续寻找删除前面的节点依赖后，入度为0的节点        currentLevel &#x3D; remainNode.entrySet()                .stream()                .filter(e -&gt; Stream.of(e.getValue().getDepend()).allMatch(preNodes::containsKey))                .map(Map.Entry::getKey)                .collect(Collectors.toList());    &#125;    List&lt;ExecutionNode&gt; nodes &#x3D; new ArrayList&lt;&gt;(currentLevel.size());    &#x2F;&#x2F; currentLevel中为当前层级的节点，将其加入preNodes中记录起来，并从剩余节点中移除    for (String name : currentLevel) &#123;        nodes.add(remainNode.get(name));        preNodes.put(name, remainNode.remove(name));    &#125;    &#x2F;&#x2F; 若为剩余节点数量不变，说明图中有环形结构，或依赖了未定义的节点    if (remainNode.size() &#x3D;&#x3D; remainSize) &#123;        throw new IllegalStateException(&quot;there may be circular dependencies or dependency does not exist in your graph, exception nodes is: &quot; + remainNode.values());    &#125;    &#x2F;&#x2F; 放入结果集    levels.add(nodes);    &#x2F;&#x2F; 递归至下一层    buildGraph(preNodes, remainNode, levels);&#125;</code></pre><p>示例<br>简单介绍个例子，对于如下节点定义：</p><pre class="line-numbers language-js" data-language="js"><code class="language-js">ABCDE[A,B]F[A,E]G[C]H[B,C]I[G,H]J[I]K[D,E]L[E,H]</code></pre><p>则对应的图为：</p><p><img src="https://oscimg.oschina.net/oscnet/up-5074a3c6b4d37400bf48ff6264b4a8efdeb.png"></p><p>这样，所有的执行任务被分为了四层，每一层之间的任务是互不依赖的，同时下一层的执行依赖上一层。</p><h3 id="任务节点执行方案"><a href="#任务节点执行方案" class="headerlink" title="任务节点执行方案"></a>任务节点执行方案</h3><p>按照这种图的排序算法分割之后，剩下的就比较简单了，我能想到的有两种方式：</p><ol><li>每一层并行执行，全部完成之后执行下一层</li><li>利用线程间等待机制，等待前置任务执行完成通知当前线程</li></ol><p>第一种我觉得不算很好，例如上图，考虑如下情况：L的执行时间较长，大于I和J的执行时间总和，即 t(L)  &gt; t(I) + t(J)，则J完全没必要等待第三层全部执行完成，当I结束之后J就可以执行，若t(J) &gt; t(L)时，更是浪费了较多时间。<br>所以我采用了CompleteFuture的get方法阻塞有依赖的线程，只要前置任务执行完毕，当前任务就可以开始，而不必等待上一层所有的任务执行完毕。</p><p>方案如下：</p><ol><li><p>遍历每一层节点</p><p>   a. 对于当前层级的每一个节点，生成CompleteFuture，在构造Supplier时，先从futureMap获取所有的依赖节点的Future，循环调用其get方法，阻塞当前线程（若已经执行完成则直接返回结果，此处也可以使用allOf.get()方法代替）</p><p>  b. 将构造完成的CompleteFuture加入futureMap中</p></li><li><p>将futureMap所有的CompleteFuture取出来，使用allOf(…).get()方法等待全部执行完成。</p></li></ol><p>理论上每一个节点只要前置执行完成，它就会开始，但是实际上，由于线程池调度等原因，可能还会在阻塞队列中等待一段时间，但是站在系统资源分配的角度，可以接受其带来的影响。<br>实现的核心代码：（其实这种传入参数并生成新函数的方式还有一个高大上的名字：函数柯里化？=_= ）</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;** * 生成一个执行任务，返回的是一个新函数 * * @param executionGraph    执行任务图 * @param flowConfiguration 执行参数 * @return *&#x2F;static ExecutionFlow buildFlow(@NonNull ExecutionGraph executionGraph, @NonNull FlowConfiguration flowConfiguration) &#123;    SpelExpressionParser expressionParser &#x3D; new SpelExpressionParser();    return ctx -&gt; &#123;        long startTime &#x3D; System.currentTimeMillis();        List&lt;List&lt;ExecutionNode&gt;&gt; sortedNodes &#x3D; executionGraph.getSortedNodes();        Map&lt;String, CompletableFuture&lt;ExecutionContext&gt;&gt; futureMap &#x3D; new HashMap&lt;&gt;(16);        &#x2F;&#x2F; 按图序构建CompleteFuture        for (List&lt;ExecutionNode&gt; nodes : sortedNodes) &#123;            &#x2F;&#x2F; 同一层级之间的节点没有依赖，且依赖的CompletableFuture一定已经构建完成            for (ExecutionNode node : nodes) &#123;                String currNodeName &#x3D; node.getName();                CompletableFuture&lt;ExecutionContext&gt; future &#x3D; CompletableFuture.supplyAsync(() -&gt; &#123;                    try &#123;                        long t1 &#x3D; System.currentTimeMillis();                        &#x2F;&#x2F; 前置操作                        ofNullable(flowConfiguration.getPreAction()).ifPresent(c -&gt; c.accept(ctx));                        String[] depend &#x3D; node.getDepend();                        &#x2F;&#x2F; 遍历依赖节点，确保依赖节点已经执行完成                        for (String s : depend) &#123;                            try &#123;                                &#x2F;&#x2F; 阻塞等待                                futureMap.get(s).get();                                logger.info(&quot;current node [&#123;&#125;] waiting node [&#123;&#125;] done (&#123;&#125;ms)&quot;, currNodeName, s, System.currentTimeMillis() - t1);                            &#125; catch (InterruptedException | ExecutionException e) &#123;                                throw new IllegalStateException(&quot;current node [&quot; + currNodeName + &quot;] waiting node [&quot; + s + &quot;] failed&quot;, e);                            &#125;                        &#125;                        long t2 &#x3D; System.currentTimeMillis();                        logger.info(&quot;current node [&#123;&#125;] start&quot;, currNodeName);                        &#x2F;&#x2F; 前置表达式参数检查                        &#x2F;&#x2F;noinspection ConstantConditions                        if (Objects.nonNull(node.getBeforeCheckExpression()) &amp;&amp;                            !node.getBeforeCheckExpression().getValue(ctx.getCtx(), boolean.class)) &#123;                            throw new IllegalStateException(String.format(&quot;before check failed by expression [%s]&quot;                                    , node.getBeforeCheckExpression().getExpressionString()));                        &#125;                        &#x2F;&#x2F; 执行节点                        ExecutionContext ret &#x3D; node.getExecution().apply(ctx);                        &#x2F;&#x2F; 用于标识节点是否正确执行                        ctx.setVar(&quot;$&quot; + currNodeName + &quot;_success&quot;, true);                        &#x2F;&#x2F; 后置表达式参数检查                        &#x2F;&#x2F;noinspection ConstantConditions                        if (Objects.nonNull(node.getAfterCheckExpression()) &amp;&amp;                            !node.getAfterCheckExpression().getValue(ctx.getCtx(), boolean.class)) &#123;                            throw new IllegalStateException(String.format(&quot;after check failed by expression [%s]&quot;                                    , node.getAfterCheckExpression().getExpressionString()));                        &#125;                        long tl &#x3D; System.currentTimeMillis();                        logger.info(&quot;current node [&#123;&#125;] execute done (total: &#123;&#125;ms, execution: &#123;&#125;ms)&quot;, currNodeName, tl - t1, tl - t2);                        return ret;                    &#125; catch (Throwable e) &#123;                        logger.warn(&quot;current node [&#123;&#125;] execute failed: &#123;&#125;, skip exception&#x3D;&#123;&#125;&quot;, currNodeName, e.getMessage(), node.isSkipOnFail(), e);                        if (node.isSkipOnFail()) &#123;                            return ctx;                        &#125;                        throw e;                    &#125; finally &#123;                        &#x2F;&#x2F; 后置操作                        ofNullable(flowConfiguration.getFinalAction()).ifPresent(c -&gt; c.accept(ctx));                    &#125;                &#125;, flowConfiguration.getExecutor() &#x3D;&#x3D; null ? ForkJoinPool.commonPool() : flowConfiguration.getExecutor());                &#x2F;&#x2F; 将构建好的CompletableFuture放入Map                futureMap.put(node.getName(), future);            &#125;        &#125;        try &#123;            &#x2F;&#x2F; 组合所有的Future，等待所有节点行完毕            CompletableFuture&lt;Void&gt; completableFuture &#x3D; CompletableFuture.allOf(futureMap.values().toArray(new CompletableFuture[0]));            logger.info(&quot;waiting flow execution down, ttl&#x3D;&#123;&#125;&quot;, flowConfiguration.getTimeout());            if (flowConfiguration.getTimeout() &gt; 0) &#123;                completableFuture.get(flowConfiguration.getTimeout(), TimeUnit.SECONDS);            &#125; else &#123;                completableFuture.get();            &#125;            logger.info(&quot;execution flow success (&#123;&#125;ms)&quot;, System.currentTimeMillis() - startTime);            return ctx;        &#125; catch (InterruptedException | ExecutionException | TimeoutException e) &#123;            logger.warn(&quot;execution flow failed: &#123;&#125; (&#123;&#125;ms)&quot;, e.getMessage(), System.currentTimeMillis() - startTime);            throw new IllegalStateException(e);        &#125;    &#125;;&#125;</code></pre><h3 id="扩展功能"><a href="#扩展功能" class="headerlink" title="扩展功能"></a>扩展功能</h3><p>虽然已经完成了我们需要的功能，但是还不够完善，例如在实际执行每一个节点时，有的节点可以容忍失败，有的不可以，或者想在节点执行前后能检查一些参数是否满足要求，等等，所以我在这里又对节点定义的表达式做了一些增强，以此来支持一些额外的操作，同时也能在后续进行扩展：</p><p>在原有的基础上做一下改造：</p><p><code>&#123;节点名称&#125;[&#123;依赖节点A&#125;,&#123;依赖节点B&#125;, ...](&#123;扩展操作A名称&#125;(&#123;表达式&#125;), &#123;扩展操作A名称&#125;(&#123;表达式&#125;), ...)</code></p><h4 id="是否忽略失败"><a href="#是否忽略失败" class="headerlink" title="是否忽略失败"></a>是否忽略失败</h4><p>用于在当前节点执行发生异常的时候，是否将异常抛出，还是忽略这个异常</p><p>扩展名称：<code>skipOnFail</code></p><p>示例：<code>E[A,B](skipOnFail(true))</code></p><pre class="line-numbers language-java" data-language="java"><code class="language-java">......&#125; catch (Throwable e) &#123;  log.warn(&quot;current node [&#123;&#125;] execute failed: &#123;&#125;, skip exception&#x3D;&#123;&#125;&quot;, currNodeName, e.getMessage(), node.isSkipOnFail(), e);  if (node.isSkipOnFail()) &#123;    return ctx;  &#125;throw e;&#125; finally &#123;......</code></pre><h4 id="参数检查"><a href="#参数检查" class="headerlink" title="参数检查"></a>参数检查</h4><p>在针对有依赖的场景下，当前节点如何知道所依赖的节点是否执行正常呢，若有异常，我们可以通过异常得知执行失败，但是有时候不会有异常抛出（例如调用的子方法有拦截器的时候，有可能在拦截器中会处理掉异常信息），需要检查数据才能得知是否正确执行，如果把这个检查的操作由节点内部定义的函数来做，似乎是比较繁琐的，而且这一部分我觉得由框架来统一处理掉是比较合适的，我想到的方案是用表达式的形式来检查参数：<br>给每个节点增加一个前置和后置的表达式，表达式的返回值是boolean类型，若为false则抛出异常；</p><p>表达式结构：<code>&#123;节点名称&#125;[&#123;依赖节点A&#125;,&#123;依赖节点B&#125;, ...](beforeCheck(&#123;布尔表达式&#125;), afterCheck(&#123;布尔表达式&#125;))</code></p><p>示例：<code>J[I](beforeCheck([c] == 0 &amp;&amp; [k] == 9 &amp;&amp; [c] != null), afterCheck([a] == 1))</code> </p><p>表达式遵循SpringEL语法，解析时的上下文为ExecutionContext中的变量</p><h4 id="执行样例"><a href="#执行样例" class="headerlink" title="执行样例"></a>执行样例</h4><p>执行样例代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    Random random &#x3D; new Random();    &#x2F;&#x2F; 简单映射一个函数集合，随机暂停一段时间，模拟函数执行，部分函数里面做了一些简单的值的设定，模拟结果输出    Map&lt;String, Function&lt;ExecutionContext, ExecutionContext&gt;&gt; functionMap &#x3D; Arrays.stream(&quot;A,B,C,D,E,F,G,H,I,J,K,L&quot;.split(&quot;,&quot;)).collect(Collectors.toMap(            e -&gt; e,            e -&gt; ctx -&gt; &#123;                try &#123;                    int i &#x3D; 500 + 500 * random.nextInt(5);                    Thread.sleep(i);                    ctx.setVar(e, i);                    switch (e) &#123;                        case &quot;A&quot;:                            ctx.setVar(&quot;a&quot;, 1);                            break;                        case &quot;B&quot;:                            ctx.setVar(&quot;a&quot;, 0);                            break;                        case &quot;C&quot;:                            ctx.setVar(&quot;c&quot;, 3);                            break;                        case &quot;G&quot;:                            ctx.setVar(&quot;g&quot;, 9);                            ctx.setVar(&quot;a&quot;, 1);                            break;                    &#125;                &#125; catch (InterruptedException ignored) &#123;                &#125;                return ctx;            &#125;    ));    &#x2F;&#x2F; 构造一个执行图的定义    ExecutionGraph graph &#x3D; ExecutionGraph.createGraph(new ArrayList&lt;&gt;() &#123;&#123;        add(&quot;A&quot;);        add(&quot;B[A](beforeCheck([a] &#x3D;&#x3D; 1))&quot;);        add(&quot;C&quot;);        add(&quot;D&quot;);        add(&quot;E[A,B](beforeCheck([a]&#x3D;&#x3D;2); skipOnFail(true))&quot;); &#x2F;&#x2F; 该节点会发生异常，但是配置了跳过        add(&quot;F[A,E]&quot;);        add(&quot;G[C]&quot;);        add(&quot;H[B,C]&quot;);        add(&quot;I[G,H]&quot;);        add(&quot;J[I](beforeCheck( T(java.util.Arrays).asList(1,2,3).contains([c]) and [g] &#x3D;&#x3D; [c]*[c] and [c] !&#x3D; null); afterCheck([c] &gt;&#x3D; 1))&quot;);        add(&quot;K[D,E]&quot;);        add(&quot;L[E,H]&quot;);    &#125;&#125;, functionMap);    &#x2F;&#x2F; CompletableFuture默认使用的ForkJoinPool.commonPool，可以试下使用cachedThreadPool会有什么不一样？    &#x2F;&#x2F; ExecutorService executorService &#x3D; Executors.newCachedThreadPool();    ExecutionFlow executionFlow &#x3D; ExecutionFlow.buildFlow(graph);    executionFlow.apply(new ExecutionContext());&#125;</code></pre><p>执行日志：</p><pre class="line-numbers language-log" data-language="log"><code class="language-log">&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk-11.0.8.jdk&#x2F;Contents&#x2F;Home&#x2F;bin&#x2F;java -Dvisualvm.id&#x3D;76728482855487 -javaagent:&#x2F;Users&#x2F;windlively&#x2F;Library&#x2F;Application Support&#x2F;JetBrains&#x2F;Toolbox&#x2F;apps&#x2F;IDEA-U&#x2F;ch-0&#x2F;213.6461.79&#x2F;IntelliJ IDEA.app&#x2F;Contents&#x2F;lib&#x2F;idea_rt.jar&#x3D;55008:&#x2F;Users&#x2F;windlively&#x2F;Library&#x2F;Application Support&#x2F;JetBrains&#x2F;Toolbox&#x2F;apps&#x2F;IDEA-U&#x2F;ch-0&#x2F;213.6461.79&#x2F;IntelliJ IDEA.app&#x2F;Contents&#x2F;bin -Dfile.encoding&#x3D;UTF-8 -classpath &#x2F;Users&#x2F;windlively&#x2F;IdeaProjects&#x2F;leisure&#x2F;frame&#x2F;target&#x2F;classes:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;projectlombok&#x2F;lombok&#x2F;1.18.10&#x2F;lombok-1.18.10.jar:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-expression&#x2F;5.2.2.RELEASE&#x2F;spring-expression-5.2.2.RELEASE.jar:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-core&#x2F;5.2.2.RELEASE&#x2F;spring-core-5.2.2.RELEASE.jar:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;spring-jcl&#x2F;5.2.2.RELEASE&#x2F;spring-jcl-5.2.2.RELEASE.jar:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;springframework&#x2F;boot&#x2F;spring-boot-starter-logging&#x2F;2.2.2.RELEASE&#x2F;spring-boot-starter-logging-2.2.2.RELEASE.jar:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;ch&#x2F;qos&#x2F;logback&#x2F;logback-classic&#x2F;1.2.3&#x2F;logback-classic-1.2.3.jar:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;ch&#x2F;qos&#x2F;logback&#x2F;logback-core&#x2F;1.2.3&#x2F;logback-core-1.2.3.jar:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;slf4j&#x2F;slf4j-api&#x2F;1.7.29&#x2F;slf4j-api-1.7.29.jar:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;apache&#x2F;logging&#x2F;log4j&#x2F;log4j-to-slf4j&#x2F;2.12.1&#x2F;log4j-to-slf4j-2.12.1.jar:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;apache&#x2F;logging&#x2F;log4j&#x2F;log4j-api&#x2F;2.12.1&#x2F;log4j-api-2.12.1.jar:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;slf4j&#x2F;jul-to-slf4j&#x2F;1.7.29&#x2F;jul-to-slf4j-1.7.29.jar:&#x2F;Users&#x2F;windlively&#x2F;.m2&#x2F;repository&#x2F;org&#x2F;apache&#x2F;commons&#x2F;commons-lang3&#x2F;3.9&#x2F;commons-lang3-3.9.jar ink.windlively.frame.parallelprocessor.Main12:38:04.122 [main] INFO ink.windlively.frame.parallelprocessor.ExecutionGraph - start create graph, node definition: [A, B[A&lt;-](beforeCheck([a] &#x3D;&#x3D; 1)), C, D, E[A&lt;-,B&lt;-](beforeCheck([a]&#x3D;&#x3D;2),skipOnFail(true)), F[A&lt;-,E&lt;-], G[C&lt;-], H[B&lt;-,C&lt;-], I[G&lt;-,H&lt;-], J[I&lt;-](beforeCheck(T(java.util.Arrays).asList(1,2,3).contains([c]) and [g] &#x3D;&#x3D; [c]*[c] and [c] !&#x3D; null),afterCheck([c] &gt;&#x3D; 1)), K[D&lt;-,E&lt;-], L[E&lt;-,H&lt;-]]12:38:04.165 [main] INFO ink.windlively.frame.parallelprocessor.ExecutionGraph - build execution graph success: ACDB[A&lt;-](beforeCheck([a] &#x3D;&#x3D; 1))G[C&lt;-]E[A&lt;-,B&lt;-](beforeCheck([a]&#x3D;&#x3D;2),skipOnFail(true))H[B&lt;-,C&lt;-]F[A&lt;-,E&lt;-]I[G&lt;-,H&lt;-]K[D&lt;-,E&lt;-]L[E&lt;-,H&lt;-]J[I&lt;-](beforeCheck(T(java.util.Arrays).asList(1,2,3).contains([c]) and [g] &#x3D;&#x3D; [c]*[c] and [c] !&#x3D; null),afterCheck([c] &gt;&#x3D; 1))12:38:04.183 [main] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - waiting flow execution down, ttl&#x3D;012:38:04.183 [ForkJoinPool.commonPool-worker-5] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [C] start12:38:04.184 [ForkJoinPool.commonPool-worker-3] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [A] start12:38:04.183 [ForkJoinPool.commonPool-worker-9] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [D] start12:38:05.189 [ForkJoinPool.commonPool-worker-9] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [D] execute done (total: 1006ms, execution: 1006ms)12:38:05.687 [ForkJoinPool.commonPool-worker-3] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [A] execute done (total: 1504ms, execution: 1503ms)12:38:05.689 [ForkJoinPool.commonPool-worker-9] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [F] waiting node [A] done (498ms)12:38:05.689 [ForkJoinPool.commonPool-worker-7] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [B] waiting node [A] done (1506ms)12:38:05.689 [ForkJoinPool.commonPool-worker-15] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [E] waiting node [A] done (1505ms)12:38:05.690 [ForkJoinPool.commonPool-worker-7] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [B] start12:38:06.688 [ForkJoinPool.commonPool-worker-5] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [C] execute done (total: 2505ms, execution: 2505ms)12:38:06.689 [ForkJoinPool.commonPool-worker-11] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [G] waiting node [C] done (2505ms)12:38:06.689 [ForkJoinPool.commonPool-worker-11] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [G] start12:38:06.689 [ForkJoinPool.commonPool-worker-5] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [K] waiting node [D] done (0ms)12:38:07.247 [ForkJoinPool.commonPool-worker-7] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [B] execute done (total: 3064ms, execution: 1557ms)12:38:07.248 [ForkJoinPool.commonPool-worker-15] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [E] waiting node [B] done (3064ms)12:38:07.248 [ForkJoinPool.commonPool-worker-13] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [H] waiting node [B] done (3064ms)12:38:07.248 [ForkJoinPool.commonPool-worker-15] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [E] start12:38:07.248 [ForkJoinPool.commonPool-worker-13] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [H] waiting node [C] done (3064ms)12:38:07.248 [ForkJoinPool.commonPool-worker-13] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [H] start12:38:07.261 [ForkJoinPool.commonPool-worker-15] WARN ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [E] execute failed: before check failed by expression [[a]&#x3D;&#x3D;2], skip exception&#x3D;truejava.lang.IllegalStateException: before check failed by expression [[a]&#x3D;&#x3D;2]at ink.windlively.frame.parallelprocessor.ExecutionFlow.lambda$buildFlow$2(ExecutionFlow.java:81)at java.base&#x2F;java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)at java.base&#x2F;java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1692)at java.base&#x2F;java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)at java.base&#x2F;java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)at java.base&#x2F;java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)at java.base&#x2F;java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)at java.base&#x2F;java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)12:38:07.262 [ForkJoinPool.commonPool-worker-9] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [F] waiting node [E] done (2071ms)12:38:07.262 [ForkJoinPool.commonPool-worker-9] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [F] start12:38:07.262 [ForkJoinPool.commonPool-worker-5] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [K] waiting node [E] done (573ms)12:38:07.262 [ForkJoinPool.commonPool-worker-7] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [L] waiting node [E] done (14ms)12:38:07.262 [ForkJoinPool.commonPool-worker-5] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [K] start12:38:07.767 [ForkJoinPool.commonPool-worker-9] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [F] execute done (total: 2576ms, execution: 505ms)12:38:08.194 [ForkJoinPool.commonPool-worker-11] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [G] execute done (total: 4010ms, execution: 1505ms)12:38:08.195 [ForkJoinPool.commonPool-worker-3] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [I] waiting node [G] done (2506ms)12:38:09.266 [ForkJoinPool.commonPool-worker-5] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [K] execute done (total: 2577ms, execution: 2004ms)12:38:09.749 [ForkJoinPool.commonPool-worker-13] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [H] execute done (total: 5565ms, execution: 2501ms)12:38:09.750 [ForkJoinPool.commonPool-worker-7] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [L] waiting node [H] done (2502ms)12:38:09.750 [ForkJoinPool.commonPool-worker-3] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [I] waiting node [H] done (4062ms)12:38:09.751 [ForkJoinPool.commonPool-worker-7] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [L] start12:38:09.751 [ForkJoinPool.commonPool-worker-3] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [I] start12:38:10.753 [ForkJoinPool.commonPool-worker-7] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [L] execute done (total: 3505ms, execution: 1002ms)12:38:11.752 [ForkJoinPool.commonPool-worker-3] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [I] execute done (total: 6064ms, execution: 2001ms)12:38:11.753 [ForkJoinPool.commonPool-worker-15] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [J] waiting node [I] done (4491ms)12:38:11.753 [ForkJoinPool.commonPool-worker-15] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [J] start12:38:12.301 [ForkJoinPool.commonPool-worker-15] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - current node [J] execute done (total: 5039ms, execution: 548ms)12:38:12.301 [main] INFO ink.windlively.frame.parallelprocessor.ExecutionFlow - execution flow success (8130ms)进程已结束,退出代码0</code></pre><h4 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h4><p>在引入SpringEL表达式之后，其扩展性已经非常强了，Spring表达式支持Java的许多语法、Spring Bean的调用、方法调用等，例如可以仅用配置表达式的方式，在表达式中通过Bean调用的方式定义任务执行过程，并自动设置出入参，配置出一个任务流程，而无需再在代码中预先定义好functionMap。</p><h4 id="代码地址"><a href="#代码地址" class="headerlink" title="代码地址"></a>代码地址</h4><p>GitHub：<a href="https://github.com/windlively/leisure/tree/master/frame/src/main/java/ink/windlively/frame/parallelprocessor">https://github.com/windlively/leisure/tree/master/frame/src/main/java/ink/windlively/frame/parallelprocessor</a></p><p>Gitee：<a href="https://gitee.com/windlively/leisure/tree/master/frame/src/main/java/ink/windlively/frame/parallelprocessor">https://gitee.com/windlively/leisure/tree/master/frame/src/main/java/ink/windlively/frame/parallelprocessor</a></p>]]></content>
    
    
    <categories>
      
      <category>数据结构与算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构与算法</tag>
      
      <tag>图</tag>
      
      <tag>拓扑排序</tag>
      
      <tag>多线程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据结构与算法的实际应用——根据表关系构建SQL语句</title>
    <link href="/2021/03/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E2%80%94%E2%80%94%E6%A0%B9%E6%8D%AE%E8%A1%A8%E5%85%B3%E7%B3%BB%E6%9E%84%E5%BB%BASQL%E8%AF%AD%E5%8F%A5/"/>
    <url>/2021/03/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E2%80%94%E2%80%94%E6%A0%B9%E6%8D%AE%E8%A1%A8%E5%85%B3%E7%B3%BB%E6%9E%84%E5%BB%BASQL%E8%AF%AD%E5%8F%A5/</url>
    
    <content type="html"><![CDATA[<h1 id="数据结构与算法的实际应用——根据表关系构建SQL语句"><a href="#数据结构与算法的实际应用——根据表关系构建SQL语句" class="headerlink" title="数据结构与算法的实际应用——根据表关系构建SQL语句"></a>数据结构与算法的实际应用——根据表关系构建SQL语句</h1><h2 id="背景需求"><a href="#背景需求" class="headerlink" title="背景需求"></a>背景需求</h2><p>最近在项目中有一个场景，根据前端可视化模式传入的参数构建一组SQL语句，应用在Spark Streaming应用的数据同步中。这其实是一个已有的功能，但是发现原先的代码实现发现有较严重的问题，导致该功能在有关联查询时不可用，我经过调研之后决定重新实现。</p><p>这些SQL由普通的Lookup SQL和Spark SQL组成，Lookup SQL用于查询关联数据，SparkSQL则用于输出结果，核心问题在于如何合理组织这些表的关联关系。</p><p>PS：实现代码为Scala语言。</p><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>其中前端传入的参数为</p><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">case class UpdateTask(                      @BeanProperty id: Option[Long],                      @BeanProperty taskName: Option[String],                      @BeanProperty taskDesc: Option[String],                      @BeanProperty sourceInstance: Option[String],                      @BeanProperty targetInstance: Option[Long],                      @BeanProperty eventInstance: Option[Long],                      @BeanProperty sourceTree: Option[Seq[Long]],                      @BeanProperty selectSourceTree: Option[Seq[Long]],                      @BeanProperty targetTree: Option[Long],                      @BeanProperty eventTable: Option[Long],                      @BeanProperty tableRelation: Option[Seq[TableRelation]],                      @BeanProperty filterCondition: Option[String],                      @BeanProperty targetCalculateTableName: Option[String],                      @BeanProperty targetCalculate: Option[Seq[TargetCalculate]],                      @BeanProperty sourceTableField: Option[Seq[TableColumnInfo]],                      @BeanProperty sqlType: Option[Int],                      @BeanProperty classicSql: Option[String],                      @BeanProperty sinkConfig: Option[String],                      @BeanProperty targetPrimaryKey: Option[Seq[String]]                     ) extends SimpleBaseEntity</code></pre><p>所需要用的参数为</p><ul><li><p><code>eventTable</code> : 触发表</p></li><li><p><code>tableRelation</code> : 表关联关系列表，其中<code>TableRelation</code> 的结构为</p>  <pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">case class TableRelation(@BeanProperty leftTableSelect: Long,                         @BeanProperty rightTableSelect: Long,                         @BeanProperty leftColumnSelect: String,                         @BeanProperty rightColumnSelect: String)</code></pre></li><li><p><code>targetCalculate</code> : 输出结果的计算表达式，其中 <code>TargetCalculate</code> 的结构为</p>  <pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">case class TargetCalculate(@BeanProperty columnName: String,                           @BeanProperty config: String)</code></pre></li><li><p><code>selectSourceTree</code> : 所用到的源表</p></li></ul><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>当没有关联关系的时候，比较简单，不在此讨论。当有多个关联关系时，应该先查询出被关联的表数据，再查询下一级的表，以此类推，实际场景下可能一般只有一两个表关联，但是毕竟还是需要考虑极端情况，原先的实现只考虑了简单的关联，复杂一点的关联则无法处理，经过一段时间思考后，决定基于树这种数据结构去实现此功能。</p><p>假设传入了如下一些表关系，并且A表为源表（触发表）：</p><pre class="line-numbers language-none"><code class="language-none">A &lt;-&gt; BA &lt;-&gt; CA &lt;-&gt; DB &lt;-&gt; EB &lt;-&gt; FE &lt;-&gt; GC &lt;-&gt; HC &lt;-&gt; I</code></pre><p>则经过处理后，可以生成如下一个树</p><pre class="line-numbers language-none"><code class="language-none">             --&gt; E &lt;--&gt; G    --&gt; B &lt;--|    |        --&gt; F    |A &lt;----&gt; D    |    |        --&gt; H    --&gt; C &lt;--|             --&gt; I</code></pre><p>在此需要说明，不需要考虑左右顺序问题，例如 A &lt;-&gt; B 等价于 B &lt;-&gt; A，在后面对此问题会有说明。</p><p>当传入了多个相同的表关联关系时，需要做一个聚合，因为前端的参数中，每一个关联关系只包含一组关联字段，所以当有多个关联字段时，就传入了多个相同的关联关系，但是关联字段不同。</p><p>得到这个树形关系后，也同时得到了表之间的依赖关系，但是还有一个前提， 每个表只能依赖一个表，假设如下关系：</p><pre class="line-numbers language-none"><code class="language-none">             --&gt; E &lt;--&gt; G    --&gt; B &lt;--|    |        --&gt; F    |A &lt;----&gt; D    |    |        --&gt; H    --&gt; G &lt;--|             --&gt; I</code></pre><p>此时，G表既可以由A得到，又可以由E得到，假设从A表得到G表，那么从G表又可以得到E表……产生了歧义，并由此产生一个了有环图。但是我们需求中目前没有这种关联关系（因为前端配置页面中，没有标识关联的方向性，即目前可视化模式传入的关联关系都是双向，对于一组关系，既可以从A得到B，也可以从B得到A，也就是前面的：A &lt;-&gt; B 等价于 B &lt;-&gt; A），所以不考虑这种情况，出现时给予报错，提示依赖关系产生了环。如果有方向性的话，我们生成树的算法会更简单一些，直接DFS即可，但是对于重复出现的表，需要做额外处理，例如给重复表起别名，保证结果集不会出现重名字段，否则Spark在处理过程中会产生异常。</p><p>在得到这个依赖关系后，后面的事情就好办了，我们从根节点开始层序遍历（也即为BFS广度优先遍历），逐层构建SQL语句，也可以采用树的先序遍历（DFS深度优先），只要保证子节点在父节点后面遍历即可，保证后面的SQL语句用到的关联参数在前面的SQL中已经查询到。</p><p>在生成SQL的过程中，为了避免不同库表有相同的表名或字段名，除了最后一句输出结果的Spark SQL，前面的SQL查询字段均需要起一个别名，在此沿用之前旧代码的方案：使用 <code>&#123;字段名&#125; AS &#123;库名&#125;__&#123;表名&#125;__&#123;字段名&#125;</code> 的形式保证字段名不会重复</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="数据结构类定义"><a href="#数据结构类定义" class="headerlink" title="数据结构类定义"></a>数据结构类定义</h3><p>有了思路之后，便开始着手实现此功能，首先定义一个树节点的case类：</p><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">case class TableRelationTreeNode(value: Long, &#x2F;&#x2F; 当前节点的表id                                 parentRelation: LinkRelation, &#x2F;&#x2F; 和父节点的关联关系                                 childs: ListBuffer[TableRelationTreeNode]  &#x2F;&#x2F; 子节点                                 )</code></pre><p><code>LinkRelation</code> 描述了两个表之间的关联关系，是对前端传入的<code>TableRelation</code>聚合后的结果：</p><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">case class LinkRelation(leftTable: Long, &#x2F;&#x2F; 左表id                        rightTable: Long, &#x2F;&#x2F; 右表id                        linkFields: Seq[(String, String)] &#x2F;&#x2F; 关联字段, 元组的两个参数分别为左表字段、右表字段                        )</code></pre><h3 id="关联关系树的构建"><a href="#关联关系树的构建" class="headerlink" title="关联关系树的构建"></a>关联关系树的构建</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">&#x2F;** * @param parentNode      父节点 * @param remainRelations 剩余关联关系 *&#x2F;def buildRelationTree(parentNode: TableRelationTreeNode, remainRelations: ListBuffer[LinkRelation]): Any &#x3D; &#123;  if (remainRelations.isEmpty) return  val parentTableId &#x3D; parentNode.value;  &#x2F;&#x2F; 找出关联关系中包含父节点的表id  val childRelation &#x3D; remainRelations.filter(e &#x3D;&gt; e.leftTable &#x3D;&#x3D; parentTableId || e.rightTable &#x3D;&#x3D; parentTableId)  if (childRelation.isEmpty) return  &#x2F;&#x2F; 将关联关系中父节点的关联信息置于左侧，方便后续操作  childRelation    .map(e &#x3D;&gt; if (e.leftTable &#x3D;&#x3D; parentTableId) e else LinkRelation(e.rightTable, e.leftTable, e.linkFields.map(e &#x3D;&gt; (e._2, e._1))))    .foreach&#123;e &#x3D;&gt; parentNode.childs +&#x3D; TableRelationTreeNode(e.rightTable, e, new ListBuffer())&#125;&#x2F;&#x2F; 移除已经使用过的关联关系  remainRelations --&#x3D; childRelation  parentNode.childs foreach &#123;buildRelationTree(_, remainRelations)&#125;&#125;</code></pre><h3 id="SQL语句生成的核心代码"><a href="#SQL语句生成的核心代码" class="headerlink" title="SQL语句生成的核心代码"></a>SQL语句生成的核心代码</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">def buildTransSQL(task: UpdateTask): Seq[String] &#x3D; &#123;&#x2F;&#x2F; 存储所有用到的表（namespace为表的信息）    val namespacesRef &#x3D; mutable.HashMap[Long, Namespace]()    task.selectSourceTree.get.foreach(i &#x3D;&gt; namespacesRef +&#x3D; (kv &#x3D; (i, Await.result(namespaceDal.findById(i), minTimeOut).get)))    val targetTableId &#x3D; task.targetTree.get&#x2F;&#x2F; 目标表    val targetNamespace &#x3D; Await.result(namespaceDal.findById(targetTableId), minTimeOut).head    namespacesRef.put(targetTableId, targetNamespace)    val eventTableId &#x3D; task.eventTable.get&#x2F;&#x2F; 事件表（源&#x2F;触发表）    val eventNamespace &#x3D; namespacesRef(eventTableId)&#x2F;&#x2F; 没有计算逻辑，当做镜像同步，直接SELECT * ...    if (task.targetCalculate.isEmpty)      return Seq.newBuilder.+&#x3D;(s&quot;spark_sql&#x3D; select * from $&#123;eventNamespace.nsTable&#125;;&quot;).result()    val transSqlList &#x3D; new ListBuffer[String]    &#x2F;&#x2F; 先将触发表的所有字段查询出来    transSqlList +&#x3D; s&quot;spark_sql&#x3D; select $&#123;      sourceDataDal.getSourceDataTableField(eventTableId).filter(_ !&#x3D; &quot;ums_active_&quot;).map(e &#x3D;&gt; &#123;        s&quot;$e AS $&#123;eventNamespace.nsDatabase&#125;__$&#123;eventNamespace.nsTable&#125;__$e&quot;      &#125;).mkString(&quot;, &quot;)    &#125; from $&#123;eventNamespace.nsTable&#125;&quot;    if (task.getTableRelation.nonEmpty) &#123;      val remainLinks &#x3D; new ListBuffer[LinkRelation]()      &#x2F;&#x2F; 聚合重复的表关联关系      task.getTableRelation.getOrElse(Seq.empty)        .map(e &#x3D;&gt; &#123;          if (e.leftTableSelect &gt; e.rightTableSelect) &#123;            TableRelation(              leftTableSelect &#x3D; e.rightTableSelect,              rightTableSelect &#x3D; e.leftTableSelect,              leftColumnSelect &#x3D; e.rightColumnSelect,              rightColumnSelect &#x3D; e.leftColumnSelect            )          &#125; else e        &#125;)        .groupBy(e &#x3D;&gt; s&quot;$&#123;e.leftTableSelect&#125;-$&#123;e.rightTableSelect&#125;&quot;)        .map(e &#x3D;&gt; &#123;          LinkRelation(            leftTable &#x3D; e._2.head.leftTableSelect,            rightTable &#x3D; e._2.head.rightTableSelect,            linkFields &#x3D; e._2.map(e &#x3D;&gt; (e.leftColumnSelect, e.rightColumnSelect))          )        &#125;) foreach &#123;        remainLinks +&#x3D; _      &#125;&#x2F;&#x2F; 根结点      val rootTreeNode &#x3D; TableRelationTreeNode(        eventTableId,        null,        new ListBuffer[TableRelationTreeNode]      )      &#x2F;&#x2F; 构建关系树      buildRelationTree(rootTreeNode, remainLinks)      &#x2F;&#x2F; 如果有剩余的关系未被使用，则说明有无法连接到根节点的关系，抛出异常      if (remainLinks.nonEmpty) &#123;        throw new IllegalArgumentException(s&quot;游离的关联关系：$&#123;          remainLinks.map(e &#x3D;&gt; &#123;            val leftNs &#x3D; namespacesRef(e.leftTable)            val rightNs &#x3D; namespacesRef(e.rightTable)            s&quot;$&#123;leftNs.nsDatabase&#125;.$&#123;leftNs.nsTable&#125; &lt;-&gt; $&#123;rightNs.nsDatabase&#125;.$&#123;rightNs.nsTable&#125;&quot;          &#125;).toString        &#125;\n无法与根节点($&#123;eventNamespace.nsDatabase&#125;.$&#123;eventNamespace.nsTable&#125;)建立关系&quot;)      &#125;      val queue &#x3D; new mutable.Queue[TableRelationTreeNode]      queue.enqueue(rootTreeNode)      &#x2F;&#x2F; 广度优先遍历，逐层构建SQL语句，保证依赖顺序      while (queue.nonEmpty) &#123;        val len &#x3D; queue.size        for (i &lt;- 0 until len) &#123;          val node &#x3D; queue.dequeue          if (node.value !&#x3D; eventTableId) &#123;            val relation &#x3D; node.parentRelation            &#x2F;&#x2F; 当前节点表            val curNs &#x3D; namespacesRef(node.value)            &#x2F;&#x2F; 父节点表            val parNs &#x3D; namespacesRef(relation.leftTable)            val curTableName &#x3D; s&quot;$&#123;curNs.nsDatabase&#125;.$&#123;curNs.nsTable&#125;&quot;            val fields &#x3D; sourceDataDal.getSourceDataTableField(node.value)            val fieldAliasPrefix &#x3D; s&quot;$&#123;curNs.nsDatabase&#125;__$&#123;curNs.nsTable&#125;__&quot;            &#x2F;&#x2F; 构建lookup SQL            transSqlList +&#x3D; s&quot;pushdown_sql left join with $&#123;curNs.nsSys&#125;.$&#123;curNs.nsInstance&#125;.$&#123;curNs.nsDatabase&#125;&#x3D;select $&#123;              fields.map(f &#x3D;&gt; s&quot;$f as $fieldAliasPrefix$f&quot;).mkString(&quot;, &quot;)            &#125; from $curTableName where ($&#123;              relation.linkFields.map(_._2.replaceAll(&quot;.*\\.&quot;, &quot;&quot;)).mkString(&quot;,&quot;)            &#125;) in ($&#123;relation.linkFields.map(_._1.replace(&quot;.&quot;,&quot;__&quot;)).map(e &#x3D;&gt; &quot;$&#123;&quot; + e + &quot;&#125;&quot;).mkString(&quot;,&quot;)&#125;)&quot;;          &#125;          node.childs foreach &#123; queue.enqueue(_) &#125;        &#125;      &#125;    &#125;    &#x2F;&#x2F; 输出最终结果集的SparkSQL    transSqlList +&#x3D; s&quot;spark_sql&#x3D; select $&#123;      task.targetCalculate.get.map &#123; e &#x3D;&gt;        s&quot;$&#123;e.config.replaceAll(&quot;(\\w+)\\.(\\w+)\\.(\\w+)&quot;, &quot;$1__$2__$3&quot;)&#125; as $&#123;e.columnName&#125;&quot;      &#125;.mkString(&quot;, &quot;)    &#125; from $&#123;eventNamespace.nsTable&#125; where $&#123;if (task.filterCondition.getOrElse(&quot;&quot;) &#x3D;&#x3D; &quot;&quot;) &quot;1&#x3D;1&quot; else task.filterCondition.get&#125;&quot;    transSqlList.toSeq  &#125;</code></pre><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>我新建了几张测试表，并使用小程序向库中随机生成了一些数据，然后又新建了一个目标表，以此来测试该功能，过程如下</p><h3 id="前端配置"><a href="#前端配置" class="headerlink" title="前端配置"></a>前端配置</h3><p>关联关系</p><p><img src="https://oscimg.oschina.net/oscnet/up-ad374c7f0532171add44d6e2141ace62855.png"></p><p>计算逻辑</p><p><img src="https://oscimg.oschina.net/oscnet/up-2767f6831520f8f011fed2511a43ca13c44.png"></p><p>抽象出的关联关系应为：</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">                                         ------&gt; customer_transaction                                         |customer &lt;---&gt; customer_account_info &lt;----                                         |                                         ------&gt; customer_seller_relation  &lt;-----&gt; seller_info</code></pre><h3 id="后台生成的SQL："><a href="#后台生成的SQL：" class="headerlink" title="后台生成的SQL："></a>后台生成的SQL：</h3><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">spark_sql &#x3D;select  address AS adp_mock_spr_mirror__customer__address,  company AS adp_mock_spr_mirror__customer__company,  gender AS adp_mock_spr_mirror__customer__gender,  id AS adp_mock_spr_mirror__customer__id,  id_card AS adp_mock_spr_mirror__customer__id_card,  mobile AS adp_mock_spr_mirror__customer__mobile,  real_name AS adp_mock_spr_mirror__customer__real_name,  ums_id_ AS adp_mock_spr_mirror__customer__ums_id_,  ums_op_ AS adp_mock_spr_mirror__customer__ums_op_,  ums_ts_ AS adp_mock_spr_mirror__customer__ums_ts_from  customer;pushdown_sql  left join with tidb.spr_ods_department.adp_mock_spr_mirror &#x3D;select  account_bank as adp_mock_spr_mirror__customer_account_info__account_bank,  account_level as adp_mock_spr_mirror__customer_account_info__account_level,  account_no as adp_mock_spr_mirror__customer_account_info__account_no,  customer_id as adp_mock_spr_mirror__customer_account_info__customer_id,  entry_time as adp_mock_spr_mirror__customer_account_info__entry_time,  id as adp_mock_spr_mirror__customer_account_info__id,  loc_seller as adp_mock_spr_mirror__customer_account_info__loc_seller,  risk_level as adp_mock_spr_mirror__customer_account_info__risk_level,  risk_test_date as adp_mock_spr_mirror__customer_account_info__risk_test_date,  ums_active_ as adp_mock_spr_mirror__customer_account_info__ums_active_,  ums_id_ as adp_mock_spr_mirror__customer_account_info__ums_id_,  ums_op_ as adp_mock_spr_mirror__customer_account_info__ums_op_,  ums_ts_ as adp_mock_spr_mirror__customer_account_info__ums_ts_from  adp_mock_spr_mirror.customer_account_infowhere  (id) in ($ &#123; adp_mock_spr_mirror__customer__id &#125;);pushdown_sql  left join with tidb.spr_ods_department.adp_mock_spr_mirror &#x3D;select  customer_id as adp_mock_spr_mirror__customer_seller_relation__customer_id,  id as adp_mock_spr_mirror__customer_seller_relation__id,  relation_type as adp_mock_spr_mirror__customer_seller_relation__relation_type,  seller_id as adp_mock_spr_mirror__customer_seller_relation__seller_id,  ums_active_ as adp_mock_spr_mirror__customer_seller_relation__ums_active_,  ums_id_ as adp_mock_spr_mirror__customer_seller_relation__ums_id_,  ums_op_ as adp_mock_spr_mirror__customer_seller_relation__ums_op_,  ums_ts_ as adp_mock_spr_mirror__customer_seller_relation__ums_ts_,  wechat_relation as adp_mock_spr_mirror__customer_seller_relation__wechat_relationfrom  adp_mock_spr_mirror.customer_seller_relationwhere  (customer_id) in (    $ &#123; adp_mock_spr_mirror__customer_account_info__id &#125;  );  pushdown_sql  left join with tidb.spr_ods_department.adp_mock_spr_mirror &#x3D;select  balance as adp_mock_spr_mirror__customer_transaction__balance,  borrow_loan as adp_mock_spr_mirror__customer_transaction__borrow_loan,  comment as adp_mock_spr_mirror__customer_transaction__comment,  customer_account_id as adp_mock_spr_mirror__customer_transaction__customer_account_id,  customer_id as adp_mock_spr_mirror__customer_transaction__customer_id,  deal_abstract_code as adp_mock_spr_mirror__customer_transaction__deal_abstract_code,  deal_account_type_code as adp_mock_spr_mirror__customer_transaction__deal_account_type_code,  deal_code as adp_mock_spr_mirror__customer_transaction__deal_code,  deal_partner_account as adp_mock_spr_mirror__customer_transaction__deal_partner_account,  deal_partner_name as adp_mock_spr_mirror__customer_transaction__deal_partner_name,  deal_partner_ogr_name as adp_mock_spr_mirror__customer_transaction__deal_partner_ogr_name,  deal_partner_org_num as adp_mock_spr_mirror__customer_transaction__deal_partner_org_num,  id as adp_mock_spr_mirror__customer_transaction__id,  subject as adp_mock_spr_mirror__customer_transaction__subject,  transaction_amount as adp_mock_spr_mirror__customer_transaction__transaction_amount,  transaction_time as adp_mock_spr_mirror__customer_transaction__transaction_time,  ums_active_ as adp_mock_spr_mirror__customer_transaction__ums_active_,  ums_id_ as adp_mock_spr_mirror__customer_transaction__ums_id_,  ums_op_ as adp_mock_spr_mirror__customer_transaction__ums_op_,  ums_ts_ as adp_mock_spr_mirror__customer_transaction__ums_ts_from  adp_mock_spr_mirror.customer_transactionwhere  (customer_id, customer_account_id) in (    $ &#123; adp_mock_spr_mirror__customer_account_info__id &#125;,    $ &#123; adp_mock_spr_mirror__customer_account_info__account_no &#125;  );pushdown_sql  left join with tidb.spr_ods_department.adp_mock_spr_mirror &#x3D;select  current_bank as adp_mock_spr_mirror__seller_info__current_bank,  department_id as adp_mock_spr_mirror__seller_info__department_id,  email as adp_mock_spr_mirror__seller_info__email,  entry_time as adp_mock_spr_mirror__seller_info__entry_time,  id as adp_mock_spr_mirror__seller_info__id,  id_card as adp_mock_spr_mirror__seller_info__id_card,  leader_id as adp_mock_spr_mirror__seller_info__leader_id,  mobile as adp_mock_spr_mirror__seller_info__mobile,  name as adp_mock_spr_mirror__seller_info__name,  position as adp_mock_spr_mirror__seller_info__position,  tenant_id as adp_mock_spr_mirror__seller_info__tenant_id,  ums_active_ as adp_mock_spr_mirror__seller_info__ums_active_,  ums_id_ as adp_mock_spr_mirror__seller_info__ums_id_,  ums_op_ as adp_mock_spr_mirror__seller_info__ums_op_,  ums_ts_ as adp_mock_spr_mirror__seller_info__ums_ts_from  adp_mock_spr_mirror.seller_infowhere  (id) in (    $ &#123; adp_mock_spr_mirror__customer_seller_relation__seller_id &#125;  );spark_sql &#x3D;select  adp_mock_spr_mirror__customer_account_info__id as id,  adp_mock_spr_mirror__customer__real_name as name,  IF(adp_mock_spr_mirror__customer__gender &#x3D; 0, &quot;0&quot;, &quot;1&quot;) as sex,  adp_mock_spr_mirror__seller_info__department_id as age,  adp_mock_spr_mirror__customer__mobile as phone,  adp_mock_spr_mirror__seller_info__entry_time as born,  adp_mock_spr_mirror__customer__address as address,  IF(    adp_mock_spr_mirror__customer_transaction__borrow_loan &#x3D; 1,    &quot;1&quot;,    &quot;0&quot;  ) as married,  NOW() as create_time,  NOW() as update_time,  &#39;P&#39; as zodiacfrom  customerwhere  1 &#x3D; 1;</code></pre><h3 id="同步结果"><a href="#同步结果" class="headerlink" title="同步结果"></a>同步结果</h3><p><img src="https://oscimg.oschina.net/oscnet/up-0b722f692e6727e053b48e3a97e6eac2c9d.png"></p><p>从Spark后台日志中可以看到，数据已经正常插入目标表。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>以上是树和BFS在实际开发场景中的一个应用，代码实现其实较为简单，重点是实现的思路，当然解决问题的方法并不是唯一的，在此问题中，也可以在构建树的过程中直接构建SQL语句，省去后续的BFS过程，但是我考虑到后续可能增加的需求，还是将此处拆成了两步，方便后续在扩展，根据实际场景选择方案即可。另外，计算逻辑中缺少字段强校验，当用户输入错误字段时在运行期间才能察觉到，考虑后期再增加此功能。</p><p>有不对的地方欢迎指正，希望本文对大家有所帮助。</p>]]></content>
    
    
    <categories>
      
      <category>数据结构与算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构与算法</tag>
      
      <tag>Spark SQL</tag>
      
      <tag>BFS</tag>
      
      <tag>scala</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>canal在docker下的搭建(配合canal-admin)</title>
    <link href="/2021/03/07/canal%E5%9C%A8docker%E4%B8%8B%E7%9A%84%E6%90%AD%E5%BB%BA-%E9%85%8D%E5%90%88canal-admin/"/>
    <url>/2021/03/07/canal%E5%9C%A8docker%E4%B8%8B%E7%9A%84%E6%90%AD%E5%BB%BA-%E9%85%8D%E5%90%88canal-admin/</url>
    
    <content type="html"><![CDATA[<h2 id="MySQL配置"><a href="#MySQL配置" class="headerlink" title="MySQL配置"></a>MySQL配置</h2><ul><li><p>对于自建 MySQL , 需要先开启 Binlog 写入功能，配置 binlog-format 为 ROW 模式，my.cnf 中配置如下</p>  <pre class="line-numbers language-none"><code class="language-none">[mysqld]log-bin&#x3D;mysql-bin # 开启 binlogbinlog-format&#x3D;ROW # 选择 ROW 模式server_id&#x3D;1 # 配置 MySQL replaction 需要定义，不要和 canal 的 slaveId 重复</code></pre><ul><li>注意：针对阿里云 RDS for MySQL , 默认打开了 binlog , 并且账号默认具有 binlog dump 权限 , 不需要任何权限或者 binlog 设置,可以直接跳过这一步</li></ul></li><li><p>授权 canal 链接 MySQL 账号具有作为 MySQL slave 的权限, 如果已有账户可直接 grant</p>  <pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">CREATE USER canal IDENTIFIED BY &#39;canal&#39;;GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#39;canal&#39;@&#39;%&#39;;-- GRANT ALL PRIVILEGES ON *.* TO &#39;canal&#39;@&#39;%&#39; ;FLUSH PRIVILEGES;</code></pre><p>  PS：我本地使用的MySQL 8.0，实测不用修改此配置也可正常使用</p></li></ul><h2 id="canal容器的创建与启动"><a href="#canal容器的创建与启动" class="headerlink" title="canal容器的创建与启动"></a>canal容器的创建与启动</h2><ol><li><p>拉取所需要的镜像</p> <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"># canal-admin🍓 ➜  ~ docker pull canal&#x2F;canal-admin# canal-server🍓 ➜  ~ docker pull canal&#x2F;canal-server</code></pre></li><li><p>下载canal-admin的运行脚本</p> <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">wget https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;alibaba&#x2F;canal&#x2F;master&#x2F;docker&#x2F;run_admin.sh</code></pre></li><li><p>启动并运行canal-admin</p> <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"># 以8089端口启动canal-adminsh run_admin.sh -e server.port&#x3D;8089 \         -e canal.adminUser&#x3D;admin \         -e canal.adminPasswd&#x3D;admin# 指定外部的mysql作为admin的库sh run_admin.sh \    -e server.port&#x3D;8089 \    -e spring.datasource.address&#x3D;host.docker.internal \    -e spring.datasource.database&#x3D;xxx \    -e spring.datasource.username&#x3D;root \    -e spring.datasource.password&#x3D;xxx</code></pre></li><li><p>打开浏览器，访问<a href="http://localhost:8089/">http://localhost:8089</a>，默认账号密码为admin/123456，首页如图所示</p><p> <img src="https://oscimg.oschina.net/oscnet/up-9fe870724e9ad4581f18e9a4be241c1fcaf.png"></p></li><li><p>下载canal-server的运行脚本</p> <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">wget https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;alibaba&#x2F;canal&#x2F;master&#x2F;docker&#x2F;run.sh</code></pre></li><li><p>admin管理模式启动并运行canal-server，本案例以单机模式为例，集群模式需手动创建一个集群，并且提供zookeeper地址，然后启动参数加上集群名称即可，配置与单机模式一样，只不过一个集群共用一个server配置</p> <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"># 以单机模式启动run.sh -e canal.admin.manager&#x3D;127.0.0.1:8089 \         -e canal.admin.port&#x3D;11110 \         -e canal.admin.user&#x3D;admin \         -e canal.admin.passwd&#x3D;4ACFE3202A5FF5CF467898FC58AAB1D615029441# 集群模式启动，自动加入test集群# 如果使用集群模式，需要在canal-admin管理页面创建集群，同一个集群使用相同的配置文件run.sh -e canal.admin.manager&#x3D;127.0.0.1:8089 \         -e canal.admin.port&#x3D;11110 \         -e canal.admin.user&#x3D;admin \         -e canal.admin.passwd&#x3D;4ACFE3202A5FF5CF467898FC58AAB1D615029441          -e canal.admin.register.cluster&#x3D;test</code></pre><p> PS：在docker容器中，若非主机网络模式，127.0.0.1并非为主机的地址，Mac版可使用<strong>host.docker.internal</strong>访问到主机，Linux暂不支持，需要手动在容器中查询到主机的ip，替换掉上面的127.0.0.1</p></li><li><p>启动成功后，刷新admin页面的server列表，会出现刚刚启动的canal-server：</p><p> <img src="https://oscimg.oschina.net/oscnet/up-4aadd69d740610d80bfaf9c01b2047db717.png"></p><p> 至此，canal的创建与启动已经完成，在管理页面进行配置操作即可</p></li></ol><h2 id="canal核心配置介绍"><a href="#canal核心配置介绍" class="headerlink" title="canal核心配置介绍"></a>canal核心配置介绍</h2><p>canal的配置分为server配置和instance配置，一个server可包含多个instance，部分配置</p><h3 id="server配置"><a href="#server配置" class="headerlink" title="server配置"></a>server配置</h3><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties"># 服务模式，支持tcp, kafka, rocketMQ, rabbitMQcanal.serverMode &#x3D; kafka### kafka配置# 该值为false时，发送的消息为二进制压缩格式，需要客户端使用protobuf工具解析，为true时，发送json文本canal.mq.flatMessage &#x3D; true# kafka服务器地址kafka.bootstrap.servers &#x3D; host.docker.internal:9092</code></pre><h3 id="instance配置"><a href="#instance配置" class="headerlink" title="instance配置"></a>instance配置</h3><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties"># 监听的数据库地址canal.instance.master.address&#x3D;host.docker.internal:3306# 数据库的用户名canal.instance.dbUsername&#x3D;root# 数据库密码canal.instance.dbPassword&#x3D;123456# 表名过滤，正则表达式，($&#123;库名&#125;.$&#123;表名&#125;)canal.instance.filter.regex&#x3D;.+\\..+# kafka topic名称，所有的消息都将放入此topic# canal.mq.topic&#x3D;example# 根据库名可表名动态topiccanal.mq.dynamicTopic&#x3D;.+\\..+# 发送分区canal.mq.partition&#x3D;0# 分区数量#canal.mq.partitionsNum&#x3D;3# 根据库名和表名计算出发送分区(Hash)，可控制同一个库&#x2F;表有序#canal.mq.partitionHash&#x3D;test.table:id^name,.*\\..*### 动态topic和partition的详细说明# canal.mq.dynamicTopic 表达式说明# canal 1.1.3版本之后, 支持配置格式：schema 或 schema.table，多个配置之间使用逗号或分号分隔# 例子1：test\\.test 指定匹配的单表，发送到以test_test为名字的topic上# 例子2：.*\\..* 匹配所有表，则每个表都会发送到各自表名的topic上# 例子3：test 指定匹配对应的库，一个库的所有表都会发送到库名的topic上# 例子4：test\\..* 指定匹配的表达式，针对匹配的表会发送到各自表名的topic上# 例子5：test,test1\\.test1，指定多个表达式，会将test库的表都发送到test的topic上，test1\\.test1的表发送到对应的test1_test1 topic上，其余的表发送到默认的canal.mq.topic值# 为满足更大的灵活性，允许对匹配条件的规则指定发送的topic名字，配置格式：topicName:schema 或 topicName:schema.table# 例子1: test:test\\.test 指定匹配的单表，发送到以test为名字的topic上# 例子2: test:.*\\..* 匹配所有表，因为有指定topic，则每个表都会发送到test的topic下# 例子3: test:test 指定匹配对应的库，一个库的所有表都会发送到test的topic下# 例子4：testA:test\\..* 指定匹配的表达式，针对匹配的表会发送到testA的topic下# 例子5：test0:test,test1:test1\\.test1，指定多个表达式，会将test库的表都发送到test0的topic下，test1\\.test1的表发送到对应的test1的topic下，其余的表发送到默认的canal.mq.topic值# 大家可以结合自己的业务需求，设置匹配规则，建议MQ开启自动创建topic的能力# canal.mq.partitionHash 表达式说明# canal 1.1.3版本之后, 支持配置格式：schema.table:pk1^pk2，多个配置之间使用逗号分隔# 例子1：test\\.test:pk1^pk2 指定匹配的单表，对应的hash字段为pk1 + pk2# 例子2：.*\\..*:id 正则匹配，指定所有正则匹配的表对应的hash字段为id# 例子3：.*\\..*:$pk$ 正则匹配，指定所有正则匹配的表对应的hash字段为表主键(自动查找)# 例子4: 匹配规则啥都不写，则默认发到0这个partition上# 例子5：.*\\..* ，不指定pk信息的正则匹配，将所有正则匹配的表,对应的hash字段为表名# 按表hash: 一张表的所有数据可以发到同一个分区，不同表之间会做散列 (会有热点表分区过大问题)# 例子6: test\\.test:id,.\\..* , 针对test的表按照id散列,其余的表按照table散列# 注意：大家可以结合自己的业务需求，设置匹配规则，多条匹配规则之间是按照顺序进行匹配(命中一条规则就返回)</code></pre><h3 id="其余配置可参考官网wiki文档：alibaba-canal"><a href="#其余配置可参考官网wiki文档：alibaba-canal" class="headerlink" title="其余配置可参考官网wiki文档：alibaba/canal"></a>其余配置可参考官网wiki文档：<a href="https://github.com/alibaba/canal/wiki/QuickStart">alibaba/canal</a></h3><h2 id="测试监听"><a href="#测试监听" class="headerlink" title="测试监听"></a>测试监听</h2><p>使用kafka客户端测试，由于我使用的动态topic，所以topic名称为：{库名}_{表名}</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">🍓 ➜  kafka_2.12-2.2.2 .&#x2F;bin&#x2F;kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test_article</code></pre><p>手动修改一条该表的数据，即可收到canal发送的数据库变更消息：</p><p><img src="https://oscimg.oschina.net/oscnet/up-efdcbe72ea74b2357c99b31786999aaf840.png"></p><h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p>总体的搭建过程还是比较简单的，admin模块为我们提供了一个可视化的管理界面，简单易用，单独使用canal-server模块也可以，但是修改配置起来比较麻烦。</p><p>此外，在整个过程还是遇到了一些问题的，以下介绍几个踩坑点：</p><ul><li>canal监听时，有些库名和表名是空的，导致在动态topic情况下，kafka提示无效的topic名称，我们在配置中将空库名和表名的消息过滤掉就好，将默认的<code>.*\\..*</code>改为<code>.+\\..+</code></li><li>我的kafka是在本地主机的，需要增加kafka配置<code>advertised.listeners=PLAINTEXT://host.docker.internal:9092</code> ，容器中的应用才能正常访问kafka服务端</li><li>刚开始在启动canal-server时，总是连接admin服务失败，页面上所有接口也无响应，但是docker显示admin容器还在运行，进入canal-admin容器后查看日志无报错，但是后台的java进程已经没有了，困扰了挺久，后来发现我的docker内存配置只有2G，推测是内存不足停掉了，于是将docker内存配置改为8G，问题解决</li></ul><p><strong>本方案仅限于本地学习与测试，生产环境应使用HA模式部署，详见：<a href="https://github.com/alibaba/canal/wiki/AdminGuide#ha%E6%A8%A1%E5%BC%8F%E9%85%8D%E7%BD%AE">https://github.com/alibaba/canal/wiki/AdminGuide#ha模式配置</a></strong></p><h2 id="附录-GitHub经常无法下载文件，提供一些用到的脚本"><a href="#附录-GitHub经常无法下载文件，提供一些用到的脚本" class="headerlink" title="附录(GitHub经常无法下载文件，提供一些用到的脚本)"></a>附录(GitHub经常无法下载文件，提供一些用到的脚本)</h2><ul><li><p><strong>GitHub地址：</strong><a href="https://github.com/alibaba/canal">https://github.com/alibaba/canal</a></p></li><li><p><strong>run_admin.sh</strong></p>  <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#!&#x2F;bin&#x2F;bashfunction usage() &#123;    echo &quot;Usage:&quot;    echo &quot;  run_admin.sh [CONFIG]&quot;    echo &quot;example :&quot;    echo &quot;  run_admin.sh -e server.port&#x3D;8089 \\&quot;    echo &quot;         -e canal.adminUser&#x3D;admin \\&quot;    echo &quot;         -e canal.adminPasswd&#x3D;admin&quot;    exit&#125;function check_port() &#123;    local port&#x3D;$1    local TL&#x3D;$(which telnet)    if [ -f $TL ]; then        data&#x3D;&#96;echo quit | telnet 127.0.0.1 $port| grep -ic connected&#96;        echo $data        return    fi    local NC&#x3D;$(which nc)    if [ -f $NC ]; then        data&#x3D;&#96;nc -z -w 1 127.0.0.1 $port | grep -ic succeeded&#96;        echo $data        return    fi    echo &quot;0&quot;    return&#125;function getMyIp() &#123;    case &quot;&#96;uname&#96;&quot; in        Darwin)         myip&#x3D;&#96;echo &quot;show State:&#x2F;Network&#x2F;Global&#x2F;IPv4&quot; | scutil | grep PrimaryInterface | awk &#39;&#123;print $3&#125;&#39; | xargs ifconfig | grep inet | grep -v inet6 | awk &#39;&#123;print $2&#125;&#39;&#96;         ;;        *)         myip&#x3D;&#96;ip route get 1 | awk &#39;&#123;print $NF;exit&#125;&#39;&#96;         ;;  esac  echo $myip&#125;CONFIG&#x3D;$&#123;@:1&#125;#VOLUMNS&#x3D;&quot;-v $DATA:&#x2F;home&#x2F;admin&#x2F;canal-admin&#x2F;logs&quot;PORTLIST&#x3D;&quot;8089&quot;PORTS&#x3D;&quot;&quot;for PORT in $PORTLIST ; do    #exist&#x3D;&#96;check_port $PORT&#96;    exist&#x3D;&quot;0&quot;    if [ &quot;$exist&quot; &#x3D;&#x3D; &quot;0&quot; ]; then        PORTS&#x3D;&quot;$PORTS -p $PORT:$PORT&quot;    else        echo &quot;port $PORT is used , pls check&quot;        exit 1    fidoneNET_MODE&#x3D;&quot;&quot;case &quot;&#96;uname&#96;&quot; in    Darwin)        bin_abs_path&#x3D;&#96;cd $(dirname $0); pwd&#96;        ;;    Linux)        bin_abs_path&#x3D;$(readlink -f $(dirname $0))        NET_MODE&#x3D;&quot;--net&#x3D;host&quot;        PORTS&#x3D;&quot;&quot;        ;;    *)        NET_MODE&#x3D;&quot;--net&#x3D;host&quot;        PORTS&#x3D;&quot;&quot;        bin_abs_path&#x3D;&#96;cd $(dirname $0); pwd&#96;        ;;esacBASE&#x3D;$&#123;bin_abs_path&#125;DATA&#x3D;&quot;$BASE&#x2F;data&quot;mkdir -p $DATAif [ $# -eq 0 ]; then    usageelif [ &quot;$1&quot; &#x3D;&#x3D; &quot;-h&quot; ] ; then    usageelif [ &quot;$1&quot; &#x3D;&#x3D; &quot;help&quot; ] ; then    usagefiMEMORY&#x3D;&quot;-m 1024m&quot;LOCALHOST&#x3D;&#96;getMyIp&#96;cmd&#x3D;&quot;docker run -d -it -h $LOCALHOST $CONFIG --name&#x3D;canal-admin $VOLUMNS $NET_MODE $PORTS $MEMORY canal&#x2F;canal-admin&quot;echo $cmdeval $cmd</code></pre></li><li><p><strong>run.sh</strong></p>  <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#!&#x2F;bin&#x2F;bashfunction usage() &#123;    echo &quot;Usage:&quot;    echo &quot;  run.sh [CONFIG]&quot;    echo &quot;example 1 :&quot;    echo &quot;  run.sh -e canal.instance.master.address&#x3D;127.0.0.1:3306 \\&quot;    echo &quot;         -e canal.instance.dbUsername&#x3D;canal \\&quot;    echo &quot;         -e canal.instance.dbPassword&#x3D;canal \\&quot;    echo &quot;         -e canal.instance.connectionCharset&#x3D;UTF-8 \\&quot;    echo &quot;         -e canal.instance.tsdb.enable&#x3D;true \\&quot;    echo &quot;         -e canal.instance.gtidon&#x3D;false \\&quot;    echo &quot;         -e canal.instance.filter.regex&#x3D;.*\\\\\\..* &quot;    echo &quot;example 2 :&quot;    echo &quot;  run.sh -e canal.admin.manager&#x3D;127.0.0.1:8089 \\&quot;    echo &quot;         -e canal.admin.port&#x3D;11110 \\&quot;    echo &quot;         -e canal.admin.user&#x3D;admin \\&quot;    echo &quot;         -e canal.admin.passwd&#x3D;4ACFE3202A5FF5CF467898FC58AAB1D615029441&quot;    exit&#125;function check_port() &#123;    local port&#x3D;$1    local TL&#x3D;$(which telnet)    if [ -f $TL ]; then        data&#x3D;&#96;echo quit | telnet 127.0.0.1 $port| grep -ic connected&#96;        echo $data        return    fi    local NC&#x3D;$(which nc)    if [ -f $NC ]; then        data&#x3D;&#96;nc -z -w 1 127.0.0.1 $port | grep -ic succeeded&#96;        echo $data        return    fi    echo &quot;0&quot;    return&#125;function getMyIp() &#123;    case &quot;&#96;uname&#96;&quot; in        Darwin)         myip&#x3D;&#96;echo &quot;show State:&#x2F;Network&#x2F;Global&#x2F;IPv4&quot; | scutil | grep PrimaryInterface | awk &#39;&#123;print $3&#125;&#39; | xargs ifconfig | grep inet | grep -v inet6 | awk &#39;&#123;print $2&#125;&#39;&#96;         ;;        *)         myip&#x3D;&#96;ip route get 1 | awk &#39;&#123;print $NF;exit&#125;&#39;&#96;         ;;  esac  echo $myip&#125;CONFIG&#x3D;$&#123;@:1&#125;#VOLUMNS&#x3D;&quot;-v $DATA:&#x2F;home&#x2F;admin&#x2F;canal-server&#x2F;logs&quot;PORTLIST&#x3D;&quot;11110 11111 11112 9100&quot;PORTS&#x3D;&quot;&quot;for PORT in $PORTLIST ; do    #exist&#x3D;&#96;check_port $PORT&#96;    exist&#x3D;&quot;0&quot;    if [ &quot;$exist&quot; &#x3D;&#x3D; &quot;0&quot; ]; then        PORTS&#x3D;&quot;$PORTS -p $PORT:$PORT&quot;    else        echo &quot;port $PORT is used , pls check&quot;        exit 1    fidoneNET_MODE&#x3D;&quot;&quot;case &quot;&#96;uname&#96;&quot; in    Darwin)        bin_abs_path&#x3D;&#96;cd $(dirname $0); pwd&#96;        ;;    Linux)        bin_abs_path&#x3D;$(readlink -f $(dirname $0))        NET_MODE&#x3D;&quot;--net&#x3D;host&quot;        PORTS&#x3D;&quot;&quot;        ;;    *)        bin_abs_path&#x3D;&#96;cd $(dirname $0); pwd&#96;        NET_MODE&#x3D;&quot;--net&#x3D;host&quot;        PORTS&#x3D;&quot;&quot;        ;;esacBASE&#x3D;$&#123;bin_abs_path&#125;DATA&#x3D;&quot;$BASE&#x2F;data&quot;mkdir -p $DATAif [ $# -eq 0 ]; then    usageelif [ &quot;$1&quot; &#x3D;&#x3D; &quot;-h&quot; ] ; then    usageelif [ &quot;$1&quot; &#x3D;&#x3D; &quot;help&quot; ] ; then    usagefiMEMORY&#x3D;&quot;-m 4096m&quot;LOCALHOST&#x3D;&#96;getMyIp&#96;cmd&#x3D;&quot;docker run -d -it -h $LOCALHOST $CONFIG --name&#x3D;canal-server $VOLUMNS $NET_MODE $PORTS $MEMORY canal&#x2F;canal-server&quot;echo $cmdeval $cmd</code></pre></li><li><p><strong>server配置文件模板(canal.properties)</strong></p>  <pre class="line-numbers language-properties" data-language="properties"><code class="language-properties">########################################################## common argument############################################################### tcp bind ipcanal.ip &#x3D;# register ip to zookeepercanal.register.ip &#x3D;canal.port &#x3D; 11111canal.metrics.pull.port &#x3D; 11112# canal instance user&#x2F;passwd# canal.user &#x3D; canal# canal.passwd &#x3D; E3619321C1A937C46A0D8BD1DAC39F93B27D4458# canal admin config#canal.admin.manager &#x3D; 127.0.0.1:8089canal.admin.port &#x3D; 11110canal.admin.user &#x3D; admincanal.admin.passwd &#x3D; 4ACFE3202A5FF5CF467898FC58AAB1D615029441canal.zkServers &#x3D;# flush data to zkcanal.zookeeper.flush.period &#x3D; 1000canal.withoutNetty &#x3D; false# tcp, kafka, rocketMQ, rabbitMQcanal.serverMode &#x3D; tcp# flush meta cursor&#x2F;parse position to filecanal.file.data.dir &#x3D; $&#123;canal.conf.dir&#125;canal.file.flush.period &#x3D; 1000## memory store RingBuffer size, should be Math.pow(2,n)canal.instance.memory.buffer.size &#x3D; 16384## memory store RingBuffer used memory unit size , default 1kbcanal.instance.memory.buffer.memunit &#x3D; 1024 ## meory store gets mode used MEMSIZE or ITEMSIZEcanal.instance.memory.batch.mode &#x3D; MEMSIZEcanal.instance.memory.rawEntry &#x3D; true## detecing configcanal.instance.detecting.enable &#x3D; false#canal.instance.detecting.sql &#x3D; insert into retl.xdual values(1,now()) on duplicate key update x&#x3D;now()canal.instance.detecting.sql &#x3D; select 1canal.instance.detecting.interval.time &#x3D; 3canal.instance.detecting.retry.threshold &#x3D; 3canal.instance.detecting.heartbeatHaEnable &#x3D; false# support maximum transaction size, more than the size of the transaction will be cut into multiple transactions deliverycanal.instance.transaction.size &#x3D;  1024# mysql fallback connected to new master should fallback timescanal.instance.fallbackIntervalInSeconds &#x3D; 60# network configcanal.instance.network.receiveBufferSize &#x3D; 16384canal.instance.network.sendBufferSize &#x3D; 16384canal.instance.network.soTimeout &#x3D; 30# binlog filter configcanal.instance.filter.druid.ddl &#x3D; truecanal.instance.filter.query.dcl &#x3D; falsecanal.instance.filter.query.dml &#x3D; falsecanal.instance.filter.query.ddl &#x3D; falsecanal.instance.filter.table.error &#x3D; falsecanal.instance.filter.rows &#x3D; falsecanal.instance.filter.transaction.entry &#x3D; false# binlog format&#x2F;image checkcanal.instance.binlog.format &#x3D; ROW,STATEMENT,MIXED canal.instance.binlog.image &#x3D; FULL,MINIMAL,NOBLOB# binlog ddl isolationcanal.instance.get.ddl.isolation &#x3D; false# parallel parser configcanal.instance.parser.parallel &#x3D; true## concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()#canal.instance.parser.parallelThreadSize &#x3D; 16## disruptor ringbuffer size, must be power of 2canal.instance.parser.parallelBufferSize &#x3D; 256# table meta tsdb infocanal.instance.tsdb.enable &#x3D; truecanal.instance.tsdb.dir &#x3D; $&#123;canal.file.data.dir:..&#x2F;conf&#125;&#x2F;$&#123;canal.instance.destination:&#125;canal.instance.tsdb.url &#x3D; jdbc:h2:$&#123;canal.instance.tsdb.dir&#125;&#x2F;h2;CACHE_SIZE&#x3D;1000;MODE&#x3D;MYSQL;canal.instance.tsdb.dbUsername &#x3D; canalcanal.instance.tsdb.dbPassword &#x3D; canal# dump snapshot interval, default 24 hourcanal.instance.tsdb.snapshot.interval &#x3D; 24# purge snapshot expire , default 360 hour(15 days)canal.instance.tsdb.snapshot.expire &#x3D; 360########################################################## destinations##############################################################canal.destinations &#x3D; # conf root dircanal.conf.dir &#x3D; ..&#x2F;conf# auto scan instance dir add&#x2F;remove and start&#x2F;stop instancecanal.auto.scan &#x3D; truecanal.auto.scan.interval &#x3D; 5canal.instance.tsdb.spring.xml &#x3D; classpath:spring&#x2F;tsdb&#x2F;h2-tsdb.xml#canal.instance.tsdb.spring.xml &#x3D; classpath:spring&#x2F;tsdb&#x2F;mysql-tsdb.xmlcanal.instance.global.mode &#x3D; managercanal.instance.global.lazy &#x3D; falsecanal.instance.global.manager.address &#x3D; $&#123;canal.admin.manager&#125;#canal.instance.global.spring.xml &#x3D; classpath:spring&#x2F;memory-instance.xmlcanal.instance.global.spring.xml &#x3D; classpath:spring&#x2F;file-instance.xml#canal.instance.global.spring.xml &#x3D; classpath:spring&#x2F;default-instance.xml###########################################################       MQ Properties      ################################################################ aliyun ak&#x2F;sk , support rds&#x2F;mqcanal.aliyun.accessKey &#x3D;canal.aliyun.secretKey &#x3D;canal.aliyun.uid&#x3D;canal.mq.flatMessage &#x3D; truecanal.mq.canalBatchSize &#x3D; 50canal.mq.canalGetTimeout &#x3D; 100# Set this value to &quot;cloud&quot;, if you want open message trace feature in aliyun.canal.mq.accessChannel &#x3D; localcanal.mq.database.hash &#x3D; truecanal.mq.send.thread.size &#x3D; 30canal.mq.build.thread.size &#x3D; 8###########################################################      Kafka      ###############################################################kafka.bootstrap.servers &#x3D; 127.0.0.1:6667kafka.acks &#x3D; allkafka.compression.type &#x3D; nonekafka.batch.size &#x3D; 16384kafka.linger.ms &#x3D; 1kafka.max.request.size &#x3D; 1048576kafka.buffer.memory &#x3D; 33554432kafka.max.in.flight.requests.per.connection &#x3D; 1kafka.retries &#x3D; 0kafka.kerberos.enable &#x3D; falsekafka.kerberos.krb5.file &#x3D; &quot;..&#x2F;conf&#x2F;kerberos&#x2F;krb5.conf&quot;kafka.kerberos.jaas.file &#x3D; &quot;..&#x2F;conf&#x2F;kerberos&#x2F;jaas.conf&quot;###########################################################     RocketMQ     ###############################################################rocketmq.producer.group &#x3D; testrocketmq.enable.message.trace &#x3D; falserocketmq.customized.trace.topic &#x3D;rocketmq.namespace &#x3D;rocketmq.namesrv.addr &#x3D; 127.0.0.1:9876rocketmq.retry.times.when.send.failed &#x3D; 0rocketmq.vip.channel.enabled &#x3D; false###########################################################     RabbitMQ     ###############################################################rabbitmq.host &#x3D;rabbitmq.virtual.host &#x3D;rabbitmq.exchange &#x3D;rabbitmq.username &#x3D;rabbitmq.password &#x3D;</code></pre></li><li><p><strong>instance模板配置(instance.propertios)</strong></p>  <pre class="line-numbers language-properties" data-language="properties"><code class="language-properties">################################################### mysql serverId , v1.0.26+ will autoGen# canal.instance.mysql.slaveId&#x3D;0# enable gtid use true&#x2F;falsecanal.instance.gtidon&#x3D;false# position infocanal.instance.master.address&#x3D;127.0.0.1:3306canal.instance.master.journal.name&#x3D;canal.instance.master.position&#x3D;canal.instance.master.timestamp&#x3D;canal.instance.master.gtid&#x3D;# rds oss binlogcanal.instance.rds.accesskey&#x3D;canal.instance.rds.secretkey&#x3D;canal.instance.rds.instanceId&#x3D;# table meta tsdb infocanal.instance.tsdb.enable&#x3D;true#canal.instance.tsdb.url&#x3D;jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;canal_tsdb#canal.instance.tsdb.dbUsername&#x3D;canal#canal.instance.tsdb.dbPassword&#x3D;canal#canal.instance.standby.address &#x3D;#canal.instance.standby.journal.name &#x3D;#canal.instance.standby.position &#x3D;#canal.instance.standby.timestamp &#x3D;#canal.instance.standby.gtid&#x3D;# username&#x2F;passwordcanal.instance.dbUsername&#x3D;canalcanal.instance.dbPassword&#x3D;canalcanal.instance.connectionCharset &#x3D; UTF-8# enable druid Decrypt database passwordcanal.instance.enableDruid&#x3D;false#canal.instance.pwdPublicKey&#x3D;MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALK4BUxdDltRRE5&#x2F;zXpVEVPUgunvscYFtEip3pmLlhrWpacX7y7GCMo2&#x2F;JM6LeHmiiNdH1FWgGCpUfircSwlWKUCAwEAAQ&#x3D;&#x3D;# table regexcanal.instance.filter.regex&#x3D;.*\\..*# table black regexcanal.instance.filter.black.regex&#x3D;# table field filter(format: schema1.tableName1:field1&#x2F;field2,schema2.tableName2:field1&#x2F;field2)#canal.instance.filter.field&#x3D;test1.t_product:id&#x2F;subject&#x2F;keywords,test2.t_company:id&#x2F;name&#x2F;contact&#x2F;ch# table field black filter(format: schema1.tableName1:field1&#x2F;field2,schema2.tableName2:field1&#x2F;field2)#canal.instance.filter.black.field&#x3D;test1.t_product:subject&#x2F;product_image,test2.t_company:id&#x2F;name&#x2F;contact&#x2F;ch# mq configcanal.mq.topic&#x3D;example# dynamic topic route by schema or table regex#canal.mq.dynamicTopic&#x3D;mytest1.user,mytest2\\..*,.*\\..*canal.mq.partition&#x3D;0# hash partition config#canal.mq.partitionsNum&#x3D;3#canal.mq.partitionHash&#x3D;test.table:id^name,.*\\..*#################################################</code></pre></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>docker</tag>
      
      <tag>后端开发</tag>
      
      <tag>MySQL</tag>
      
      <tag>canal</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>jar包执行时访问资源文件造成的FileSystemNotFoundException问题</title>
    <link href="/2021/01/07/jar%E5%8C%85%E6%89%A7%E8%A1%8C%E6%97%B6%E8%AE%BF%E9%97%AE%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6%E9%80%A0%E6%88%90%E7%9A%84FileSystemNotFoundException%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    <url>/2021/01/07/jar%E5%8C%85%E6%89%A7%E8%A1%8C%E6%97%B6%E8%AE%BF%E9%97%AE%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6%E9%80%A0%E6%88%90%E7%9A%84FileSystemNotFoundException%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>在Java项目中，若需要访问资源文件，通常使用<code>getClass().getResource(&quot;/xxx&quot;)</code>和<code>getClass().getResourceAsStream(&quot;/&quot;)</code>来获取资源文件，后一种方式获取到的是InputStream，一般不会出现什么问题，但是通过第一种获取资源URL的方式，在IDEA中执行时没有问题，但是在服务器环境执行时，会出现<code>java.nio.file.FileSystemNotFoundException</code>，之前遇到这个问题我没有在意，只是换成<code>getResourceAsStream</code>后就解决了，但是后来遇到一个需要递归访问资源文件目录，我使用的<code>Files.walkFileTree</code>方法，直接获取输入流的方案不适合我，随后发现其实只要是打成jar包执行的时候，通过<code>Files</code>和<code>Path</code>去访问资源文件，<code>getResource</code>就会抛出<code>FileSystemNotFoundException</code>，并非服务器环境的问题，因为jar包执行时，文件系统与IDE中直接执行时不一样，所以会抛出这个异常。<br>原始的代码如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">Path configDir &#x3D; Paths.get(                    LocalConfigDataFlowManager.class.getResource(                            &quot;&#x2F;&quot;                    ).toURI().getPath(), &quot;flow-config&quot;            );List&lt;Map&lt;String, Object&gt;&gt; config &#x3D; new ArrayList&lt;&gt;();Files.walkFileTree(        configDir,        new HashSet&lt;&gt;(),        1,        new FileVisitor&lt;Path&gt;() &#123;        ......</code></pre><p>报错信息如下：</p><pre class="line-numbers language-log" data-language="log"><code class="language-log">java.nio.file.FileSystemNotFoundException        at jdk.zipfs&#x2F;jdk.nio.zipfs.ZipFileSystemProvider.getFileSystem(ZipFileSystemProvider.java:169)        at jdk.zipfs&#x2F;jdk.nio.zipfs.ZipFileSystemProvider.getPath(ZipFileSystemProvider.java:155)        at java.base&#x2F;java.nio.file.Path.of(Path.java:208)        at java.base&#x2F;java.nio.file.Paths.get(Paths.java:97)        at ink.andromeda.dataflow.core.flow.ConfigurableDataFlowManager.&lt;init&gt;(ConfigurableDataFlowManager.java:305)        at ink.andromeda.dataflow.demo.LocalConfigDataFlowManager.&lt;init&gt;(LocalConfigDataFlowManager.java:25)        at ink.andromeda.dataflow.demo.DataFlowDemoApplication.dataFlowManager(DataFlowDemoApplication.java:51)        at ink.andromeda.dataflow.demo.DataFlowDemoApplication$$EnhancerBySpringCGLIB$$73b01d37.CGLIB$dataFlowManager$0(&lt;generated&gt;)        ............2021-01-07.22:34:39.649 ERROR TraceId[] [main] i.a.d.d.LocalConfigDataFlowManager.visitFileFailed:60 null&#x2F;flow-configjava.nio.file.NoSuchFileException: null&#x2F;flow-config        at java.base&#x2F;sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)        at java.base&#x2F;sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)        at java.base&#x2F;sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)        at java.base&#x2F;sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)        at java.base&#x2F;sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:149)        at java.base&#x2F;java.nio.file.Files.readAttributes(Files.java:1763)        at java.base&#x2F;java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219)        at java.base&#x2F;java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276)        at java.base&#x2F;java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322)        at java.base&#x2F;java.nio.file.Files.walkFileTree(Files.java:2716)        at ink.andromeda.dataflow.demo.LocalConfigDataFlowManager.getFlowConfig(LocalConfigDataFlowManager.java:39)        at ink.andromeda.dataflow.core.flow.ConfigurableDataFlowManager.reload(ConfigurableDataFlowManager.java:92)        at ink.andromeda.dataflow.core.flow.ConfigurableDataFlowManager.init(ConfigurableDataFlowManager.java:56)        at java.base&#x2F;jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at java.base&#x2F;jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at java.base&#x2F;jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.base&#x2F;java.lang.reflect.Method.invoke(Method.java:566)        ......</code></pre><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>刚开始试了如下方案：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">Path configDir &#x3D; FileSystems.getDefault().getPath(new UrlResource(this.getClass().getResource(&quot;&#x2F;flow-config&quot;).toURI()).toString());</code></pre><p>但是仍然有问题：</p><pre class="line-numbers language-log" data-language="log"><code class="language-log">2021-01-07.23:06:42.037 ERROR TraceId[] [main] i.a.d.d.LocalConfigDataFlowManager.visitFileFailed:63 URL [jar:file:&#x2F;Users&#x2F;windlively&#x2F;IdeaProjects&#x2F;data-flow&#x2F;data-flow-demo&#x2F;target&#x2F;data-flow-demo-1.0-SNAPSHOT.jar!&#x2F;BOOT-INF&#x2F;classes!&#x2F;flow-config]java.nio.file.NoSuchFileException: URL [jar:file:&#x2F;Users&#x2F;windlively&#x2F;IdeaProjects&#x2F;data-flow&#x2F;data-flow-demo&#x2F;target&#x2F;data-flow-demo-1.0-SNAPSHOT.jar!&#x2F;BOOT-INF&#x2F;classes!&#x2F;flow-config]        at java.base&#x2F;sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)        at java.base&#x2F;sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)        at java.base&#x2F;sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)        at java.base&#x2F;sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)        at java.base&#x2F;sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:149)        at java.base&#x2F;java.nio.file.Files.readAttributes(Files.java:1763)        at java.base&#x2F;java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219)        at java.base&#x2F;java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276)        at java.base&#x2F;java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322)        at java.base&#x2F;java.nio.file.Files.walkFileTree(Files.java:2716)        at ink.andromeda.dataflow.demo.LocalConfigDataFlowManager.getFlowConfig(LocalConfigDataFlowManager.java:42)        at ink.andromeda.dataflow.core.flow.ConfigurableDataFlowManager.reload(ConfigurableDataFlowManager.java:92)        at ink.andromeda.dataflow.core.flow.ConfigurableDataFlowManager.init(ConfigurableDataFlowManager.java:56)</code></pre><p>于是继续查询资料，在stackoverflow上看到了一个利用Spring的<code>@Value()</code>注解和Spring Resource来访问资源文件的替代方案，而且提供了遍历资源文件夹的方法。<br>首先在Bean中加入一个字段并用Value注解注入资源文件的位置：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Value(&quot;classpath:&#x2F;flow-config&#x2F;**&quot;)private Resource[] flowConfigResources;</code></pre><p>Spring会自动将classes根目录<code>flow-config</code>文件夹下的资源文件全部注入到<code>flowConfigResources</code>字段中去。<br>然后修改原先的代码如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">protected List&lt;Map&lt;String, Object&gt;&gt; getFlowConfig() &#123;    return Stream.of(flowConfigResources)            .filter(s -&gt; Objects.nonNull(s.getFilename()))            .filter(s -&gt; s.getFilename().matches(&quot;^sync-config-[\\w-]+?.json$&quot;))            .map(flowConfigResource -&gt; &#123;                try (InputStream is &#x3D; flowConfigResource.getInputStream()) &#123;                    ByteArrayOutputStream os &#x3D; new ByteArrayOutputStream();                    int data;                    while ((data &#x3D; is.read()) !&#x3D; -1) os.write(data);                    &#x2F;&#x2F;noinspection unchecked                    return (Map&lt;String, Object&gt;) GSON().fromJson(os.toString(StandardCharsets.UTF_8.name()),                            new TypeToken&lt;Map&lt;String, Object&gt;&gt;() &#123;                            &#125;.getType());                &#125; catch (IOException ex) &#123;                    throw new IllegalStateException(ex);                &#125;            &#125;)            .filter(Objects::nonNull)            .collect(Collectors.toList());&#125;</code></pre><p>过滤和遍历Spring注入的Resource列表，即可读取到此文件夹下所有需要的资源文件，打成jar包之后也可正常运行。</p>]]></content>
    
    
    
    <tags>
      
      <tag>后端开发</tag>
      
      <tag>Java</tag>
      
      <tag>踩坑记录</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>前端发展简史</title>
    <link href="/2020/12/23/%E5%89%8D%E7%AB%AF%E5%8F%91%E5%B1%95%E7%AE%80%E5%8F%B2/"/>
    <url>/2020/12/23/%E5%89%8D%E7%AB%AF%E5%8F%91%E5%B1%95%E7%AE%80%E5%8F%B2/</url>
    
    <content type="html"><![CDATA[<h2 id="前端技术发展历程"><a href="#前端技术发展历程" class="headerlink" title="前端技术发展历程"></a>前端技术发展历程</h2><h3 id="远古时代："><a href="#远古时代：" class="headerlink" title="远古时代："></a>远古时代：</h3><p>还没有前端这个概念，网页是纯静态页面，HTML伴随着HTTP协议诞生，做一些纯文字信息的展示。</p><h3 id="CSS和JavaScript加入"><a href="#CSS和JavaScript加入" class="headerlink" title="CSS和JavaScript加入"></a>CSS和JavaScript加入</h3><p>早期的页面样式是由<code>&lt;font&gt;&lt;b&gt;&lt;sub&gt;&lt;center&gt;</code>等一系列标签去控制的，但是不利于维护和扩展，所以出现了CSS，将样式控制独立了出来，利于样式的复用。那时候网速也很慢，为了优化交互体验，诞生了JavaScript，此时的JavaScript就是做一些简单的页面逻辑交互，而且原名叫LiveScript，为了蹭Java热度改为了JavaScript……</p><h3 id="JavaScript和ECMAScript？"><a href="#JavaScript和ECMAScript？" class="headerlink" title="JavaScript和ECMAScript？"></a>JavaScript和ECMAScript？</h3><p>JavaScript的开发公司是Netscape，Netscape为了抵抗微软的JScript，将JavaScript提交给ECMA国际标准化组织，希望JavaScript成为国际标准，后来ECMA组织颁布了浏览器脚本语言标准，称之为ECMAScript，因此ECMAScript是一套规范标准，而JavaScript、微软的JScript则是这套标准的实现，大多数场合下ECMAScript和JavaScript的称呼可以通用。</p><h3 id="Dreamweaver、Firework、Flash、FrontPage等拖拽式设计网页的软件"><a href="#Dreamweaver、Firework、Flash、FrontPage等拖拽式设计网页的软件" class="headerlink" title="Dreamweaver、Firework、Flash、FrontPage等拖拽式设计网页的软件"></a>Dreamweaver、Firework、Flash、FrontPage等拖拽式设计网页的软件</h3><ul><li><p>Dreamweaver</p><p>大名鼎鼎的设计软件公司Adobe出品的产品，将网页开发变成了所见即所得，可以使得不懂代码的人经过简单的拖拽操作即可快速生成一套静态网页。Dreamweaver至今仍然在更新，支持的功能也越来越高级了。</p></li></ul><ul><li><p>FrontPage</p><p>微软的网页制作软件，属于Office组件中的一个产品，功能也十分强大，还支持数据库相关操作，于2006年停止更新，后由SharePoint Designer和Expression Web代替</p></li></ul><h3 id="动态网页技术CGI、PHP、JSP等的产生"><a href="#动态网页技术CGI、PHP、JSP等的产生" class="headerlink" title="动态网页技术CGI、PHP、JSP等的产生"></a>动态网页技术CGI、PHP、JSP等的产生</h3><ul><li><p>CGI</p><p>CGI(通用网关接口)是最老的一种技术，其实就是一组接口规范，可以用许多语言( C 、C++ 、VB和Perl等)编写，只要实现其接口即可，当浏览器发起请求，经Web服务器路由后会启动一个进程，调用对应的的CGI程序，程序执行完毕后返回HTML文本至浏览器，展示给用户。由于CGI性能低下，后来衍生出FastCGI，至今仍是一种广泛应用的技术，主流web服务器(Apache、Nginx、Microsoft IIS等)均支持该技术。</p></li><li><p>PHP</p><p>是一种在HTML文本中嵌入服务端代码的脚本语言，可以跨平台运行。由于其简单易上手，功能强大，又是开源技术，曾在Web开发领域风靡一时，和MySQL是好基友。（PHP是世界上最好的语言 yeah~）</p></li><li><p>JSP</p><p>基于Java的动态网页技术，与PHP有些许类似，也是在HTML代码中嵌入Java代码，由服务端编译执行。Java是Web开发领域最主流的技术之一，诞生过许多优秀的Web框架技术，从SSH(Struct、Spring、Hibernate)到SSM(Spring、Spring MVC、MyBatis)，都深受开发者喜爱。如今已经是Spring一家独大，几乎囊括了后端开发的方方面面。相比于PHP技术要求更高一点。</p></li></ul><ul><li><p>ASP</p><p>微软家的动态网页技术，同时支持VBScript和JScript，一般结合.NET框架使用，技术以及功能上来说都挺好，就是收费，财大气粗的公司多数可能会选择它。。。</p></li></ul><ul><li><p>FreeMarker、Thymeleaf等后端模板引擎</p><p>相对于JSP进行优化的页面渲染框架，这两种模板引擎Spring Boot框架都给予了良好的支持。</p></li></ul><h3 id="Ajax技术兴起以及JQuery时代降临"><a href="#Ajax技术兴起以及JQuery时代降临" class="headerlink" title="Ajax技术兴起以及JQuery时代降临"></a>Ajax技术兴起以及JQuery时代降临</h3><ul><li><p>Ajax</p><p>异步的JavaScript和XML(Asynchronous JavaScript and XML)技术，在之前的架构中，客户端向服务器发起请求，服务器处理结束后返回一个新的HTML文本，这样每一次请求都会交互大量数据，而且还要占用服务端资源渲染HTML文档，因此产生了Ajax技术：通过JavaScript代码主动请求服务器，而服务器只返回客户端需要的数据，不再将数据渲染为HTML返回，客户端拿到数据之后，通过DOM操作异步的更新界面，Ajax的优点非常明显：</p><ul><li>极大的减少了网络通信的数据量，比如有时候页面仅需变更一个数字，原先的服务端渲染方式就需要将整个页面全部重新返回，而ajax方式只需要返回这个更新后的数字。</li><li>减轻服务器压力，在大量请求时，仅渲染HTML文档所占用的资源就已经很大了，而客户端JavaScript代码更新页面则不会存在此问题。</li><li>页面是局部刷新的，而不是跟以前一样全部刷新，用户体验更好。</li></ul><p>但是也有一部分缺点：</p><ul><li>用户使用浏览器前进后退时的体验不好，异步刷新的局部更新方式浏览器无法获取历史页面，即丢失了页面的变更历史，但是这一点之后也有开发者想出办法解决。<br>搜索引擎无法SEO。搜索引擎公司的爬虫脚本获取不到网站数据，只能得到一段发送HTTP请求的JS代码，对网站的SEO是一个负面影响，不过Google对此已经有了解决方案，google的搜索引擎已经可以通过执行网页中的JS代码来爬取数据了（黑科技啊！~）</li><li>早期兼容性不好，但是现在已经不是问题了。</li></ul><p>Ajax在JavaScript中是通过XmlHttpRequest对象来支持的，原生的XHR API用起来是比较复杂的，于是便有人对其进行了封装，顺便处理了兼容性，用起来十分方便，比如JQuery。<br>随着Ajax的兴起，JSON这种数据格式也随之慢慢被大家所采用的，凭借比XML的简洁与方便，现在已成为主流的数据交互格式之一。</p></li><li><p>JQuery</p><p>JQuery是之前非常流行的一款前端JS框架，简洁且功能强大，还帮助开发者处理了很多兼容性问题，优化了DOM操作，封装了许多非常好用的API，是当时前端必备的利器，我当时对其也爱不释手，至今仍然还有不少人在用。在此段时期，前后端开发也渐渐出现了分离的迹象。</p></li></ul><h3 id="架在Chrome-V8上的Node"><a href="#架在Chrome-V8上的Node" class="headerlink" title="架在Chrome V8上的Node"></a>架在Chrome V8上的Node</h3><ul><li><p>V8 JavaScript引擎</p><p>V8是由Google研发的一款JavaScript执行引擎，并且谷歌将其开源，V8的特点，就是：快！，非常快，各种优化的奇淫技巧，诞生了这个杰作。所以当年产生了不少调侃Chrome和IE的段子，而由于V8的出现，在服务器上运行JavaScript代码成为了可能。</p></li><li><p>Node.js</p><p>Node凭借着V8引擎的基础，将JavaScript搬到了后台，V8作为Node的运行时，并添加了一些与操作系统交互的API，使其可以脱离浏览器运行，试图将JavaScript应用于后端开发，分一杯服务器开发的羹，并且确实火了一把，虽然最终未能撼动Java的地位，但是他的包管理工具NPM以及依赖管理后续被大家广泛使用，为后来前端项目的工程化奠定了基础，使得前端开发者们有了媲美后端的一系列项目工具（依赖管理、编译、测试、打包、部署、运行）。</p></li></ul><h3 id="JavaScript编译器以及TypeScript等许多新技术"><a href="#JavaScript编译器以及TypeScript等许多新技术" class="headerlink" title="JavaScript编译器以及TypeScript等许多新技术"></a>JavaScript编译器以及TypeScript等许多新技术</h3><ul><li><p>Babel.js</p><p>babel是一个开源的JavaScript编译(转译)器，用于将其他的编程风格转换为JavaScript代码。Babel的出现主要是因为在ES 5、ES 6标准问世之后，各浏览器厂商却未能及时支持，所以出现了此类转译工具，可以将ES 5 + 的语法编译成向后兼容的JavaScript语法，也可自定义语法，提升开发效率，React框架的语法翻译就依赖此库。</p></li><li><p>TypeScript</p><p>TypeScript是JavaScript的超集，由微软推出并开源，它在JavaScript基础之上增添了许多强大的功能支持，最重要的一个特点就是加入了静态类型系统的支持，使其更适合于大型工程项目，并且对于类型的支持比Java之类的语言更加优雅。TypeScript代码通过TypeScript编译期或Babel编译为JavaScript代码执行。</p></li><li><p>服务端推送技术</p><ul><li><p>SSE</p><p>SSE(Server-Sent Events)是服务端向客户端推送数据的一种技术，原先的web模型只能是客户端向服务端发起请求，服务端被动响应，而服务器无法主动向客户端发送数据，所以出现了SSE方案，其实SSE仍然是基于HTTP长连接的一种技术，本质仍然是HTTP协议，其Content-Type为text/event-stream类型，JavaScript代码使用EventSource对象进行处理，发送的文本有固定格式，使用较为简单方便，但是只能服务端向客户端单向发送数据。Spring MVC框架对SSE有不错的支持。</p></li><li><p>WebSocket</p><p>建立在TCP之上的另外一种网络通信协议，支持全双工通信，且效率更高，使用起来比SSE复杂一些，适合需要与服务端进行频繁交互的场景。</p></li></ul></li></ul><ul><li><p>HTML5新特性</p><p>HTML5标准其实诞生时间比较早，由W3C于2014年10月完成标准制定，但是各个浏览器支持进度不一，直至Chrome 67、IE8等现代浏览器问世之后，HTML5标准才被较好的支持。</p><ul><li><p>canvas画布</p><p>支持使用JavaScript代码在页面上绘制复杂图形以及动画。</p></li><li><p>多媒体标签</p><p><code>&lt;audio&gt;&lt;video&gt;</code>等标签的加入，使得开发人员可以更容易的在网页中处理多媒体内容，此前这类复杂内容主要通过Flash、ActiveX等控件处理，而现在HTML原生支持多媒体处理，Flash等技术由于安全性相关问题已经慢慢被遗弃，Chrome浏览器早已默认禁用flash。</p></li><li><p>其他新特性</p><p>本地存储、WEB SQL、<code>&lt;article&gt;&lt;footer&gt;&lt;header&gt;&lt;nav&gt;&lt;section&gt;</code>等新标签，etc…</p></li></ul></li><li><p>CSS新特性</p><p>CSS陆续加入了许多强大和有趣的功能，使得UI可以越来越漂亮，这也得益于客户端浏览器性能越来越强悍：</p><ul><li>适合移动设备的flex布局</li><li>MediaQuery加入，支持响应式布局</li><li>Grid布局</li><li>CSS滤镜</li><li>CSS背景虚化</li><li>CSS动画</li><li>……</li></ul></li></ul><h3 id="React-js、Angular、Vue-js等框架陆续登场"><a href="#React-js、Angular、Vue-js等框架陆续登场" class="headerlink" title="React.js、Angular、Vue.js等框架陆续登场"></a>React.js、Angular、Vue.js等框架陆续登场</h3><p>随着前后端分离的web开发方案以及SPA(单页面应用)的概念越来越流行，前端框架也开始层出不穷，将原先属于后端的MVC模型利用JS搬到了前端，又形成了MVVM、MVP等模型概念，其中以React、Angular、Vue最为出名和流行，彻底将前端开发从后端开发中剥离出来，使得前端开发更为纯粹，专注于页面视图开发，曾风光无限的JQuery一类的js库开始慢慢淡出历史舞台，得益于框架提供的强大功能，我们不再需要手动操纵DOM文档。框架技术在此时的发展十分迅速，甚至开始向原生APP开发领域挺进，而基于这些框架技术开发的网站，又可被称之为Web App，网站已经从原先的信息展示变成了一些功能性应用。Android、Windows都有将JS开发的应用转换为对应平台APP的技术，至此，JavaScript已经做到了”Any application that can be written in JavaScript, will eventually be written in JavaScript”！</p><h3 id="大前端时代，百花齐放的WebApp框架"><a href="#大前端时代，百花齐放的WebApp框架" class="headerlink" title="大前端时代，百花齐放的WebApp框架"></a>大前端时代，百花齐放的WebApp框架</h3><p>此时的前端又被许多人称之为”大前端”，JavaScript早已不再局限于传统网站的开发，Electron、React Native、微信小程序、支付宝小程序等等，都在尝试基于浏览器的跨平台APP技术，也都取得了不错的效果，JavaScript从早期一个无数人吐槽的脚本语言进化到现在成为了前端开发的核心。<br>到今天，人们还不满足于此，前端技术仍在高速发展，以Google为代表的众多行业领头羊继续在探索未来的前端方向，例如浏览器已经开始支持的WebAssembly技术和Google的Flutter跨平台原生APP开发框架。</p>]]></content>
    
    
    
    <tags>
      
      <tag>前端开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker安装mongo</title>
    <link href="/2020/12/15/docker%E5%AE%89%E8%A3%85mongo/"/>
    <url>/2020/12/15/docker%E5%AE%89%E8%A3%85mongo/</url>
    
    <content type="html"><![CDATA[<ul><li><p>拉取镜像<br><code>docker pull mongo</code></p></li><li><p>选择一个合适的文件夹, 创建mongo目录并进入<br><code>mkdir mongo &amp;&amp; cd mongo</code></p></li><li><p>创建配置文件目录<br><code>mkdir conf</code></p></li><li><p>创建并编辑配置文件<br><code>vim conf/mongod.conf</code><br>mongod.config为mongo配置文件, 示例:</p><pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">storage:journal:  enabled: trueengine: wiredTiger#如下配置仅对 wiredTiger 引擎生效（3.0 以上版本） wiredTiger:  engineConfig:  # wiredTiger缓存工作集（working set）数据的内存大小，单位：GB   # 此值决定了wiredTiger与mmapv1的内存模型不同，它可以限制mongod对内存的使用量，而mmapv1则不能（依赖于系统级的mmap）。默认情况下，cacheSizeGB 的值为假定当前节点只部署一个mongod实例，此值的大小为物理内存的一半；如果当前节点部署了多个mongod进程，那么需要合理配置此值。如果mongod部署在虚拟容器中（比如，lxc，cgroups，Docker）等，它将不能使用整个系统的物理内存，则需要适当调整此值。默认值为物理内存的一半。     cacheSizeGB: 1.5systemLog:  logAppend: truenet:  bindIp: 0.0.0.0# 是否开启授权security:  authorization: enabled</code></pre></li><li><p>创建并运行mongo docker容器，路径映射需要根据机器更改  </p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker run --name mongo \   --privileged \   -p 27017:27017 \   -v ~&#x2F;docker-app&#x2F;mongo&#x2F;data:&#x2F;data&#x2F;db \   -v ~&#x2F;docker-app&#x2F;mongo&#x2F;conf:&#x2F;data&#x2F;configdb \   -v ~&#x2F;docker-app&#x2F;mongo&#x2F;logs:&#x2F;data&#x2F;log&#x2F; \   -d  \   mongo  \   -f &#x2F;data&#x2F;configdb&#x2F;mongod.conf</code></pre><p>解释:</p><blockquote><p>–name mongo  #容器名<br>–privileged  #给予权限<br>-p 27017:27017   #端口映射<br>-v ~/docker-app/mongo/data:/data/db   #数据文件夹映射（主机:容器）<br>-v ~/docker-app/mongo/conf:/data/configdb   #配置文件路径映射<br>-v ~/docker-app/mongo/logs:/data/log/    #日志文件夹路径映射<br>-d   #后台运行<br>mongo   # 所使用的镜像<br>-f /data/configdb/mongod.conf  #使用配置文件启动(路径对应的容器路径，非主机路径)  </p></blockquote></li><li><p>附一个bash脚本(在mongo文件夹下执行)</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"># 创建一个mongo docker容器mkdir conftouch conf&#x2F;mongod.confconf_file&#x3D;&#39;conf&#x2F;mongod.conf&#39;cat&gt;$conf_file&lt;&lt;EOFstorage:  journal:    enabled: true  engine: wiredTiger  wiredTiger:  engineConfig:    cacheSizeGB: 1.5systemLog:  logAppend: truenet:  bindIp: 0.0.0.0security:  authorization: enabledEOFdocker pull mongobase_dir&#x3D;$PWDdocker run --name mongo \  --privileged \  -p 27017:27017 \  -v $base_dir&#x2F;data:&#x2F;data&#x2F;db \  -v $base_dir&#x2F;conf:&#x2F;data&#x2F;configdb \  -v $base_dir&#x2F;logs:&#x2F;data&#x2F;log&#x2F; \  -d  \  mongo  \  -f &#x2F;data&#x2F;configdb&#x2F;mongod.conf</code></pre></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>docker</tag>
      
      <tag>后端开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于一次Kafka重复消费问题排查记录的闲谈</title>
    <link href="/2020/12/15/%E5%85%B3%E4%BA%8E%E4%B8%80%E6%AC%A1Kafka%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%AE%B0%E5%BD%95%E7%9A%84%E9%97%B2%E8%B0%88/"/>
    <url>/2020/12/15/%E5%85%B3%E4%BA%8E%E4%B8%80%E6%AC%A1Kafka%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%AE%B0%E5%BD%95%E7%9A%84%E9%97%B2%E8%B0%88/</url>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;前段时间上线一个新服务，我们的运营在测试的时候，导入了一批数据，结果目标表里的数据是预期数量的2倍，有大量的重复数据，一开始我认为可能是我没有过滤数据类型导致的，我所消费的数据是通过监听数据库的binlog解析后推送到Kafka的数据，我收到kafka消息经过反序列化得到多条数据库表的变动记录，每一条记录都有一个类型：<code>INSERT</code>，<code>UPDATE</code>，<code>DELETE</code>，其实也就是对应SQL的类型，我一开始并没有判断这个类型，而是收到的所有数据都进行后续的处理，运营也说可能是有<code>UPDATE</code>操作的，于是我加了过滤，只处理<code>INSERT</code>类型数据，改好之后想着肯定没问题了，于是让运营再删掉原有数据重新导入一遍，第二天再看结果。   </p><p>&emsp;&emsp;然而第二天，问题依旧……这下可难到我了，想了一会猜测会不会是前面的环节推送的数据就是重复的呢？但是也不能瞎猜，于是我在处理一条数据之前打印上offset，发版后开始观察日志，不一会儿库里出现了重复数据了，我拿到重复的订单号之后去日志中搜索，结果，两条数据的offset是一样的？</p><p><img src="https://oscimg.oschina.net/oscnet/up-a4d97566c877c3ad14dc1ae79d947b9c48e.png" alt="img"></p><p>&emsp;&emsp;看来这真是我消费的问题了，但是之前类似的项目也是同样的消费方式，从来没出现过重复消费呀，这就让我非常纳闷，于是找了几条重复数据，观察了一下插入时间，发现时间间隔还挺有规律，基本都是五分钟左右重复插入一次，在日志上发现重复消费是两台机器交替进行的，我所消费的Topic是只有一个分区的，所以只会有一台机器消费，从日志上看出来两台机器在交替消费，因而产生了重复消费，但是为什么呢，于是再搜了下<em>Exception</em>关键词，发现了一个<code>CommitFailedException</code>：</p><p><img src="https://oscimg.oschina.net/oscnet/up-4a5809d58553eb75c4d899315e717ef0e9c.png" alt="img"></p><p>&emsp;&emsp;可以看出来，是当前消费端被踢出了消费组，随后offset提交失败，然后换了一台机器重新消费这个offset，导致了重复消费，但是为什么被被剔除出消费组我仍然无法解释，因为日志上再也没其他错误信息了，好在后来又让我发现了点蛛丝马迹，那会刚好使用了<code>tail -f</code>命令，不经意间发现过了好久，接收到的数据offset都是一样的，一条kafka消息解压后有这么多？(后来在本地试了下，果然一条Kafka消息，反序列化后都有3000到9000条不等，这也太多了吧。。)经过一番Google之后注意到了Kafka的两个配置项：<code>max.poll.interval.ms</code>和<code>max.poll.records</code>分别代表拉取消息的间隔时间和拉取的最大条数，我的配置是：</p><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties">max.poll.interval.ms &#x3D; 600000 # 默认5分钟max.poll.records &#x3D; 20         # 这个是我最开始写的20条</code></pre><p>&emsp;&emsp;也就是说，最快要5分钟内处理完20个offset，否则将认为客户端不在消费了，也就产生了上面的异常，被踢出消费组，而后又commit失败。从打印的日志来看，这个时间明显不够，处理一个offset的消息都要很久，更别说最大20个了。知道原因后，我改了参数:</p><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties">max.poll.interval.ms &#x3D; 1200000max.poll.records &#x3D; 1</code></pre><p>&emsp;&emsp;也就是一条十分钟的一个的下限速度，但是后来证明，这个时间依旧远远不够(最后这个时间已经改为了1个小时…)，经过一段时间的观察，一条Kafka消息反序列化最多会有10000条数据，处理时间最长大约40多分钟，我最开始确实没有想到这个Topic中的一条消息包含的数据会这么多，导致了这一系列的问题，时间改为1小时后连续两天再没出现过重复消费offset的问题。</p><p>&emsp;&emsp;但是但是，这个程序的处理速度慢，也是导致此问题的一个原因，当然后来发现代码中，处理一条数据，平均查询与插入数据库的次数有五六十次！这当然快不起来啊，于是我在大部分的SQL查询部分使用<code>WeakHashMap</code>进行了数据缓存，因为这部分查询的数据基本是不会有变动的，极大的减少了数据库查询次数，处理速度提升了将近10倍！再后来，由于这个Topic只有一个partition，完全没办法用到多台机器的性能，而且据运维反馈，这个TiDB binlog监听的中间件只支持一个分区发送， 于是我自己在程序中增加了一道转发，即消费到Kafka消息反序列化之后，将反序列化之后的数据先不做处理，直接一条一条转发至RocketMQ，这个过程是非常快的，rocketMQ再发送至各个机器上(也可新建一个多partition的Kafka Topic用于转发)，这样就能充分利用集群的优势，进一步极大地提高处理速度，这一块说这么多其实偏题了，属于后续的一个优化。</p><p>&emsp;&emsp;后来发现，其实每一次在消费端即将离开之前，都会有一条日志：</p><p><img src="https://oscimg.oschina.net/oscnet/up-9bd6fbd5b2048752b177b7de8a7211c6c6d.png" alt="img"></p><p>&emsp;&emsp;提示向服务端发送了离开消费组的请求，因为客户端poll操作已超时，并建议增大最大拉取间隔时间或者减小最大拉取数量(这个不行，我都改到1了 T_T )。  </p><p>&emsp;&emsp;然后在处理完一个offset提交的时候会提示请求失败，当前消费者不再是此消费组的一部分。</p><p><img src="https://oscimg.oschina.net/oscnet/up-ded106931e5c1de8ecefc6f11fca2dbf796.png" alt="img"></p><p>&emsp;&emsp;但是日志级别是INFO，确实不太容易发现，至此问题已完全解决，原因也完全清楚了。</p><p>&emsp;&emsp;总的来说此次遇到的Kafka重复消费的原因，第一是Kafka的消息太大（后来解析到最大有包含25万条数据的一条消息。。。这都是使用protobuf序列化的消息），但是这部分我们无法变动，第二是一开始处理速度也比较慢，默认间隔时间完全不够，综合导致频繁重新消费。</p><p>&emsp;&emsp;经过此次问题对Kafka参数有了更深的一些认识，除上面两个用到的同时也是比较重要参数之外，还有请求的超时时间、会话超时时间、心跳检测事件、拉取消息的超时时间等，在本地Debug期间还遇到过一个总是拉取不到消息然后报空指针异常的问题，然后查到原因是拉取Kafka消息超时了，一条消息可能有十几兆，那会刚好我电脑的网速非常慢，就超时了，后来加大了<code>fetch.max.wait.ms</code>和<code>request.timeout.ms</code>就没问题了。很有意义的一次Kafka问题排查经历</p><h3 id="附一个：Kafka-Consumer配置官方文档"><a href="#附一个：Kafka-Consumer配置官方文档" class="headerlink" title="附一个：Kafka Consumer配置官方文档"></a>附一个：<a href="http://kafka.apache.org/090/documentation.html#consumerconfigs">Kafka Consumer配置官方文档</a></h3>]]></content>
    
    
    
    <tags>
      
      <tag>kafka</tag>
      
      <tag>后端开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动态创建与修改定时任务</title>
    <link href="/2020/12/15/%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BA%E4%B8%8E%E4%BF%AE%E6%94%B9%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"/>
    <url>/2020/12/15/%E5%8A%A8%E6%80%81%E5%88%9B%E5%BB%BA%E4%B8%8E%E4%BF%AE%E6%94%B9%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h3 id="emsp-emsp-最近遇到一个需求，需要能够按照特定的配置执行定时任务，而且定时任务需要在应用不重启的情况下动态增删改，Spring提供的-Scheduled注解是硬编码形式，只能实现固定的定时任务，随后经过一番探究，依托注明的quartz框架终于实现了该功能，下面来分享一下我的方案。"><a href="#emsp-emsp-最近遇到一个需求，需要能够按照特定的配置执行定时任务，而且定时任务需要在应用不重启的情况下动态增删改，Spring提供的-Scheduled注解是硬编码形式，只能实现固定的定时任务，随后经过一番探究，依托注明的quartz框架终于实现了该功能，下面来分享一下我的方案。" class="headerlink" title="&emsp;&emsp;最近遇到一个需求，需要能够按照特定的配置执行定时任务，而且定时任务需要在应用不重启的情况下动态增删改，Spring提供的@Scheduled注解是硬编码形式，只能实现固定的定时任务，随后经过一番探究，依托注明的quartz框架终于实现了该功能，下面来分享一下我的方案。"></a>&emsp;&emsp;最近遇到一个需求，需要能够按照特定的配置执行定时任务，而且定时任务需要在应用不重启的情况下动态增删改，Spring提供的<code>@Scheduled</code>注解是硬编码形式，只能实现固定的定时任务，随后经过一番探究，依托注明的quartz框架终于实现了该功能，下面来分享一下我的方案。</h3><ul><li><p>首先引入quartz maven依赖：</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml">&lt;dependency&gt;    &lt;groupId&gt;org.quartz-scheduler&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;quartz&lt;&#x2F;artifactId&gt;    &lt;!-- 由于我的项目继承了spring-boot-starter-parent，因此这里可以不用写版本号，会直接使用父pom文档中dependencyManagement的quartz版本号 --&gt;    &lt;!-- &lt;version&gt;2.3.2&lt;&#x2F;version&gt; --&gt;&lt;&#x2F;dependency&gt;</code></pre></li><li><p>我的定时任务配置是存储在MySQL数据库当中的，当程序启动时，初始化过程会的<code>init()</code>方法会读取一遍所有有效的定时任务配置，然后将其实例化为一个个对象，一个对象便代表了一个定时任务，我定义的类为 <code>public class ScheduledClauseTriggerEngine implements ClauseTriggerEngine&lt;Void&gt;, Job, AutoCloseable</code>，其中<code>ClauseTriggerEngine</code>为我自定义的接口，因为在项目中除定时触发外还有其他的任务触发方式，不再过多赘述，<code>Job</code>(<code>org.quartz.Job</code>)是quartz框架的一个接口，代表一个任务，在任务调度时，<code>Job</code>的<code>execute(JobExecutionContext context)</code>方法会被调用，用以执行任务内容。所有实例化后的<code>ScheduledClauseTriggerEngine</code>对象会被存在一个<code>Map&lt;Integer, ScheduledClauseTriggerEngine&gt;</code>容器中去，Key为定时任务的id，后续在定时任务增删改的时候，也会同步修改这个Map的内容。</p></li><li><p>创建<code>SchedulerFactoryBean</code>(<code>org.springframework.scheduling.quartz.SchedulerFactoryBean</code>)，并设置JobFactory，由于我这里只使用到SchedulerFactoryBean一次，因此这一小段代码写在构造方法中的，若是全局使用，需要在Spring的Configuration类中专门定义一个SchedulerFactoryBean类型的Bean(比较规范的用法)。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">SchedulerFactoryBean schedulerFactoryBean &#x3D; new SchedulerFactoryBean();        schedulerFactoryBean.setJobFactory((bundle, scheduler) -&gt;                triggers.get(Integer.parseInt(bundle.getJobDetail().getKey().getName())));        schedulerFactoryBean.afterPropertiesSet();        this.scheduler &#x3D; schedulerFactoryBean.getScheduler();        this.scheduler.start();</code></pre><p><code>setJobFactory</code>这一步比较重要，默认的调度方案是通过反射实现的，即传入一个Job类型的class，然后反射实例化一个此类的对象，再去调用execute方法，通过<code>JobExecutionContext</code>传参，而我的方案是所有任务类都已实例化完成，我希望在触发时直接返回对应的对象实例去执行即可，因此需要去修改JobFactory，<code>triggers</code>是上一步中所说的存储定时任务的Map，而<code>bundle.getJobDetail().getKey().getName()</code>其实就是获取到了任务的key，在我这里其实也就是定时任务id，这个与后面步骤的代码相对应，也就是此时定时任务触发时，会拿到我提前准备好的Map中的对应任务实例去执行，覆盖默认行为。</p></li><li><p>实例化ScheduledClauseTriggerEngine并创建定时任务，下面为比较重要的几行代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 此部分代码为实例化并创建一个定时任务的代码，我将其封装为了一个方法，方便调用，在初始化方法中查询所有定时任务循环调用即可&#x2F;&#x2F; ... 忽略数据库查询及参数校验的过程&#x2F;&#x2F; 创建JobDetailJobDetail jobDetail &#x3D; new JobDetailImpl()              .getJobBuilder()              &#x2F;&#x2F; 任务的id以及group，id为数据库中的id，在上一步设置的JobFactory，当改任务被调度时，会根据此id去获取到要执行的任务              .withIdentity(clauseTriggerId.toString(), SCHEDULE_JOB_GROUP_NAME)              &#x2F;&#x2F; 任务描述，可选              .withDescription(clauseTrigger.getName())              &#x2F;&#x2F; 这里直接传入ScheduledClauseTriggerEngine.class即可              .ofType(ScheduledClauseTriggerEngine.class)              .build();&#x2F;&#x2F; 添加触发器并开始调度任务scheduler.scheduleJob(jobDetail, TriggerBuilder.newTrigger()        &#x2F;&#x2F; 要调度的任务的key        .withIdentity(clauseTriggerId.toString())        &#x2F;&#x2F; 触发周期，triggerConfigToCronExpression是将数据库中的时间配置转换为corn表达式的方法        .withSchedule(CronScheduleBuilder.cronSchedule(triggerConfigToCronExpression(clauseTrigger.getTriggerConfig())))        .build());&#x2F;&#x2F; 此时其实定时任务已经开始生效&#x2F;&#x2F; 后续操作...triggerEngine.setTemplateList(scheduledTemplates);log.info(&quot;add one scheduled clause trigger: &#123;&#125;&quot;, clauseTrigger.getName());return triggerEngine;</code></pre></li><li><p>定时任务的增删改：</p><ul><li><p>根据id新增一个任务：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void addTrigger(int triggerId) &#123;  &#x2F;&#x2F; 根据triggerId实例化和启动一个定时任务，并添加到定时任务的Map中去，instanceOneScheduledClauseTriggerEngine就是上一步所封装的方法  ScheduledClauseTriggerEngine triggerEngine &#x3D; triggers.computeIfAbsent(triggerId, k -&gt; instanceOneScheduledClauseTriggerEngine(triggerId));&#125;</code></pre></li><li><p>根据id删除一个任务：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void removeTrigger(int clauseTriggerId) &#123;      try &#123;          &#x2F;&#x2F; 生成要删除的jobKey，注意此处必须传入刚才所使用的的group name，否则会使用默认的组名，便无法查询到我们想要删除的任务          JobKey jobKey &#x3D; JobKey.jobKey(String.valueOf(clauseTriggerId), SCHEDULE_JOB_GROUP_NAME);          &#x2F;&#x2F; 移除定时任务          scheduler.deleteJob(jobKey);          &#x2F;&#x2F; 从Map中移除对应的对象          triggers.remove(clauseTriggerId);          log.info(&quot;remove schedule trigger: &#123;&#125;&quot;, jobKey);      &#125; catch (SchedulerException e) &#123;          log.error(e.getMessage(), e);      &#125;&#125;</code></pre></li><li><p>根据id更新一个任务：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void updateTrigger(int triggerId) &#123;    &#x2F;&#x2F; 由于我项目中的定时任务可能任务执行内容会变，因此我是将定时任务删除再重新添加，若定时任务只会有触发时间的变化，也可使用rescheduleJob方法只更新触发时间    removeTrigger(triggerId);    addTrigger(triggerId);&#125;</code></pre></li></ul></li><li><p>集群环境下需要注意的地方</p><ul><li><p>多台机器时，我需要只有一台机器执行任务，而其他机器不执行，在此处我使用了Redis作为锁，追求简便，当然也可使用zookeeper。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Overridepublic void execute(JobExecutionContext context) &#123;    String jobKey &#x3D; context.getJobDetail().getKey().toString();    String redisKey &#x3D; JOB_REDIS_PREFIX + jobKey;    &#x2F;&#x2F; 判断是否获取到锁    &#x2F;&#x2F;noinspection ConstantConditions    if(redisTemplate.opsForValue().increment(redisKey) !&#x3D; 1L)&#123;        log.info(&quot;job &#123;&#125; has in running&quot;, jobKey);        return;    &#125;    &#x2F;&#x2F; 注意上面的判断必须放在try-finally块之外，否则会导致一个隐秘的BUG(无论当前机器是否获取到锁，都会执行finally中的方法，释放掉锁，产生错误)    &#x2F;&#x2F; 为锁加上默认过期时间    redisTemplate.expire(redisKey, 3600, TimeUnit.SECONDS);    try &#123;        MDC.put(&quot;traceId&quot;, randomId());        log.info(&quot;execute schedule job: &#123;&#125;&quot;, jobKey);        long l &#x3D; System.currentTimeMillis();        trigger();        log.info(&quot;finish job: &#123;&#125;, used time: &#123;&#125;ms&quot;, jobKey, System.currentTimeMillis()-l);    &#125; catch (Exception ex)&#123;        log.error(ex.getMessage(), ex);    &#125;finally &#123;        MDC.clear();        &#x2F;&#x2F; 释放锁        redisTemplate.delete(redisKey);    &#125;&#125;</code></pre><p>其实在之前，我写了一个注解：<code>@RedisLock</code>，可以通过注解方式直接为某个方法加分布式锁，但是注解不能传入变量，只能传入常量，在这个项目，锁的key是动态的，无法直接使用，便先采用直接写代码的形式，后期可以添加上此功能，通过注解传入SpringEL表达式解析方法入参，就可以实现动态key值了。</p></li><li><p>多台机器定时任务更新问题，当定时任务配置更改时，我需要响应的修改定时任务，但是多台机器，我不能一台一台机器的手动去调用对应的方法，因此我想到了使用redis的发布订阅去完成，因为Redis的默认消息模式是群发模式，刚好符合我的需求，若项目中有MQ，也可配置一个群发的MQ Topic去实现，略微复杂一些。<br>附我所使用的代码，供参考，基于spring-redis：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Bean  RedisMessageListenerContainer redisMessageListenerContainer(RedisConnectionFactory connectionFactory,                                                              ScheduledTriggerService scheduledTriggerService,                                                              DwdDataTriggerService dwdDataTriggerService,                                                              ClauseExecuteService clauseExecuteService) &#123;      RedisMessageListenerContainer container &#x3D; new RedisMessageListenerContainer();      container.setConnectionFactory(connectionFactory);      &#x2F;&#x2F;trigger发布订阅      container.addMessageListener((message, bytes) -&gt; &#123;          String body &#x3D; new String(message.getBody(), StandardCharsets.UTF_8);          if (body.startsWith(&quot;scheduled-trigger-change&quot;)) &#123;            Assert.isTrue(body.matches(&quot;^scheduled-trigger-change:((add)|(remove)|(update)):\\d+$&quot;),&quot;invalid scheduled-trigger-change message: &quot; + body);              String[] split &#x3D; body.split(&quot;:&quot;);              String type &#x3D; split[1];              int triggerId &#x3D; Integer.parseInt(split[2]);              switch (type) &#123;                  case &quot;add&quot;:                      scheduledTriggerService.addTrigger(triggerId);                      break;                  case &quot;remove&quot;:                      scheduledTriggerService.removeTrigger(triggerId);                      break;                  case &quot;update&quot;:                      scheduledTriggerService.updateTrigger(triggerId);                      break;                  default:                      scheduledTriggerService.refreshAllTriggerEngine();                      break;              &#125;          &#125; else &#123;              log.info(&quot;receive redis message, topic: &#123;&#125;, body, &#123;&#125;&quot;, new String(message.getChannel()), body);              dwdDataTriggerService.refreshClauseTrigger();          &#125;      &#125;, new ChannelTopic(&quot;trigger-config-change&quot;));      return container;  &#125;</code></pre><p>发送消息：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">redisTemplate.convertAndSend(&quot;trigger-config-change&quot;, &quot;scheduled-trigger-change:update:0&quot;);</code></pre><p>当定时配置变更时，发送redis消息即可。</p><h3 id="总结-本篇文章基于我的实际项目，讲解了借助于quartz框架的定时任务动态增删改的方案，但是因项目而异，我也做了许多定制化的操作，我的思路就是一项定时任务配置对应一个对象实例，任务触发时直接拿到对应的对象实例进行调用，但是quartz框架的默认调度方案不是这样的，所以做了一下调整，此外还增加了集群环境的支持。本篇文章提供一种方案或者说思路，实际使用时还需要大家结合自己的需求进行合理更改或优化，例如当定时任务比较轻量的时候，我认为可不借助于框架，使用轮询也未尝不是一种简单有效的方案。"><a href="#总结-本篇文章基于我的实际项目，讲解了借助于quartz框架的定时任务动态增删改的方案，但是因项目而异，我也做了许多定制化的操作，我的思路就是一项定时任务配置对应一个对象实例，任务触发时直接拿到对应的对象实例进行调用，但是quartz框架的默认调度方案不是这样的，所以做了一下调整，此外还增加了集群环境的支持。本篇文章提供一种方案或者说思路，实际使用时还需要大家结合自己的需求进行合理更改或优化，例如当定时任务比较轻量的时候，我认为可不借助于框架，使用轮询也未尝不是一种简单有效的方案。" class="headerlink" title="总结: 本篇文章基于我的实际项目，讲解了借助于quartz框架的定时任务动态增删改的方案，但是因项目而异，我也做了许多定制化的操作，我的思路就是一项定时任务配置对应一个对象实例，任务触发时直接拿到对应的对象实例进行调用，但是quartz框架的默认调度方案不是这样的，所以做了一下调整，此外还增加了集群环境的支持。本篇文章提供一种方案或者说思路，实际使用时还需要大家结合自己的需求进行合理更改或优化，例如当定时任务比较轻量的时候，我认为可不借助于框架，使用轮询也未尝不是一种简单有效的方案。"></a><strong>总结:</strong> 本篇文章基于我的实际项目，讲解了借助于quartz框架的定时任务动态增删改的方案，但是因项目而异，我也做了许多定制化的操作，我的思路就是一项定时任务配置对应一个对象实例，任务触发时直接拿到对应的对象实例进行调用，但是quartz框架的默认调度方案不是这样的，所以做了一下调整，此外还增加了集群环境的支持。本篇文章提供一种方案或者说思路，实际使用时还需要大家结合自己的需求进行合理更改或优化，例如当定时任务比较轻量的时候，我认为可不借助于框架，使用轮询也未尝不是一种简单有效的方案。</h3></li></ul></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>后端开发</tag>
      
      <tag>Java</tag>
      
      <tag>quartz</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Angular使用Http拦截器</title>
    <link href="/2020/12/15/Angular%E4%BD%BF%E7%94%A8Http%E6%8B%A6%E6%88%AA%E5%99%A8/"/>
    <url>/2020/12/15/Angular%E4%BD%BF%E7%94%A8Http%E6%8B%A6%E6%88%AA%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在前端开发的过程中，一般通过HTTP接口与后端进行数据交互，而后端一般会固定一个返回格式，例如：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json">&#123;    &quot;code&quot;: 0,    &quot;success&quot;: true,    &quot;message&quot;: &quot;&quot;,    &quot;result&quot;:&#123;        &quot;id&quot;:9,        &quot;title&quot;:&quot;&quot;,        &quot;content&quot;:&quot;&quot;,        &quot;createTime&quot;:&quot;2020-11-25 19:22:31&quot;,        &quot;updateTime&quot;:&quot;2020-11-25 19:47:22&quot;,        &quot;available&quot;:true    &#125;&#125;</code></pre><p>&emsp;&emsp;前端在拿到数据后，首先判断是否成功，然后取出数据体显示到页面上，但是每一次都这么去做，几乎都是重复的操作，在后端开发的过程中，有诸如过滤器、Spring提供的拦截器等工具实现对HTTP请求的统一处理，在前端其实也有类似的东西，Angular框架就提供了拦截器接口:</p><pre class="line-numbers language-typescript" data-language="typescript"><code class="language-typescript">interface HttpInterceptor &#123;  intercept(req: HttpRequest&lt;any&gt;, next: HttpHandler): Observable&lt;HttpEvent&lt;any&gt;&gt;&#125;</code></pre><p>&emsp;&emsp;可以实现统一的HTTP请求处理，帮助我们简化代码，并且方便代码的维护，直接放上一个我实际使用过的示例代码：</p><pre class="line-numbers language-typescript" data-language="typescript"><code class="language-typescript">import &#123;  HttpErrorResponse,  HttpEvent,  HttpHandler,  HttpInterceptor,  HttpRequest,  HttpResponse,  HttpResponseBase&#125; from &#39;@angular&#x2F;common&#x2F;http&#39;;import &#123;Observable, of, throwError&#125; from &#39;rxjs&#39;;import &#123;Injectable&#125; from &#39;@angular&#x2F;core&#39;;import &#123;catchError, debounceTime, finalize, mergeMap, retry&#125; from &#39;rxjs&#x2F;operators&#39;;import &#123;AppService&#125; from &#39;..&#x2F;service&#x2F;app.service&#39;;&#x2F;** * 全局HTTP请求拦截器 *&#x2F;@Injectable()export class AppHttpInterceptor implements HttpInterceptor &#123;  &#x2F;&#x2F; 当前正在通信中的HTTP请求数量，此值是为了在http请求的过程中添加加载动画  public processingHttpCount &#x3D; 0;  &#x2F;&#x2F; 依赖注入  constructor(public appService: AppService) &#123;  &#125;  intercept(req: HttpRequest&lt;any&gt;, next: HttpHandler): Observable&lt;HttpEvent&lt;any&gt;&gt; &#123;    &#x2F;&#x2F; &#x2F;monitor前缀的不做处理    if (req.url.includes(&#39;&#x2F;monitor&#39;)) &#123;      return next.handle(req);    &#125;    &#x2F;&#x2F;; setTimeout(() &#x3D;&gt; this.appService.showLoadingBar &#x3D; true);    &#x2F;&#x2F;     this.processingHttpCount ++;    return next.handle(req.clone(&#123;      &#x2F;&#x2F; 为所有拦截的请求添加一个&#39;&#x2F;starry&#39;前缀      url: &#39;&#x2F;starry&#39; + (req.url.startsWith(&#39;&#x2F;&#39;) ? req.url : &#39;&#x2F;&#39; + req.url)    &#125;))      .pipe(        debounceTime(1000),        &#x2F;&#x2F; 失败时重试2次        retry(2),        mergeMap((event: any) &#x3D;&gt; &#123;          &#x2F;&#x2F; 处理后端HTTP接口返回结果          if (event instanceof HttpResponseBase) &#123;            &#x2F;&#x2F; HTTP返回代码正常            if (event.status &gt;&#x3D; 200 &amp;&amp; event.status &lt; 400) &#123;              &#x2F;&#x2F; 处理HTTP Response              if (event instanceof HttpResponse) &#123;                const body &#x3D; event.body;                &#x2F;&#x2F; 判断后端的成功标志字段是否为true                if (body &amp;&amp; body.success) &#123;                  &#x2F;&#x2F; 取出响应体数据的data部分并继续后续操作(将原有的body替换为了body[&#39;result&#39;])                  return of(new HttpResponse(Object.assign(event, &#123;body: body.result&#125;)));                &#125; else &#123;                  &#x2F;&#x2F; 抛出异常                  throw Error(body.message);                &#125;              &#125;            &#125;          &#125;          &#x2F;&#x2F; 其余事件类型不作拦截处理          return of(event);        &#125;), catchError((err: HttpErrorResponse) &#x3D;&gt; &#123;          &#x2F;&#x2F; 如果发生5xx异常，显示一个错误信息提示          this.appService.showSnackBar(err.message, 4000);          console.error(err.message)          return throwError(err);        &#125;), finalize(() &#x3D;&gt; &#123;          &#x2F;&#x2F; 最终processingHttpCount减一，并且在减至0的时候移除掉加载动画          setTimeout(() &#x3D;&gt; --this.processingHttpCount &#x3D;&#x3D;&#x3D; 0 ?            this.appService.showLoadingBar &#x3D; false : this.appService.showLoadingBar &#x3D; true, 500);        &#125;));  &#125;&#125;</code></pre><p>&emsp;&emsp;并将此拦截器注册在Angular模块的provider中去，在providers中添加：</p><pre class="line-numbers language-typescript" data-language="typescript"><code class="language-typescript">&#123;    provide: HTTP_INTERCEPTORS, useClass: AppHttpInterceptor, multi: true&#125;</code></pre><p>&emsp;&emsp;这样在调用后端接口的时候我们不用每次再处理后端的返回数据，可直接在返回值中拿到数据体部分去做页面展示，其余的事情就交给拦截器去处理，例如：</p><pre class="line-numbers language-typescript" data-language="typescript"><code class="language-typescript">this.httpClient.get(&#39;&#x2F;config&#x2F;template&#x2F;&#39; + template).subscribe(data &#x3D;&gt; this.configTemplates.push(&#123;template, data&#125;));</code></pre><p>&emsp;&emsp;至此，就配置好了一个HTTP拦截器，还可以统一处理请求的URL以及异常处理等等，十分方便。官方文档地址：<a href="https://angular.io/api/common/http/HttpInterceptor">https://angular.io/api/common/http/HttpInterceptor</a> (中文文档将 <strong>.io</strong> 改为 <strong>.cn</strong> 即可)<br>&emsp;&emsp;除此之外，对于页面路由，Angular其实也提供了类似的工具，可以对路由以及页面组件进行拦截控制，有机会再作介绍。</p>]]></content>
    
    
    
    <tags>
      
      <tag>前端开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker安装zookeeper集群(附bash脚本)</title>
    <link href="/2020/12/14/docker%E5%AE%89%E8%A3%85zookeeper%E9%9B%86%E7%BE%A4-%E9%99%84bash%E8%84%9A%E6%9C%AC/"/>
    <url>/2020/12/14/docker%E5%AE%89%E8%A3%85zookeeper%E9%9B%86%E7%BE%A4-%E9%99%84bash%E8%84%9A%E6%9C%AC/</url>
    
    <content type="html"><![CDATA[<ul><li><p>准备一个文件夹并进入此文件夹， 例如</p><p><code>mkdir -p ~/docker-app/zookeeper &amp;&amp; cd ~/docker-app/zookeeper</code></p></li><li><p>准备三个文件夹并写入zookeeper的myid</p><p><code>mkdir -p zoo1/data &amp;&amp; echo 1 &gt; zoo1/data/myid</code><br><code>mkdir -p zoo2/data &amp;&amp; echo 2 &gt; zoo2/data/myid</code><br><code>mkdir -p zoo3/data &amp;&amp; echo 3 &gt; zoo3/data/myid</code>  </p></li><li><p>创建一个docker-compose.yml文件并编辑  </p><p><code>vim docker-compose.yml</code></p><p>文件内容如下:  </p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">version: &#39;3.7&#39;networks:  zk_cluster:    name: zk_cluster #为集群创建一个网络    driver: bridge#集群中的服务(3个节点)services:  zoo1:    image: zookeeper #所使用的镜像    restart: always #容器异常时是否重启    container_name: zoo1 #容器名称    ports: #与宿主机的端口映射      - 2181:2181      - 8001:8080    # zookeeper的配置    environment:      ZOO_MY_ID: 1      ZOO_SERVERS: server.1&#x3D;0.0.0.0:2888:3888;2181 server.2&#x3D;zoo2:2888:3888;2181 server.3&#x3D;zoo3:2888:3888;2181    #容器目录映射，此处使用了相对路径    volumes:      - .&#x2F;zoo1&#x2F;data:&#x2F;data      - .&#x2F;zoo1&#x2F;datalog:&#x2F;datalog    #所使用的网络    networks:      - zk_cluster  zoo2:    image: zookeeper    restart: always    container_name: zoo2    ports:      - 2182:2181      - 8002:8080    environment:      ZOO_MY_ID: 2      ZOO_SERVERS: server.1&#x3D;zoo1:2888:3888;2181 server.2&#x3D;0.0.0.0:2888:3888;2181 server.3&#x3D;zoo3:2888:3888;2181    volumes:      - .&#x2F;zoo2&#x2F;data:&#x2F;data      - .&#x2F;zoo2&#x2F;datalog:&#x2F;datalog    networks:      - zk_cluster  zoo3:    image: zookeeper    restart: always    container_name: zoo3    ports:      - 2183:2181      - 8003:8080    environment:      ZOO_MY_ID: 3      ZOO_SERVERS: server.1&#x3D;zoo1:2888:3888;2181 server.2&#x3D;zoo2:2888:3888;2181 server.3&#x3D;0.0.0.0:2888:3888;2181    volumes:      - .&#x2F;zoo3&#x2F;data:&#x2F;data      - .&#x2F;zoo3&#x2F;datalog:&#x2F;datalog    networks:      - zk_cluster</code></pre></li><li><p>使用docker-compose命令运行  </p><p><code>docker-compose --project-directory $PWD up -d</code></p></li><li><p>附：一键创建docker zookeeper集群并执行的脚本（该方案仅供参考和学习，生产环境需仔细斟酌，合理修改配置参数）</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#! &#x2F;bin&#x2F;bashmkdir -p zookeeper &amp;&amp; cd zookeeperDIR&#x3D;$PWDecho &quot;cd $DIR&quot;echo &quot;create docker compose config file&quot;CONF_YML&#x3D;&#39;docker-compose.yml&#39;touch $CONF_YMLecho &quot;version: &#39;3.7&#39;&quot; &gt; $CONF_YMLNET&#x3D;&#39;zk_cluster&#39;echo &#39;networks:&#39; &gt;&gt; $CONF_YMLecho &quot;  $NET:&quot; &gt;&gt; $CONF_YMLecho &quot;    name: $NET&quot; &gt;&gt; $CONF_YMLecho &quot;    driver: bridge&quot; &gt;&gt; $CONF_YML#节点个数，可以修改此值创建任意数量的容器节点let CLUSTER_COUNT&#x3D;3 IMAGE&#x3D;zookeeperecho &quot;services:&quot; &gt;&gt; $CONF_YMLfor i in &#96;seq 1 $CLUSTER_COUNT&#96;do    echo &quot;  zoo$i:&quot; &gt;&gt; $CONF_YML    echo &quot;    image: $IMAGE&quot; &gt;&gt; $CONF_YML    echo &quot;    restart: always&quot; &gt;&gt; $CONF_YML    echo &quot;    container_name: zoo$i&quot; &gt;&gt; $CONF_YML    echo &quot;    ports:&quot; &gt;&gt; $CONF_YML    echo &quot;      - $[2180 + $i]:2181&quot; &gt;&gt; $CONF_YML    echo &quot;      - $[8000 + $i]:8080&quot; &gt;&gt; $CONF_YML    echo &quot;    environment:&quot; &gt;&gt; $CONF_YML    echo &quot;      ZOO_MY_ID: $i&quot; &gt;&gt; $CONF_YML    zk_srv_conf&#x3D;&#39;&#39;    for j in &#96;seq 1 $CLUSTER_COUNT&#96;    do        if test $i !&#x3D; $j;        then            zk_srv_conf+&#x3D;&quot;server.$j&#x3D;zoo$j:2888:3888;2181&quot;        else            zk_srv_conf+&#x3D;&quot;server.$j&#x3D;0.0.0.0:2888:3888;2181&quot;        fi        if test $j !&#x3D; $CLUSTER_COUNT;        then            zk_srv_conf+&#x3D;&#39; &#39;;        fi    done    echo &quot;      ZOO_SERVERS: $zk_srv_conf&quot; &gt;&gt; $CONF_YML    echo &quot;    volumes:&quot; &gt;&gt; $CONF_YML    echo &quot;      - .&#x2F;zoo$i&#x2F;data:&#x2F;data&quot; &gt;&gt; $CONF_YML    echo &quot;      - .&#x2F;zoo$i&#x2F;datalog:&#x2F;datalog&quot; &gt;&gt; $CONF_YML    echo &quot;    networks:&quot; &gt;&gt; $CONF_YML    echo &quot;      - $NET&quot; &gt;&gt; $CONF_YML    mkdir -p zoo$i&#x2F;data    echo $i &gt; zoo$i&#x2F;data&#x2F;myiddone# docker pull zookeeperdocker-compose --project-directory $DIR up -d</code></pre></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>docker</tag>
      
      <tag>后端开发</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
